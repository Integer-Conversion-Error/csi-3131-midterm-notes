"According to the text, what are the two main jobs of a computer?",Processing and networking,Input and output,I/O and computing,Storage and display,User interaction and security,C,The text explicitly states that a computer's main jobs are 'I/O and computing'.
"In many common computer uses, which function is often considered primary, with computing being incidental?",Data processing,System administration,I/O operations,Software development,Memory management,C,"The text mentions that 'Often, I/O is primary, computing incidental (e.g., browsing, editing)'."
What is the primary role of the Operating System (OS) concerning I/O?,To design new I/O devices,To manage and control I/O operations and devices,To optimize I/O device manufacturing,To provide power to I/O devices,To monitor network traffic only,B,The text states the 'OS role in I/O: manage and control I/O operations and devices'.
Which of the following is NOT explicitly mentioned as a topic covered regarding I/O?,I/O hardware basics and their constraints,OS I/O services and application I/O interface,The UNIX System V STREAMS mechanism,Historical evolution of I/O interfaces,I/O performance and OS design principles for improvement,D,"The text lists specific topics covered, and 'Historical evolution of I/O interfaces' is not among them."
What is identified as a major operating system design concern related to devices?,Device manufacturing cost,Device aesthetics,Device control,Device marketing strategies,Device power consumption,C,The text clearly states: 'Device control is major OS design concern'.
"Why do I/O devices like a mouse, hard disk, and tape robot require varied control methods?",Because they are manufactured by different companies.,Due to their wide variation in function and speed.,To ensure device security.,To comply with international standards.,To minimize power usage.,B,"The text explains that 'Wide variation in I/O device function/speed (mouse, hard disk, flash drive, tape robot) requires varied control methods'."
What is the primary purpose of the kernel's I/O subsystem?,To provide a user interface for I/O operations.,To manage network connections.,To separate the kernel from device management complexities.,To regulate the speed of I/O devices.,To analyze I/O data for security threats.,C,"The text states that control methods 'form kernel's I/O subsystem, separating kernel from device management complexities'."
Which I/O device technology trend helps in incorporating new device generations?,Decreasing cost of hardware components.,Increasing standardization of software/hardware interfaces.,Growing variety of I/O devices.,Miniaturization of devices.,Enhanced power efficiency.,B,The text notes: 'Increasing standardization of software/hardware interfaces: helps incorporate new device generations'.
What challenge do trends in I/O device technology present regarding device incorporation?,Decreasing demand for I/O devices.,Increasing difficulty in designing device drivers.,"Increasingly broad variety of I/O devices, making it challenging to incorporate new, unlike ones.",The rapid obsolescence of current I/O technologies.,Lack of sufficient power supply for new devices.,C,"The text identifies: 'Increasingly broad variety of I/O devices: challenge to incorporate new, unlike devices'."
Which basic I/O hardware elements are cited as capable of accommodating diverse devices?,"CPUs, RAM, and GPUs","Monitors, keyboards, and printers","Ports, buses, and device controllers","Hard drives, SSDs, and optical drives","Network cards, modems, and routers",C,"The text specifies: 'Basic I/O hardware elements (ports, buses, device controllers) accommodate diverse devices'."
How is the kernel structured to address the complexities of diverse I/O devices?,"By using a single, monolithic device management module.",By relying solely on hardware-level management.,By structuring with device-driver modules to encapsulate device details.,By requiring users to manually configure each device.,By limiting the number of supported I/O devices.,C,The text states: 'Kernel structured with device-driver modules to encapsulate device details'.
What uniform interface do device drivers provide to the I/O subsystem?,A programming language interface.,A physical connection interface.,A device-access interface.,A network protocol interface.,A graphical user interface.,C,"The text clarifies that 'Device drivers provide uniform device-access interface to I/O subsystem, similar to system calls for applications'."
"What is the definition of a ""device driver"" as provided in the glossary?",A hardware component that physically controls a device.,A software application used for device troubleshooting.,An OS component providing uniform access and managing I/O to various devices.,A protocol for device-to-device communication.,A utility for measuring device performance.,C,The glossary explicitly defines 'device driver' as 'OS component providing uniform access and managing I/O to various devices'.
"Which specific mechanism is mentioned as a topic covered, involving dynamic driver code pipelines?",Windows Plug and Play,Linux Kernel Modules,UNIX System V STREAMS,macOS I/O Kit,Android Hardware Abstraction Layer,C,The text lists 'UNIX System V STREAMS mechanism: dynamic driver code pipelines' as a covered topic.
"In the context of computer hardware, what is a 'port'?",A type of internal memory for fast data access.,A software interface for network communication protocols.,A connection point for devices to attach to computers.,A specialized processing unit within the CPU.,A temporary storage area for system logs.,C,The text defines a 'port' as a 'Connection point for devices to attach to computers'.
Which statement best describes a 'bus' in computer systems?,A software program that manages device drivers.,A protocol for network communication over wireless links.,"A communication system connecting computer components (CPU, I/O devices) for data and command transfer.",A specific type of input device like a scanner.,A method for cooling internal computer components.,C,"The text defines a 'bus' as a 'Communication system connecting computer components (CPU, I/O devices) for data/command transfer' and a 'set of wires, rigidly defined protocol'."
What is a 'daisy chain' in the context of device communication?,A secure encryption method for data transfer.,"Devices connected in a string (A to B, B to C), usually operating as a bus.",A network topology where all devices connect to a central hub.,A method for distributing power to multiple peripheral devices.,A series of parallel data lines for high-speed transfers.,B,"The text defines 'daisy chain' as 'devices connected in string (A to B, B to C), usually operates as a bus'."
Which bus type typically connects the processor-memory subsystem to fast devices in a PC bus structure?,Expansion bus,USB bus,Serial-attached SCSI (SAS) bus,PCIe bus,Parallel ATA (PATA) bus,D,The text states 'PCIe bus: connects processor-memory subsystem to fast devices'.
"In a typical PC bus structure, what is the primary function of the 'expansion bus'?",Connecting high-speed graphics cards directly to the CPU.,Providing direct access to main memory for the processor.,"Connecting slow devices such as keyboards, serial ports, and USB ports.",Managing network traffic between the computer and external networks.,Interfacing with external storage arrays in a data center.,C,"The text specifies the 'Expansion bus' 'connects slow devices (keyboard, serial, USB ports)'."
"In PCIe technology, what does a 'lane' consist of?",A single wire for unidirectional data flow.,Two signaling pairs (receive/transmit) enabling a full-duplex byte stream.,A shared channel for multiple devices to transmit data sequentially.,A dedicated power line for peripheral components.,A software-defined pathway for data packets.,B,"The text states a 'Lane: two signaling pairs (receive/transmit), full-duplex byte stream'."
"According to the text, what does 'PCIe gen3 x8' signify about the bus's capabilities?","It is the 3rd generation of PCIe, operating at 8 MB/s throughput.","It is the 3rd generation of PCIe, utilizing 8 lanes for a total throughput of 8 GB/s.","It is the 3rd generation of PCIe, with an 8-bit data packet format.","It is the 3rd generation of PCIe, offering 8 Gigabits per second per lane.","It is the 3rd generation of PCIe, with a maximum of 8 physical links.",B,"The text provides the example 'PCIe gen3 x8: 8 GB/s throughput', indicating 'x8' refers to 8 lanes."
What is a 'controller' in the context of I/O hardware?,A software driver that manages device operations.,"An electronic component that operates a port, bus, or device.",A physical cable connecting two devices in a daisy chain.,A memory unit used for buffering I/O data temporarily.,A diagnostic tool for identifying I/O hardware faults.,B,"The text defines 'Controller' as 'electronics operating a port, bus, or device'."
What is a 'host bus adapter (HBA)' primarily used for?,Boosting network signal strength for wireless devices.,Connecting a CPU directly to high-speed memory modules.,Acting as a complex device controller installed in a host bus port for device connection.,Regulating power supply to internal computer components.,Optimizing CPU scheduling for I/O-bound tasks.,C,"The text describes an HBA as a 'Device controller installed in host bus port for device connection', often complex like a Fibre Channel bus controller."
Which of the following tasks is specifically mentioned as being implemented by a disk controller?,Managing operating system boot processes.,Implementing network routing protocols for internet access.,"Bad-sector mapping, prefetching, buffering, and caching.",Allocating CPU time to various user applications.,Translating virtual memory addresses to physical addresses.,C,"The text states, 'Disk controller: implements disk-side protocol (SAS, SATA), microcode, processor for tasks (bad-sector mapping, prefetching, buffering, caching)'."
What is 'memory-mapped I/O'?,A technique where I/O devices have their own dedicated processor cores.,A method where device-control registers are mapped into the processor's address space.,A system where all I/O operations are handled exclusively by special I/O instructions.,A type of memory optimized solely for I/O operations.,A process of caching I/O data in dedicated buffer memory.,B,The text defines 'memory-mapped I/O' as a 'Device I/O method where device-control registers map into processor address space'.
"What is a key advantage of 'memory-mapped I/O', especially for tasks like updating graphics memory?",It reduces the complexity of device driver development.,"It allows the CPU to use standard data-transfer instructions, making large transfers faster.",It provides better security by isolating I/O devices from main memory.,It eliminates the need for any dedicated I/O controllers.,It guarantees real-time performance for all I/O operations.,B,The text notes that 'CPU uses standard data-transfer instructions to read/write registers at mapped locations' and 'Writing millions of bytes to graphics memory faster than millions of I/O instructions'.
Which of the following is NOT typically one of the four registers found in an I/O device controller?,Status register,Control register,Data-in register,Data-out register,Program Counter register,E,"The text lists 'Typically four registers: status, control, data-in, data-out'."
What is the primary function of the 'data-in register' in an I/O device controller?,To send output data from the host to the device.,To indicate the device's current operational state.,To receive input data from the device to be read by the host.,To initiate a command on the device.,To store temporary configuration settings.,C,"The text states, 'Data-in register: read by host for input'."
A host writes to which I/O device control register to start a command or change a device's mode?,Data-in register,Data-out register,Status register,Control register,Error register,D,"The text states, 'Control register: written by host to start command or change device mode'."
What information can typically be read from an I/O device's 'status register'?,Data to be sent to the device.,Commands to change device operating mode.,"States such as command complete, byte available, or error.",The device's unique serial number.,The amount of free memory on the device.,C,"The text states, 'Status register: bits read by host, indicate states (command complete, byte available, error)'."
What is the purpose of FIFO chips sometimes found in I/O controllers?,To prioritize commands from the host.,To implement flow control protocols for network communication.,"To hold several bytes, expanding capacity and buffering data bursts.",To generate interrupt signals to the CPU.,To store firmware for the controller's operation.,C,"The text states, 'Some controllers have FIFO chips: hold several bytes, expand capacity, buffer data bursts'."
What does 'polling' (or busy-waiting) involve in the context of host-controller interaction for I/O?,The host sends an interrupt request to the controller for every data transfer.,"The host continuously reads the status register of a device, waiting for I/O completion.",The controller sends data directly to main memory without CPU intervention.,The host dedicates a separate processor core to handle all I/O operations.,The controller queues up multiple I/O requests for batch processing.,B,The text defines 'polling' as an 'I/O loop where I/O thread continuously reads status waiting for I/O completion' and states 'host is busy-waiting or polling (repeatedly reading status register)'.
Under what condition is 'polling' an efficient method for host-controller interaction?,When the wait for the device to be ready is long.,When there are many other CPU tasks pending concurrently.,"When the controller and device are very fast, and the wait is short.",When data loss due to buffer overflow is a significant concern.,When interrupts are disabled by the CPU for critical sections.,C,"The text states, 'Polling efficient if controller/device fast'."
"What is a significant disadvantage of 'polling' for I/O, especially when the device is slow?",It increases the complexity of device driver development.,It leads to higher power consumption for the peripheral device.,"It is inefficient if the wait is long and other CPU tasks are pending, wasting CPU cycles.",It requires more dedicated hardware components for the I/O operation.,"It cannot detect errors during data transfer, leading to corrupted data.",C,"The text notes, 'Inefficient if wait is long and other CPU tasks pending'."
What is an 'interrupt' in computer systems?,A software function call to a kernel routine for service.,A hardware mechanism for a device to notify the CPU that it needs attention.,A signal indicating a power failure or system shutdown.,A type of memory error that leads to system instability.,A system for debugging application code execution.,B,The text defines 'interrupt' as a 'Hardware mechanism for device to notify CPU it needs attention'.
What action does the CPU take immediately after sensing an asserted 'interrupt-request line'?,It continues executing the current instruction until completion.,It saves its current state and jumps to a predefined interrupt-handler routine.,It clears the interrupt signal and waits for the next instruction cycle.,It starts polling the device's status register repeatedly.,It waits for the device to send data directly to a buffer.,B,"The text states, 'CPU senses interrupt-request line after each instruction... CPU saves state, jumps to interrupt-handler routine at fixed address'."
What type of errors are typically handled by a 'nonmaskable interrupt'?,User program errors like division by zero.,Routine device I/O completions.,"Unrecoverable hardware errors, such as memory errors.",Software requests for operating system services.,Network connection timeouts and disconnections.,C,"The text states 'Nonmaskable interrupt: for unrecoverable errors (e.g., memory errors)'."
Which statement is true about 'maskable interrupts'?,They are exclusively used for critical system failures that cannot be ignored.,They cannot be turned off or delayed by the CPU under any circumstances.,They are primarily used by device controllers and can be temporarily turned off by the CPU.,They always have a higher priority level than nonmaskable interrupts.,"They are only generated by software, not hardware devices.",C,"The text states 'Maskable: can be turned off by CPU for critical sequences, used by device controllers'."
What is the purpose of an 'interrupt vector'?,To store all pending interrupt requests in a queue.,To manage the priority levels of different interrupt sources.,To provide a table of memory addresses of specialized interrupt handlers.,To encrypt interrupt signals for enhanced system security.,To buffer data from I/O devices before it is processed by the CPU.,C,The text defines 'interrupt vector' as a 'table of memory addresses of specialized handlers'.
When is 'interrupt chaining' used in interrupt handling?,When there are fewer devices than available interrupt vector elements.,"To ensure all interrupts are handled by a single, monolithic handler.","When more devices exist than available interrupt vector elements, requiring a list of handlers per vector element.",To combine multiple low-priority interrupts into one high-priority interrupt.,To prevent any interrupt handler from servicing a request out of order.,C,"The text states 'More devices than vector elements: interrupt chaining', where 'each vector element points to head of handler list'."
"In the context of interrupts, what is an 'exception'?",A rare hardware fault that does not trigger an interrupt.,A software-generated interrupt caused by an error or a user program's request for OS service.,A high-priority external interrupt from a critical device.,A signal indicating successful completion of an I/O operation.,A general term for any event that temporarily halts CPU execution.,B,The glossary defines 'exception' as 'Software-generated interrupt by error or user program request for OS service'.
What is the primary role of the 'first-level interrupt handler (FLIH)' compared to the 'second-level interrupt handler (SLIH)'?,"FLIH performs the actual handling of the interrupt, while SLIH handles context switching and queuing.","FLIH is responsible for context switching, state storage, and queuing, while SLIH performs the actual interrupt handling.","FLIH is designed for maskable interrupts, while SLIH is for nonmaskable interrupts.","FLIH runs in user mode, while SLIH always runs in kernel mode.","FLIH manages interrupt priorities, while SLIH interacts directly with the device controller.",B,"The text states, 'First-level interrupt handler (FLIH): context switch, state storage, queuing', and 'Second-level interrupt handler (SLIH): performs actual handling'."
"Which mechanism saves user state, switches to kernel mode, and dispatches to a kernel routine, often triggered by a system call?",Polling,Direct Memory Access (DMA),A hardware interrupt from a device,A trap (software interrupt),Busy-waiting,D,"The text describes a 'Trap' as saving 'user state, switches to kernel mode, dispatches to kernel routine' and notes 'System calls: ... execute software interrupt or trap'."
How does the priority of a 'trap' (software interrupt) typically compare to that of device interrupts?,Traps always have higher priority because they initiate OS services.,Traps always have an equal priority to device interrupts.,"Traps typically have lower priority compared to device interrupts, as they are less urgent.",Trap priority is dynamically assigned based on current system load.,Traps are only handled when no device interrupts are active.,C,"The text states, 'Trap priority: low compared to device interrupts (less urgent)'."
"In a threaded kernel architecture (e.g., Solaris), how are interrupt handlers often implemented?",As independent user-level processes with fixed priorities.,"As kernel threads with high scheduling priorities, allowing preemption and concurrent execution on multiprocessors.","As part of the device driver, running in a continuous polling loop.",As hardware-level logic that bypasses the kernel entirely.,"As single-threaded, non-preemptable routines to ensure atomicity.",B,"The text states, 'Threaded kernel architecture (e.g., Solaris): interrupt handlers as kernel threads, high scheduling priorities, preemption, concurrent execution on multiprocessor'."
"Why is 'programmed I/O (PIO)' considered wasteful for large data transfers, such as from a disk?",It requires too much dedicated memory for buffering.,"It involves the CPU watching status bits and feeding data byte-by-byte, consuming significant CPU time.",It generates an excessive number of interrupt requests.,It can only transfer data in one direction at a time.,It requires specialized I/O instructions that are not efficient on modern CPUs.,B,"The text states, 'For large transfers (e.g., disk), programmed I/O (PIO) (CPU watching status bits, feeding data byte-by-byte) is wasteful'."
What is 'direct memory access (DMA)'?,A CPU feature that allows direct access to graphics memory without a controller.,An operation allowing device controllers to transfer large data directly to/from main memory without main CPU involvement.,A method for the CPU to directly access I/O ports using special instructions.,A caching technique for frequently accessed I/O data in the CPU's L1 cache.,A protocol for network communication between devices on a local area network.,B,The text defines 'direct memory access (DMA)' as an 'Operation allowing device controllers to transfer large data directly to/from main memory'.
How does a host typically initiate a DMA transfer?,By sending a series of I/O instructions for each byte to be transferred.,By continuously polling the DMA controller's status register.,"By writing a DMA command block (including source, destination, and byte count) to memory.",By raising a nonmaskable interrupt to alert the DMA controller.,By directly accessing the device's data-out register with the first byte.,C,"The text states, 'Initiate DMA: host writes DMA command block to memory (source, destination, byte count)'."
What does 'scatter-gather' allow in the context of DMA?,Transferring data to multiple devices simultaneously from a single source.,Specifying a list of non-contiguous sources/destinations in one DMA command.,Collecting multiple small I/O requests into a single large one for efficiency.,Distributing the load across multiple DMA controllers in a system.,Grouping related I/O devices on a single bus to reduce complexity.,B,The text describes a DMA command block that can be 'complex: list of non-contiguous sources/destinations (scatter-gather)'.
How does a DMA controller perform data transfers after being initiated by the CPU?,It requests the CPU to move data one byte at a time.,It uses the CPU's general-purpose registers to temporarily store data.,"It operates the memory bus directly, performing transfers without the main CPU's intervention.",It sends an interrupt to the CPU for each byte transferred to confirm reception.,It copies data from a dedicated cache memory within the CPU.,C,"The text states, 'DMA controller operates memory bus directly, performs transfers without main CPU'."
What is 'double buffering' often used for when transferring data from a device via DMA to a user space target?,To increase the speed of data transfer by using two DMA controllers in parallel.,"To copy data twice (e.g., device to kernel, then kernel to user memory) to manage risks of user space modification.",To store the same data in two different memory locations for redundancy.,To allow simultaneous read and write operations on the same data set.,To avoid 'cycle stealing' from the CPU by pre-fetching data.,B,"The text notes, 'Data to user space: second copy operation (double buffering) from kernel to user memory, inefficient', indicating its use due to modification risk."
What is 'cycle stealing' in the context of DMA?,The CPU gaining unauthorized access to device memory.,"A device (e.g., DMA controller) temporarily seizing the memory bus, preventing CPU access.",A technique to reduce CPU power consumption during idle periods.,The process of optimizing CPU clock cycles for faster execution.,A security vulnerability allowing unauthorized data exfiltration.,B,The text defines 'cycle stealing' as 'DMA controller seizing bus: CPU momentarily prevented from main memory access'.
What is a key characteristic or advantage of 'direct virtual memory access (DVMA)'?,"It allows direct memory access only to physical addresses, without translation.",It requires CPU intervention for every data transfer operation.,It enables transfers between memory-mapped devices using virtual addresses without CPU or main memory involvement.,It bypasses the need for any memory translation units (MMUs).,"It is an older, deprecated technology no longer used in modern computing.",C,"The text states 'DVMA: uses virtual addresses, translates to physical. Can transfer between memory-mapped devices without CPU/main memory'."
"Which bus type is commonly used in data centers to connect computers to storage arrays, as specified in the glossary?",PCIe bus,Expansion bus,Fibre Channel (FC) bus,USB bus,Parallel SCSI bus,C,The glossary defines 'Fibre channel (FC)' as a 'Storage I/O bus used in data centers to connect computers to storage arrays'.
What does the term 'PHY' refer to in the context of networking components mentioned in the glossary?,"A physical cable type, such as Ethernet or Fibre Optic.",The Physical hardware component connecting to a network (OSI layer 1).,A software layer for network protocol processing.,A power supply unit for network devices.,A diagnostic tool for network connectivity issues.,B,The glossary defines 'PHY' as 'Physical hardware component connecting to a network (OSI layer 1)'.
"What does the acronym SAS stand for, and what type of component is it, according to the glossary?",System Area Server; a type of network server.,Secure Access System; a security protocol for data encryption.,Serial-attached SCSI; a common type of I/O bus.,Software Allocation System; a memory management scheme.,Storage Area Subsystem; a component in data storage architectures.,C,The glossary defines 'SAS' as 'Serial-attached SCSI (SAS) Common type of I/O bus'.
"Which data transfer method involves the CPU transferring data one byte at a time, described as wasteful for large transfers?",Direct Memory Access (DMA),Interrupt-driven I/O,Programmed I/O (PIO),Memory-mapped I/O,Scatter-gather I/O,C,The glossary defines 'programmed I/O (PIO)' as 'Data transfer method where CPU transfers data one byte at a time'.
Which term describes a thread or process continuously using the CPU while waiting for an I/O operation to complete by repeatedly reading a status register?,Interrupt handling,Direct memory access,Busy waiting (polling),Context switching,Paging,C,The glossary defines 'busy waiting' as 'Thread/process continuously uses CPU while waiting; I/O loop reading status' and equates it with 'polling'.
Which of the following is explicitly mentioned as a key concept of I/O hardware in the summary?,Virtual memory paging,Application programming interfaces (APIs),Handshaking (host and device controller),Network routing protocols,CPU instruction pipelining,C,The 'I/O hardware summary' explicitly lists 'Handshaking (host and device controller)' as a key concept.
"What is the general term for device-control registers mapped into the processor's address space, allowing the CPU to use standard data-transfer instructions?",Special I/O instructions,Programmed I/O (PIO),Memory-mapped I/O,Direct Memory Access (DMA),Register-based communication,C,The text states 'Memory-mapped I/O: device-control registers mapped into processor address space. CPU uses standard data-transfer instructions to read/write registers at mapped locations'.
"Which register is read by the host to determine the current state of an I/O device, such as whether a command is complete or an error has occurred?",Data-in register,Data-out register,Control register,Status register,Interrupt register,D,"The text states, 'Status register: bits read by host, indicate states (command complete, byte available, error)'."
What is the primary goal of the application I/O interface structuring techniques?,To maximize the speed of I/O operations by bypassing the OS kernel.,"To ensure that all I/O devices have unique, non-standardized interfaces for security.","To treat I/O devices uniformly, abstracting away differences and simplifying OS development.","To allow applications direct, unmediated access to hardware device controllers.",To force hardware manufacturers to use only one specific type of I/O device.,C,The text states the overarching goal is to 'treat I/O devices uniformly' which simplifies OS development and allows for abstracting away device differences.
Which of the following approaches are explicitly mentioned as being utilized to achieve uniform treatment of I/O devices?,"Direct hardware manipulation, unmediated access, and polling.","Abstraction, encapsulation, and software layering.",Custom system calls for every device type and dedicated hardware.,"Batch processing, interrupt masking, and memory-mapped registers.","Kernel-level device drivers, but without standard interfaces.",B,"The text explicitly lists 'Approach: abstraction, encapsulation, software layering' as the methods used."
What is the primary purpose of the device-driver layer within the kernel I/O subsystem?,To directly manage application-level requests for I/O without kernel intervention.,To export non-standardized interfaces unique to each device controller.,To hide differences among device controllers from the kernel I/O subsystem.,To provide a direct interface for applications to bypass the kernel entirely for I/O.,To perform complex computations unrelated to device communication.,C,"The text states, 'Purpose of device-driver layer: hide differences among device controllers from kernel I/O subsystem.'"
A device that transfers bytes one by one is classified as what type of device?,Block device,Random-access device,Character-stream device,Synchronous device,Sharable device,C,The text defines 'Character-stream: transfers bytes one by one.'
What is the distinguishing characteristic of a 'block' device compared to a 'character-stream' device?,"Block devices transfer data asynchronously, while character-stream devices transfer synchronously.","Block devices transfer a block of bytes as a unit, while character-stream devices transfer bytes one by one.","Block devices are always random-access, while character-stream devices are always sequential.","Block devices are typically used for printers, while character-stream devices are for disks.","Block devices are dedicated, while character-stream devices are sharable.",B,The text defines 'Block: transfers a block of bytes as a unit' and 'Character-stream: transfers bytes one by one.'
Which characteristic describes an I/O device where the user can seek to any storage location?,Sequential access,Random-access,Character-stream,Synchronous,Dedicated,B,The text defines 'Random-access: user seeks to any storage location.'
What is the key difference between synchronous and asynchronous I/O devices regarding their response times?,"Synchronous devices have irregular/unpredictable response times, while asynchronous devices have predictable response times.",Synchronous devices are always faster than asynchronous devices.,"Synchronous devices have predictable response times and are coordinated, while asynchronous devices have irregular/unpredictable response times and are not coordinated.","Asynchronous devices require direct polling, while synchronous devices use interrupts.","Synchronous devices are dedicated, while asynchronous devices are sharable.",C,"The text states, 'Synchronous: predictable response times, coordinated. Asynchronous: irregular/unpredictable response times, not coordinated.'"
Which type of device can be used concurrently by several processes or threads?,Dedicated,Sequential,Read only,Sharable,Write once,D,The text defines 'Sharable: used concurrently by several processes/threads.'
Which of the following is NOT listed as a major access convention by which the OS groups devices?,Block I/O,Character-stream I/O,Direct Memory Access (DMA),Memory-mapped file access,Network sockets,C,"The text lists Block I/O, Character-stream I/O, Memory-mapped file access, and Network sockets as major access conventions. DMA is a hardware feature, not an access convention."
What is the purpose of an 'escape' or 'back door' mechanism in an OS I/O interface?,To allow the OS to directly control all network traffic.,To provide a standardized way to access all device functionalities.,To transparently pass arbitrary commands to a device driver when the standard interface lacks a specific method.,To restrict application access to sensitive device functions.,To implement file system caching for block devices.,C,The glossary defines 'escape' and 'back door' as a 'Method of passing arbitrary commands when interface lacks standard method.'
"In UNIX, what is the `ioctl()` system call primarily used for?",Performing standard file `read()` and `write()` operations.,Creating new system calls dynamically.,Enabling an application to access any driver functionality without requiring a new system call.,Managing memory allocation for device buffers.,Synchronizing clocks across multiple devices.,C,The text states `ioctl()` 'Enables application to access any driver functionality without new system call.'
"When using `ioctl()` in UNIX, what does the 'major number' of the device identifier typically represent?","The specific instance of a device (e.g., the second hard drive).",The total number of I/O operations performed on the device.,"The device type, which routes I/O requests to the appropriate driver.",The memory address where the device is mapped.,The speed of the I/O device.,C,"The text specifies, 'Major number: device type, routes I/O requests to driver.'"
What does 'raw I/O' imply when accessing secondary storage?,Accessing data through a standard file system interface with full buffering.,"Direct access to secondary storage as a linear array of blocks, bypassing the file system.",Only read-only access to storage devices.,Accessing data via memory-mapped files exclusively.,Transferring data byte by byte without block aggregation.,B,"The text defines 'raw I/O' as 'Direct access to secondary storage as array of blocks, no file system.'"
What is a key benefit of using raw I/O for applications like database management systems (DBMS)?,It allows for standard file system permissions to be enforced more strictly.,It avoids extra buffering and redundant locking provided by the OS file system.,It automatically encrypts data for secure storage.,It enables byte-by-byte data transfer for maximum granularity.,It simplifies the programming interface by eliminating the need for `seek()` commands.,B,"The text notes, 'Raw I/O avoids extra buffering and redundant locking.'"
How does memory-mapped file access typically operate?,It transfers entire files into main memory at once before any access.,"It accesses disk storage via a byte array in main memory, with data transferred only when needed (demand-paged).","It bypasses main memory entirely, transferring data directly between disk and CPU registers.",It requires applications to manage their own disk block allocation.,"It is exclusively used for character-stream devices, not block devices.",B,"The text states, 'Access disk storage via byte array in main memory. Data transfers only when needed (demand-paged virtual memory access), efficient.'"
Which of the following devices typically uses a character-stream interface?,Disk drives,Solid State Drives (SSDs),Keyboards,USB flash drives,CD-ROM drives,C,"The text lists 'keyboards, mice, modems, printers, audio boards' as examples for character-stream interface."
What is the common interface used for network I/O in operating systems like UNIX and Windows?,`read()`/`write()`/`seek()` interface,Character-stream interface,Network socket,Raw I/O interface,Memory-mapped file access,C,"The text states, 'Common interface: network socket (UNIX, Windows).'"
What is the primary function of the `select()` system call in the context of network sockets?,To establish a new network connection.,To send a packet over a network.,To manage a set of sockets and return information on which ones are ready for I/O.,To close an existing network socket.,To convert network addresses between IPv4 and IPv6.,C,"The text describes `select()` as managing 'set of sockets, returns info on ready sockets (packet waiting, room to send).'"
"How does the `select()` system call improve network I/O efficiency, particularly regarding polling?",It introduces additional busy-waiting to ensure data integrity.,It allows applications to poll constantly without performance impact.,It eliminates polling/busy waiting for network I/O by blocking until I/O is possible.,It forces the kernel to ignore I/O requests for a specified duration.,"It streams data directly to the CPU registers, bypassing kernel buffers.",C,"The text states, '`select()` eliminates polling/busy waiting for network I/O.'"
Which of the following is a key function provided by hardware clocks and timers to the OS and applications?,Managing file system permissions.,Performing context switching between processes.,"Providing current time, elapsed time, and setting timers for future operations.",Encrypting network traffic.,Resolving domain names to IP addresses.,C,"The text states, 'Hardware clocks/timers provide: current time, elapsed time, set timer for operation X at time T.'"
What is the primary mechanism by which a programmable interval timer helps the OS with operations like process preemption or cache flushing?,It directly executes the preemption logic.,"It generates an interrupt after a set period, allowing the OS to react.",It provides a continuous stream of time data for passive monitoring.,It stores user application data temporarily.,It synchronizes external network devices.,B,"The text states it can be 'Set to wait, then generate interrupt (once or periodically)' and is 'Used by scheduler (preempt process), disk I/O (flush dirty cache), network (cancel slow operations).'"
How does an OS typically manage more timer requests from user processes than the available hardware timer channels?,By rejecting any requests beyond the hardware limit.,By assigning a dedicated hardware timer to each user process.,"By simulating virtual clocks, maintaining a sorted list of wanted interrupts, and setting the hardware timer for the earliest.",By distributing timer requests across multiple CPUs without coordination.,By requiring user processes to implement their own timing logic.,C,"The text states, 'Supports more timer requests than hardware channels by simulating virtual clocks. Kernel maintains sorted list of wanted interrupts, sets timer for earliest.'"
Which protocol is specifically mentioned for correcting system clock drift?,TCP/IP,HTTP,Network Time Protocol (NTP),FTP,SMTP,C,"The text explicitly mentions, 'System clock drift corrected by protocols (e.g., network time protocol (NTP)).'"
What defines a 'blocking' system call in the context of I/O?,The calling thread continues execution immediately without waiting for I/O.,The system call returns with partial data if the full request cannot be met immediately.,The calling thread is suspended and moved to a wait queue until the I/O operation completes.,"The I/O operation is performed entirely in hardware, bypassing the OS.",It indicates that the I/O operation has failed.,C,"The text defines 'Blocking system call: calling thread suspended, moved to wait queue. Resumes after completion.'"
What is the main difference in behavior between a 'nonblocking' I/O system call and an 'asynchronous' I/O system call regarding data transfer?,"Nonblocking calls always transfer the full amount of data requested, while asynchronous calls never do.","Nonblocking calls suspend the calling thread, while asynchronous calls return immediately.","Nonblocking `read()` returns immediately with available data (full, fewer, or none), while asynchronous `read()` requests a full transfer to complete later, returning immediately.","Asynchronous calls require manual polling, while nonblocking calls use interrupts.","Nonblocking calls are only for network I/O, while asynchronous calls are for disk I/O.",C,"The text states, 'Difference: nonblocking `read()` returns available data immediately (full, fewer, none); asynchronous `read()` requests full transfer to complete later.' Both return immediately, but their immediate *result* is different regarding data readiness."
How is I/O completion typically communicated to a thread that initiated an asynchronous system call?,The thread remains blocked until completion.,By a return value indicating success or failure immediately.,"Via variable setting, a signal/software interrupt, or a callback.",Through continuous polling by the calling thread.,By logging the completion status to a system file.,C,"The text states, 'I/O completion communicated via variable setting, signal/software interrupt, or callback.'"
"What is the primary benefit of 'Vectored I/O,' also known as 'scatter-gather'?",It allows I/O operations to bypass the kernel entirely.,"It forces data to be transferred to a single, contiguous buffer first.","It performs multiple I/O operations involving multiple locations with one system call, avoiding context-switching and system-call overhead.",It encrypts all data transfers automatically.,It is exclusively used for character-stream devices.,C,The text defines 'Vectored I/O' as 'one system call performs multiple I/O operations involving multiple locations' and lists benefits including 'Avoids context-switching and system-call overhead.'
What is `direct I/O` in UNIX?,"A method for applications to access I/O devices directly, bypassing all OS layers.",A mode on a file that disables OS block features like buffering and locking.,A system call that guarantees immediate data transfer to the CPU registers.,An interface used only for network communication.,A special type of memory mapping for graphical displays.,B,"The text states, 'OS allows mode on file that disables buffering/locking (UNIX: direct I/O).' The glossary further defines it as 'Block I/O bypassing OS block features (buffering, locking).'"
Why do modern operating systems buffer I/O requests and often return to the application before the request fully completes?,To slow down I/O operations and conserve power.,To ensure data corruption by introducing delays.,To optimize performance by allowing the application to continue execution while I/O completes later.,To force applications to implement their own buffering mechanisms.,To prevent multiple applications from accessing the same device.,C,"The text says, 'OS buffers I/O, returns to application, completes request later (optimizes performance).'"
What is a High-Performance Event Timer (HPET) typically used for in modern PCs?,Managing network packet routing.,Storing user passwords.,Providing high-resolution time intervals and triggering interrupts when a value matches.,Controlling the graphical display resolution.,Simulating virtual memory for applications.,C,The text states HPET is a 'Hardware timer provided by some CPUs' and that 'Comparators trigger interrupts when value matches HPET.' It's also mentioned that a hardware clock (like HPET) offers 'accurate time intervals.'
Which of the following is NOT typically provided as a service by the kernel's I/O subsystem?,Scheduling I/O requests,Buffering data transfers,User application logic execution,Device reservation,Error handling for I/O operations,C,"The kernel's I/O subsystem provides services such as scheduling, buffering, caching, spooling, device reservation, and error handling. User application logic execution is the responsibility of the application itself, not the I/O subsystem."
What is a primary responsibility of the kernel's I/O subsystem regarding system integrity?,Managing user interface graphics,Protecting itself from errant processes and malicious users,Optimizing network packet routing,Compiling user-level code,Performing hardware diagnostics at boot time,B,The I/O subsystem is responsible for protecting itself from errant processes and malicious users to maintain system integrity.
What is the main purpose of I/O scheduling within the kernel's I/O subsystem?,To ensure applications always get their I/O requests processed in the exact order they were made.,To determine a good execution order for I/O requests to improve overall system performance and fairness.,To prevent any application from monopolizing an I/O device.,To simply maintain a queue of I/O requests without reordering.,To delegate all I/O processing directly to hardware controllers.,B,"I/O scheduling aims to determine a good execution order for requests, as the application system call order is rarely the best. This reordering improves overall system performance, ensures fair device access, and reduces average waiting time."
Which of the following is a benefit of I/O scheduling?,Increased power consumption of I/O devices.,Decreased responsiveness for delay-sensitive requests.,Reduction in average waiting time for I/O operations.,Elimination of the need for device queues.,Direct user-level access to I/O instructions.,C,"Benefits of I/O scheduling include improving overall system performance, ensuring fair device access, and reducing average waiting time."
How does the OS typically implement I/O scheduling?,By allowing applications to directly control device access order.,By maintaining a wait queue for each device and rearranging it for efficiency.,By immediately fulfilling every I/O request in FIFO order.,By offloading all scheduling decisions to the device hardware.,By only processing one I/O request at a time system-wide.,B,The OS implements I/O scheduling by maintaining a wait queue for each device and rearranging it to optimize for efficiency and average response time.
The kernel's I/O scheduler may prioritize certain requests. Which type of request is explicitly mentioned as potentially receiving higher priority?,Requests from general user applications.,Requests involving network communication only.,"Delay-sensitive requests, such as those from the virtual memory subsystem.",Requests for printing documents.,Requests that involve sequential disk reads.,C,"The OS may prioritize delay-sensitive requests, such as those originating from the virtual memory subsystem, over requests from standard applications."
What is a `device-status table` in the context of the kernel I/O subsystem?,A table used by applications to check device compatibility.,A kernel data structure that tracks the status and queues of operations for I/O devices.,A hardware component that stores device driver code.,A log of all I/O errors that have occurred since system boot.,A user-level interface for configuring new devices.,B,"A `device-status table` is a kernel data structure that tracks the status and queues of operations for each I/O device, particularly for asynchronous I/O."
What information is typically stored in an entry of the `device-status table` for an I/O device?,Only the device's unique serial number.,"The device's physical address, current state, and the type/parameters of any pending requests if busy.","The manufacturer, warranty information, and last service date of the device.",A list of all applications that have ever used the device.,The total amount of data ever transferred by the device.,B,"An entry in the `device-status table` typically includes the device type, its address, and its state (e.g., not functioning, idle, or busy). If the device is busy, the request type and parameters are also stored in its table entry."
What is the definition of a `buffer` in the context of the kernel I/O subsystem?,A specialized hardware component used for accelerating network traffic.,A memory area used for temporary storage of data being transferred between devices or between a device and an application.,A mechanism for encrypting data before it is written to disk.,A type of physical disk sector reserved for system files.,A software utility for compressing data.,B,A `buffer` is defined as a memory area that stores data being transferred between two devices or between a device and an application.
One key reason for using buffering in I/O operations is to cope with:,Insufficient main memory for applications.,Speed mismatch between the producer and consumer of data.,Excessive CPU utilization during I/O operations.,Hardware failures in I/O devices.,Security vulnerabilities in data transfer protocols.,B,"Buffering is primarily used to cope with the speed mismatch between the producer and consumer of data, allowing data to accumulate at one speed and be processed at another."
What is `double buffering`?,Using a single buffer that is twice the normal size.,"A technique where two buffers are used in alternation to decouple producer and consumer operations, relaxing timing constraints.",A method of writing data to two separate disks simultaneously for redundancy.,A process of verifying data integrity by reading it back into a second buffer.,Storing data both in a buffer and a cache at the same time.,B,"`Double buffering` involves using two buffers to decouple the producer and consumer, allowing one buffer to be filled while the other is being emptied, thereby relaxing timing requirements."
What does `copy semantics` for application I/O guarantee?,That the application's buffer is always a direct copy of the kernel's buffer.,"That data written to disk is the version that existed at the time of the system call, independent of subsequent application buffer changes.",That the OS never copies data between kernel and application space.,That all I/O operations are handled through a copy-on-write mechanism.,That data is never duplicated in memory.,B,"`Copy semantics` ensures that the version of data written to disk is exactly what was in the application's buffer at the moment the system call was made, even if the application modifies its buffer immediately thereafter."
How does an Operating System typically guarantee `copy semantics` for a `write()` system call?,By forcing the application to wait until the disk write is complete.,By marking the application's buffer as read-only after the call.,"By copying the application data to a kernel buffer before returning from the system call, and then writing from the kernel buffer to disk.",By directly writing from the application's buffer to the disk hardware.,By using a special hardware register to store the data temporarily.,C,"To guarantee `copy semantics`, the OS typically copies the application data into a kernel buffer immediately after the `write()` system call is made (and before returning to the application). The actual disk write then occurs from this kernel buffer."
What is the primary characteristic of a `cache`?,It is a permanent storage location for frequently accessed files.,"It is a region of fast memory that holds temporary copies of data, making access more efficient.",It is a dedicated processing unit for I/O operations.,It is a mechanism for encrypting data during transfer.,It is a component that converts data formats between different devices.,B,"A `cache` is defined as a region of fast memory that holds copies of data, which are typically found elsewhere, to improve performance by providing quicker access to those copies."
What is the key difference between a `buffer` and a `cache`?,"Buffers are always in main memory, while caches are always in CPU memory.","A buffer may hold the *only* copy of data during transfer, while a cache holds a *copy* of data that also resides elsewhere.","Caches are used for write operations, while buffers are used for read operations.","Buffers are managed by hardware, while caches are managed by the operating system.",There is no functional difference; the terms are interchangeable.,B,"The text states: 'buffer may hold only copy, cache holds copy of item residing elsewhere.' This is the key distinguishing characteristic, even though a memory region can serve both roles simultaneously."
How can main memory buffers used by the OS for disk data also act as a cache?,By converting the data format to a cached version.,By simply being a memory area; they don't serve as a cache.,By accumulating disk writes for efficient schedules and allowing the kernel to check them for file I/O requests to avoid/defer physical disk I/O.,By holding encrypted versions of the data.,By transferring data directly to the CPU's internal cache.,C,"OS uses main memory buffers for disk data (for copy semantics and efficient scheduling). These buffers also act as a cache by accumulating disk writes for seconds (allowing efficient write schedules) and by allowing the kernel to check them for file I/O requests, avoiding or deferring physical disk I/O if the data is already present."
What is a `spool` in the context of the kernel I/O subsystem?,A special type of high-speed network connection.,"A buffer that holds output for a device, like a printer, that cannot accept interleaved data streams.",A utility for defragmenting disk space.,A security feature that prevents unauthorized access to I/O devices.,A program that monitors CPU temperature.,B,"A `spool` is defined as a buffer holding output for a device (e.g., printer) that cannot accept interleaved data streams, allowing multiple applications to 'print' concurrently."
Why is spooling used for devices like printers?,To increase the printing speed of a single job.,To allow multiple applications to send output concurrently to a device that can only serve one job at a time.,To compress print jobs before sending them to the printer.,To provide real-time feedback on printer status to applications.,To ensure that print jobs are always processed in the order they were submitted by applications.,B,"Spooling addresses the problem that devices like printers can only serve one job at a time, while multiple applications may attempt to print concurrently. It coordinates this concurrent output by buffering jobs."
How does the spooling system typically manage concurrent print jobs?,It directly interweaves output from multiple applications to the printer.,It rejects print requests if the printer is currently busy.,"It intercepts each application's output, spools it to a separate file on secondary storage, queues these files, and then copies them to the printer one at a time.",It requires applications to wait until the printer is free before sending any output.,It sends a small part of each job to the printer in a round-robin fashion.,C,"The OS intercepts printer output, spools each application's output to a separate secondary storage file. Once an application finishes, the spooling system queues its spool file for printer output and copies these queued files to the printer one at a time."
"For which type of devices is explicit coordination and exclusive device access typically required, as they cannot multiplex I/O requests?",Solid State Drives (SSDs).,Network Interface Cards (NICs).,Graphics Processing Units (GPUs).,Tape drives and printers.,Keyboards and mice.,D,"The text explicitly states that 'Some devices (tape drives, printers) cannot multiplex I/O requests' and thus require explicit coordination facilities like exclusive device access."
"When an OS provides functions for processes to coordinate exclusive device access, what is the application's responsibility?",To handle all hardware-level device communication directly.,To avoid deadlock scenarios among competing requests for the device.,To perform its own I/O scheduling.,To manage the device's power state.,To ensure that its data is buffered by the OS.,B,"The text states, 'Applications responsible for avoiding deadlock' when using explicit coordination facilities for exclusive device access."
What is a primary goal of error handling within a protected memory Operating System?,To allow applications to directly recover from all hardware failures.,To ensure that minor malfunctions or errant applications do not cause system failure.,To permanently disable faulty hardware components.,To notify users of every single error event immediately.,To revert the system to a previous state every time an error occurs.,B,A protected memory OS guards against hardware/application errors to prevent system failure from minor malfunctions. It aims to compensate for transient failures and provide error information.
How does the OS typically handle transient I/O failures compared to permanent I/O failures?,It attempts to recover from both transient and permanent failures with equal success.,It ignores transient failures and attempts to recover only from permanent ones.,"It compensates for transient failures (e.g., retries) but is unlikely to recover from permanent failures of important components.",It immediately crashes the system upon detecting any type of I/O failure.,It passes all error recovery responsibility directly to the application for both types of failures.,C,"The OS compensates for transient failures (e.g., disk `read()` retry, network `send()` resend) but is unlikely to recover from permanent failures of important components."
"In UNIX systems, how does an I/O system call typically report error codes to an application?",By displaying a pop-up error message on the screen.,By writing a detailed error log to a file that the application must parse.,"By returning a success/failure bit, and if failure, setting an integer variable named `errno` with a specific error code.",By sending a network packet containing the error information.,By causing the application to terminate immediately.,C,"UNIX systems typically report I/O errors by returning a success/failure bit from the system call, and if it's a failure, setting the `errno` integer variable with a specific error code."
"According to the SCSI protocol error reporting, what does the `sense key` indicate?",The specific data block that caused the error.,"The general nature of the failure, such as a hardware error or an illegal request.",The exact parameter within a command that was incorrect.,The current temperature of the SCSI device.,The time and date the error occurred.,B,"The `sense key` in SCSI protocol error reporting indicates the general nature of the failure, such as a hardware error or an illegal request."
"In SCSI protocol error reporting, what level of detail does the `additional sense-code qualifier` provide?","It indicates the broad category of the failure, like a bad command parameter.",It specifies if the error is transient or permanent.,"It offers more specific detail about the failure, such as which parameter was bad or which subsystem failed.",It provides the contact information for technical support.,It identifies the firmware version of the SCSI device.,C,"The `additional sense-code qualifier` provides more specific detail about the failure, for example, indicating which parameter was bad or which subsystem failed."
How does the OS primarily prevent user processes from executing illegal I/O instructions directly?,By requiring all I/O instructions to be written in a special programming language.,"By making all I/O instructions privileged, requiring user programs to use system calls that transition to monitor mode.",By having user processes simulate I/O instructions without actually executing them.,By physically disconnecting I/O devices when a user process is running.,By encrypting all I/O instructions.,B,"All I/O instructions are privileged. User programs cannot issue them directly but must use system calls. The OS then performs the I/O in monitor (kernel) mode after checking its validity, returning control to the user."
How are memory-mapped I/O locations and I/O ports typically protected from user process access?,Through a special password system required for each access.,By physically isolating the memory regions from the CPU.,"By the memory-protection system, which restricts user access to these specific memory areas.",By requiring users to physically unplug and replug the I/O device.,They are not protected; any user process can access them freely.,C,"Memory-mapped and I/O port memory locations are protected from user access by the memory-protection system, which is typically part of the operating system's memory management unit."
"Why might a kernel provide a mechanism for controlled direct user access to specific I/O memory, even though most I/O is privileged?",To simplify the kernel's internal I/O management.,To increase system security by offloading responsibility to user processes.,"Because certain applications, like graphics games, require high-performance direct access to memory-mapped graphics memory.",To reduce the overall memory footprint of the operating system.,To allow users to develop their own device drivers easily.,C,"The kernel cannot deny all user access. For example, graphics games need direct, high-performance access to memory-mapped graphics memory for rendering. In such cases, the kernel might provide a locking mechanism to allocate a specific section to one process at a time."
What is the primary purpose of kernel maintaining in-kernel data structures for I/O components?,To store user application data.,"To keep state information on I/O components, such as device status, open files, and network connections.",To store device driver executable code.,To record all user login attempts.,To perform arithmetic calculations for the CPU.,B,"The kernel keeps state information on I/O components via in-kernel data structures, tracking things like open files, network connections, and character-device communications."
"How does UNIX typically handle the differing `read()` semantics for various entities like user files, raw devices, and process address spaces?",It requires each application to implement its own `read()` logic for each entity.,It uses a separate kernel system call for each distinct entity type.,"It encapsulates these differences using an object-oriented technique, where an open-file record contains a dispatch table with pointers to appropriate routines based on file type.",It converts all entities to a common data format before `read()` operations.,It delegates the handling of `read()` semantics entirely to the device drivers.,C,UNIX encapsulates the differences in `read()` semantics for various entities using an object-oriented technique. An open-file record contains a dispatch table with pointers to the appropriate routines based on the file type.
Which operating system is mentioned as using a message-passing approach for I/O requests?,Linux,macOS,UNIX,Windows,Android,D,"The text states: 'Some OS use message-passing for I/O (e.g., Windows).'"
"What is a key benefit of using a message-passing approach for I/O, despite potential overhead compared to procedural techniques?",It guarantees faster I/O completion times for all requests.,"It simplifies the I/O system structure and design, adding flexibility.",It eliminates the need for device drivers.,It inherently provides copy semantics without extra steps.,It significantly reduces the kernel's memory footprint.,B,"Despite potential overhead, message-passing for I/O offers benefits such as simplifying the I/O system structure and design, and adding flexibility."
"In data centers, what is a major driving factor for the operating system's role in power management?",Maximizing individual CPU core performance.,Increasing data storage capacity.,"Minimizing power costs, greenhouse gas emissions, and heat generation.",Improving network bandwidth.,Ensuring continuous uptime regardless of power consumption.,C,"The text highlights that in data centers, power costs, greenhouse gas emissions, and heat generation (and associated cooling costs) are significant concerns, making OS power management crucial."
Which of the following best describes Android's 'power collapse' state?,A full system shutdown requiring a manual restart.,"A deep sleep state that uses marginally more power than off, but responds to external stimuli and wakes quickly.","A state where only the screen is turned off, with all other components fully active.",A mode where the CPU runs at maximum frequency for performance.,"A state used for data backup, where I/O is paused indefinitely.",B,"Android's 'power collapse' is described as a deep sleep state that uses marginally more power than off, but can respond to external stimuli and allows for quick wake-up."
How does Android's component-level power management typically determine when to enter 'power collapse'?,It relies solely on a user-defined timer for sleep mode.,It enters power collapse only when the battery level is critically low.,"It tracks component usage via device drivers; if a component is unused, it's turned off, and if all components in the device tree are unused, the system enters power collapse.",It requires applications to explicitly notify the OS when they are idle.,It analyzes network activity and enters power collapse only when there is no incoming traffic.,C,"Android builds a device tree and associates components with device drivers that track usage. If a component is unused, it's turned off. If all components on a bus are unused, the bus is off. If all components in the device tree are unused, the system enters power collapse."
What is the primary purpose of 'wakelocks' in Android's power management?,To lock the device screen to prevent accidental touches.,To temporarily prevent the system from entering a low-power 'power collapse' state when an application needs to perform work.,To ensure that only one application can access a device at a time.,To encrypt data before the device enters a sleep state.,To measure the power consumption of individual applications.,B,"`Wakelocks` allow applications to temporarily prevent the system from entering a low-power 'power collapse' state when they need to keep the CPU or certain components active, for example, during an application update."
What is ACPI (Advanced Configuration and Power Interface)?,A type of network protocol for data centers.,A proprietary Android power management component.,An industry standard firmware that provides callable routines for the kernel to manage hardware aspects like device state and power.,A software library for graphics rendering.,A physical connector for external I/O devices.,C,"ACPI (Advanced Configuration and Power Interface) is an industry standard firmware that provides callable routines for the kernel, facilitating device state discovery, management, error management, and power management."
What is the primary role of ACPI firmware in modern computers regarding power management?,It directly powers off individual CPU cores without OS involvement.,It serves as an interface through which the kernel can call routines to manage device power states and other hardware aspects.,It is responsible for compiling the device tree at boot time.,It exclusively handles power delivery to the motherboard components.,It logs power consumption data for user analysis.,B,"ACPI provides callable routines for the kernel to interact with and manage various hardware aspects, including device state discovery, error management, and power management. The kernel calls device drivers, which in turn call ACPI routines to communicate with the hardware."
"Which of the following aspects is supervised by the kernel's I/O subsystem, as stated in the summary?",User application code debugging.,Financial transaction processing.,Device-driver configuration and initialization.,Web browser rendering.,Predictive analytics for system failures.,C,"The kernel I/O subsystem supervises several aspects, including device-driver configuration and initialization, alongside management of namespaces, access control, buffering, scheduling, and error handling."
How do upper levels of the I/O subsystem typically access devices?,Through direct memory access by applications.,Via a uniform interface provided by device drivers.,By sending raw commands directly to hardware controllers.,Only through message-passing mechanisms.,By user-defined callback functions.,B,"Upper levels of the I/O subsystem access devices via a uniform interface from device drivers, abstracting away hardware specificities."
"How does an operating system typically enable an application to access data stored on a disk, starting from the application's perspective?",By directly mapping the application's memory to disk sectors.,"Through a file name, which the file system then maps to physical disk blocks.",By using hardware-specific addresses provided directly by the application.,Applications send raw I/O commands to the disk controller.,The application manually translates file names into inode numbers.,B,"The text states, 'Application refers to data by file name. File system maps file name through directories to space allocation.'"
"In MS-DOS using the FAT file system, how does a file name primarily relate to the physical storage on disk?",The file name directly indicates the memory-mapped register of the disk controller.,"The file name is mapped to an inode number, which contains space allocation information.","The file name, via a number, indicates an entry in a file-access table that tells which disk blocks are allocated.","The first part of the file name points to a device driver, and the rest to an offset.",It uses a mount table to associate the file name with a device.,C,"The text explains, 'MS-DOS for FAT: name maps to number, indicates entry in file-access table, tells which disk blocks allocated.'"
How does the UNIX operating system typically map a file name to its physical storage allocation information?,The file name is directly converted into a major and minor device number.,"The file name is mapped to an inode number, which then contains the space-allocation information.","The file name specifies a port address, which is then looked up in a device table.",A mount table entry directly provides the disk block addresses for the file.,It relies on a separate device name space to identify the disk location.,B,"The text states, 'UNIX: name maps to inode number, inode contains space-allocation info.'"
Which characteristic describes the device naming convention in MS-DOS for FAT file systems?,Device names are fully integrated into the regular file-system name space.,Device names are resolved using a mount table lookup for path prefixes.,The first part of the file name (before a colon) identifies the hardware device.,Devices are identified by major and minor device numbers within the file name.,It uses a device table that maps file names directly to port addresses.,C,"The text specifies, 'MS-DOS for FAT: first part of file name (before colon) identifies hardware device (e.g., `C:` for primary hard disk).'"
What is a key difference in how MS-DOS (FAT) and UNIX handle their device name spaces relative to the file-system name space?,"MS-DOS integrates device names into the file system, while UNIX keeps them separate.","MS-DOS uses major/minor device numbers for all device naming, unlike UNIX.","MS-DOS has a separate device name space (due to colon separator), while UNIX incorporates it into the regular file-system name space.","UNIX uses a mount table for device naming, whereas MS-DOS relies on direct port addresses in file names.","Both systems fully integrate device names, but use different lookup mechanisms.",C,"MS-DOS has a 'Device name space separate from file-system name space (due to colon separator),' while 'UNIX: device name space incorporated in regular file-system name space.'"
"In UNIX, what is the primary function of the `mount table`?",To store inode numbers for all files on the system.,To map file names directly to physical disk block addresses.,To associate path name prefixes with specific device names.,To provide a list of all currently open file descriptors for processes.,To convert major device numbers into minor device numbers.,C,"The text states, 'UNIX uses mount table: associates path name prefixes with specific device names.' The glossary further defines it as tracking file systems and access for mounted volumes."
"When resolving a path name to a device in UNIX, what is typically found after looking up the device name itself?",The inode number for the device.,The direct memory-mapped address of the device controller.,"A `<major, minor>` device number.",The file-access table entry.,The corresponding file descriptor.,C,"The text explains, 'Lookup device name: finds `<major, minor>` device number, not inode.'"
What is the purpose of the major device number in UNIX-like systems?,"To identify the specific instance of a device (e.g., the second hard drive).",To indicate the size of the device's buffer cache.,To identify the device driver responsible for handling I/O for that device type.,To specify the hardware port address of the device controller.,To signify whether the device is block-oriented or character-oriented.,C,"The text explicitly states, 'Major device number: identifies device driver to handle I/O.'"
What is the role of the minor device number in UNIX-like systems?,"To identify the generic type of device, such as 'disk' or 'printer'.",To specify the base address in memory where the device's data is stored.,To be passed to the device driver to index into a device table for a specific device instance.,To determine the interrupt request line (IRQ) used by the device.,To indicate whether the device requires direct memory access (DMA).,C,"The text says, 'Minor device number: passed to device driver to index into device table.'"
"After obtaining the major and minor device numbers in UNIX, what information does the device-table entry typically provide?","The file system type (e.g., ext4, FAT32).",The number of disk blocks allocated to the device.,The path to the device driver's executable file.,The port address or memory-mapped address of the device controller.,"The current status of the device (e.g., busy, idle).",D,"The text states, 'Device-table entry: gives port address or memory-mapped address of device controller.'"
What flexibility do modern operating systems often provide regarding device drivers?,They require kernel recompilation for every new device added.,They load all possible device drivers at boot time regardless of connected hardware.,They allow new devices and drivers to be introduced without kernel recompilation and can load drivers on demand.,Device drivers are exclusively managed by user-space applications.,They prevent any dynamic changes to device drivers after boot.,C,The text highlights that 'New devices/drivers can be introduced without kernel recompilation' and 'Some OS load device drivers on demand.'
How might an operating system detect and load a driver for a device added *after* boot time?,By waiting for manual user input to install the driver.,The kernel inspects the device upon detecting an error related to it and loads the driver dynamically.,By performing a full system reboot to rescan all buses.,It requires the application to explicitly call a driver loading function.,"Drivers for such devices must be pre-loaded, or they cannot be used.",B,"The text states, 'Devices added after boot: detected by error, kernel inspects, loads driver dynamically.'"
What is the very first step in the life cycle of a blocking `read()` system call for an opened file?,The device driver immediately allocates kernel buffer space.,The kernel system-call code checks parameters and looks for data in the buffer cache.,The process is directly placed on a wait queue for the device.,The I/O subsystem sends a request to the device controller.,The DMA controller begins transferring data.,B,"The process begins by issuing the `read()` call, and then 'Kernel system-call code checks parameters. If data in buffer cache, data returned, I/O completed.'"
"If a physical I/O operation is required for a blocking `read()` request because the data is not in the buffer cache, what happens to the requesting process?","It continues executing, polling the device for completion.",It is terminated to free up resources.,It is removed from the run queue and placed on a wait queue for the device.,It is immediately moved to the ready queue to await CPU assignment.,It spawns a new thread to handle the I/O asynchronously.,C,"The text explains, 'Else, physical I/O performed. Process removed from run queue, placed on wait queue for device. I/O request scheduled.'"
"After receiving an I/O request from the kernel's I/O subsystem, what is a key action performed by the device driver in the context of a blocking read?",It directly transfers data to the application's address space.,It unblocks the requesting process by moving it to the ready queue.,It allocates kernel buffer space and sends commands to the device controller by writing to its registers.,It receives interrupts from the DMA controller and stores data in the buffer cache.,It updates the mount table with new device information.,C,"Step 5 states, 'Device driver allocates kernel buffer space, schedules I/O. Sends commands to device controller by writing to device-control registers.'"
"In the lifecycle of a blocking read request, what is the primary responsibility of the device controller?",To manage the system's buffer cache.,To operate the device hardware for data transfer.,To determine which device driver to load.,To place the requesting process on the wait queue.,To handle interrupts from other devices.,B,"Step 6 indicates, 'Device controller operates device hardware for data transfer.'"
"How is the completion of a data transfer from a device to kernel memory often signaled, particularly when Direct Memory Access (DMA) is used?",The device driver continuously polls the device status.,The application process checks a shared memory flag.,The DMA controller generates an interrupt upon transfer completion.,The kernel periodically checks a global status variable.,The device controller sends a direct signal to the requesting process.,C,"Step 7 mentions, 'DMA controller generates interrupt on transfer completion.'"
"Upon receiving an interrupt from a DMA controller, what is a key action taken by the correct interrupt handler?",It immediately unblocks the requesting process.,It re-schedules the I/O request for later.,"It stores the transferred data, signals the device driver, and then returns.",It reconfigures the device controller.,It modifies the major and minor device numbers.,C,"Step 8 details, 'Correct interrupt handler receives interrupt via interrupt-vector table, stores data, signals device driver, returns.'"
"After the device driver signals the kernel I/O subsystem that an I/O request has completed, what are the kernel's final steps to complete the blocking `read()`?",It terminates the process and cleans up resources.,It only updates the device's status in the device table.,It transfers data/return codes to the requesting process's address space and moves the process from the wait queue to the ready queue.,It reloads the device driver to ensure readiness for the next request.,It modifies the file system's allocation table.,C,"Step 10 outlines, 'Kernel transfers data/return codes to requesting process's address space. Moves process from wait queue to ready queue.'"
"According to the glossary, what is a `mount table`?",A physical table where hard drives are installed.,A list of all active processes and their file descriptors.,"An in-memory data structure with info about each mounted volume, tracks file systems and access.",A temporary buffer for I/O requests before they are sent to the device controller.,A table that maps interrupt requests to their respective handlers.,C,"The glossary defines 'mount table' as 'In-memory data structure with info about each mounted volume, tracks file systems and access.'"
What is the primary purpose of the STREAMS mechanism in UNIX System V?,To provide a secure encryption layer for inter-process communication.,To enable dynamic assembly of driver code pipelines.,To manage virtual memory allocation for user processes.,To facilitate distributed file system access across networks.,To optimize CPU scheduling algorithms for real-time applications.,B,"The STREAMS mechanism enables dynamic assembly of driver code pipelines, as stated in the text and glossary definition."
A 'stream' in the STREAMS mechanism represents a full-duplex connection between which two components?,A user process and a network interface card.,A device driver and a user-level process.,Kernel space and user space.,Two distinct device drivers within the kernel.,Two user-level processes for inter-process communication.,B,The text defines a stream as a 'full-duplex connection between device driver and user-level process'.
Which of the following are the fundamental architectural components of a STREAMS connection?,"Stream head, device files, and read/write system calls.","Stream head, stream modules, and driver end.","User process, kernel, and physical device.","Read queue, write queue, and message buffer.","Input buffer, output buffer, and control logic.",B,"The components listed are 'Stream head', 'Driver end', and 'Zero or more stream modules'."
What is the primary function of the 'stream head' component in a STREAMS mechanism?,Controlling the physical hardware device.,Providing modular processing functionality for data.,Interfacing directly with the user-level process.,Responding to hardware interrupts from the device.,Managing the flow of data between modules.,C,The text states the 'Stream head: interfaces with user process'.
What is the main responsibility of the 'driver end' in a STREAMS connection?,To provide a user-level interface for application programs.,To encapsulate processing logic for data transformation.,To control the actual hardware device.,To manage message exchange between adjacent queues.,To handle asynchronous I/O operations from user processes.,C,The text specifies that the 'Driver end: controls the device'.
How is data primarily transferred between components within a STREAMS connection?,Through direct memory access (DMA) operations.,Using shared memory segments between components.,Via message passing between queues.,By direct function calls between kernel modules.,Through atomic operations on shared variables.,C,The text states 'Data transfer: message passing between queues'.
How are stream modules typically added or 'pushed' onto a stream by a user process?,By modifying kernel boot parameters.,Using the `open()` system call.,Via the `ioctl()` system call.,Through an `exec()` call with specific arguments.,Automatically by the operating system upon device access.,C,Modules are 'pushed' onto a stream using `ioctl()` system call.
What is the main purpose of 'flow control' in STREAMS modules?,To ensure messages are delivered in a specific order.,To prevent queue overflow by regulating data flow.,To encrypt data messages for secure communication.,To compress data before sending it to the device.,To log all data transfers for debugging purposes.,B,The text states flow control is used 'To prevent queue overflow'.
"If a STREAMS queue does NOT support flow control, how does it typically behave when receiving messages?",It buffers messages until sufficient space becomes available.,It immediately drops any incoming messages without processing.,It accepts all messages and immediately sends them to the adjacent queue without buffering.,It signals the sending queue to pause its data transmission.,It redirects overflow messages to a system-wide error log.,C,"Without flow control, a queue 'accepts all messages, immediately sends to adjacent queue without buffering'."
How does a STREAMS queue behave when it *does* support flow control?,It accepts all messages regardless of its current buffer space.,It immediately drops messages if the adjacent queue is busy.,It buffers messages and does not accept new messages without sufficient buffer space.,It signals the user process directly to halt data transmission.,It converts all incoming messages into an unstructured byte stream before processing.,C,"With flow control, a queue 'buffers messages, does not accept messages without sufficient buffer space'."
Which system call allows a user process to write raw data directly to a STREAMS connection?,`getmsg()`,`read()`,`ioctl()`,`putmsg()`,`write()`,E,`write()`: writes raw data to stream.
"A user process wants to send a specific structured message, not just raw data, to a device via STREAMS. Which system call should it use?",`read()`,`getmsg()`,`putmsg()`,`write()`,`poll()`,C,`putmsg()`: allows user to specify a message.
"When a user process reads data from a STREAMS connection using the `read()` system call, what is typically returned by the stream head?",A structured message with header and data fields.,"An ordinary, unstructured byte stream.",A control message indicating the stream's status.,An error code if no complete message is available.,The entire content of the read queue as a single block.,B,"`read()`: stream head gets message, returns ordinary data (unstructured byte stream)."
"Which system call is used by a user process to retrieve a complete message, rather than an unstructured byte stream, from a STREAMS connection?",`write()`,`putmsg()`,`getmsg()`,`ioctl()`,`select()`,C,`getmsg()`: message returned to process.
How is STREAMS I/O generally characterized regarding its blocking behavior?,It is always synchronous and blocking for all operations.,It is always asynchronous and nonblocking.,It is asynchronous (nonblocking) except when communicating with the stream head.,"It blocks only during read operations, never during writes.","It blocks only during write operations, never during reads.",C,STREAMS I/O is asynchronous (or nonblocking) except when communicating with stream head.
Under what condition might a user process block when writing data to a STREAMS connection?,If the device driver is not yet initialized.,If the stream head has no room for the message to be copied.,If the next queue in the stream uses flow control and has no room to copy the message.,If the `write()` call is used instead of `putmsg()`.,If another user process is simultaneously reading from the same stream.,C,Writing to stream: user process blocks (if next queue uses flow control) until room to copy message.
"How does the driver end typically handle incoming data compared to the stream head, concerning flow control and blocking?",Both the driver end and stream head are designed to block if their buffers are full.,"The driver end must handle all incoming data, unlike the stream head which may block.","The stream head must handle all incoming data, unlike the driver end which may block.",Neither can block; they both always drop data if full.,"Only the stream head supports flow control, the driver end does not.",B,"Unlike stream head (may block), driver end must handle all incoming data. Drivers must support flow control."
What commonly happens if a device's internal buffer becomes full when processing data from a STREAMS connection?,The device driver automatically expands its buffer size.,The device typically drops the incoming messages.,"The stream immediately terminates, requiring re-initialization.",The user process is notified to re-send the data at a later time.,Flow control mechanisms are temporarily disabled to force data through.,B,"If device buffer full: device typically drops incoming messages (e.g., network card)."
What is cited as a major benefit of the STREAMS mechanism in UNIX systems?,It provides a robust security layer for all kernel-level I/O operations.,It eliminates the need for physical device drivers in the kernel.,"It offers a framework for modular, incremental device drivers and network protocols.",It guarantees hard real-time performance for all connected devices.,"It simplifies memory management, reducing memory footprint for I/O.",C,"Benefit of STREAMS: framework for modular, incremental device drivers and network protocols."
A key advantage of STREAMS modules is their reusability. What does this mean in practice?,Modules can be dynamically loaded and unloaded without system reboot.,A single module can be used by different streams or for different devices.,"Modules can be written in any programming language, independent of the kernel language.",Modules can automatically adapt to new hardware without modification.,"Modules can be combined into a single, monolithic driver for performance.",B,"Modules reusable by different streams/devices (e.g., networking module for Ethernet and 802.11 wireless)."
"Beyond just unstructured byte streams, what additional information does STREAMS support transfer between modules?",File permissions and ownership details.,CPU utilization metrics for each module.,Message boundaries and control information.,Process IDs and user credentials for security.,Detailed kernel stack trace data for debugging.,C,STREAMS 'Supports message boundaries and control info between modules (not just unstructured byte stream)'.
Which well-known mechanism is mentioned as being implemented using STREAMS in System V UNIX and Solaris?,Virtual memory paging.,Process scheduling algorithms.,File system journaling.,The socket mechanism.,Inter-process communication (IPC) shared memory.,D,Example: System V UNIX and Solaris implement socket mechanism using STREAMS.
Which of the following is identified as a major factor significantly impacting overall system performance?,CPU clock speed,Memory bus bandwidth,I/O operations,GPU processing power,Disk storage capacity,C,The text explicitly states: 'I/O: major factor in system performance.'
Heavy demands on the CPU due to I/O primarily involve which two activities?,Executing user application code and managing virtual memory,Performing floating-point calculations and handling network protocols,Executing device-driver code and scheduling processes (block/unblock),Managing file system access and caching frequently used data,Initializing hardware components and monitoring system temperature,C,"The text states that heavy I/O demands on the CPU include 'execute device-driver code, schedule processes (block/unblock).'"
What is the primary effect of context switches on system resources?,They reduce memory consumption by flushing caches.,They stress the CPU and hardware caches.,They eliminate the need for interrupt handling.,They always improve system throughput.,They increase network latency.,B,The text indicates: 'Context switches: stress CPU and hardware caches.'
How do data copies between controllers/physical memory and kernel buffers/application space impact the system?,They reduce the overall system latency.,They offload work from the main CPU.,They improve the efficiency of interrupt handling.,They load the memory bus.,They directly increase CPU clock speed.,D,"The text states: 'Loads memory bus: data copies between controllers/physical memory, and kernel buffers/application space.'"
Which statement accurately describes the cost of interrupt handling?,It is generally inexpensive and simple.,It involves only executing the handler code.,"It is relatively expensive due to state changes, handler execution, and state restoration.",It is more efficient than Programmed I/O (PIO) in all scenarios.,It primarily stresses the network interface card.,C,"The text explicitly mentions: 'Interrupt handling: relatively expensive (state change, execute handler, restore state).'"
Under what condition can Programmed I/O (PIO) be more efficient than interrupt-driven I/O?,When the system is experiencing low I/O demands.,If busy waiting is completely eliminated.,When the amount of data transferred is very large.,If busy waiting is minimized.,When the CPU is dedicated solely to I/O tasks.,D,The text states: 'Programmed I/O (PIO) can be more efficient than interrupt-driven I/O if busy waiting minimized.'
What is a direct consequence of an I/O completion unblocking a process?,Reduced CPU utilization.,Elimination of context switches.,An increase in memory bus bandwidth.,A full context switch overhead.,Improved cache hit rates.,D,The text notes: 'I/O completion unblocks process: leads to full context switch overhead.'
Which of the following activities is known to cause a high context-switch rate?,Intensive CPU computation,Large file transfers via local disk,Network traffic,Memory defragmentation,System boot-up sequence,C,The text states: 'Network traffic: high context-switch rate.'
"In the remote login character example, which component is responsible for receiving the typed character from the keyboard and generating an interrupt?",The user process,The kernel's network layers,The keyboard itself (or its controller),The network device driver,The interrupt handler,C,"The sequence starts with 'character typed -> keyboard interrupt', implying the keyboard hardware/controller generates the initial interrupt."
"During a remote login session, what is a significant overhead observed throughout the process of sending and receiving a character?",Excessive disk I/O operations,Continuous memory page faults,Frequent context switches and state switches,CPU idle time due to waiting for network packets,Graphics rendering delays,C,The text concludes the remote login example with: 'Throughout: context switches and state switches.'
What is the purpose of using separate front-end processors for terminal I/O in some systems?,To increase the main CPU's interrupt burden.,To solely manage network connections.,To reduce the main CPU's interrupt burden.,To perform only mathematical computations.,To act as a secondary storage device.,C,The text states: 'Some systems use separate front-end processors for terminal I/O to reduce main CPU interrupt burden.'
What is a 'terminal concentrator'?,A device that consolidates CPU processing from multiple servers.,A type of front-end processor that multiplexes traffic from hundreds of remote terminals into one port.,A specialized memory unit for high-speed I/O.,A software component that manages display output for terminals.,A network switch for local area networks.,B,The text and glossary define a 'terminal concentrator' as a 'Type of front-end processor for terminals' that 'multiplexes traffic from hundreds of remote terminals into one port.'
What is the primary role of an I/O channel in mainframes and high-end systems?,To handle user interface graphics.,To offload I/O work from the main CPU and ensure smooth data flow.,To manage inter-process communication within the kernel.,To perform general-purpose computing tasks.,To provide power supply redundancy.,B,"The text describes the 'Channel job' as: 'offload I/O work from main CPU, keep data flowing smoothly.' The glossary defines an 'I/O channel' as 'Dedicated, special-purpose CPU in large systems for I/O or offloading main CPU.'"
Which of the following is NOT listed as a principle to improve I/O efficiency?,Reduce number of context switches.,Increase data copies in memory.,Reduce interrupt frequency.,Increase concurrency using DMA-knowledgeable controllers.,"Balance CPU, memory subsystem, bus, I/O performance.",B,"One of the principles listed is to 'Reduce data copies in memory (between device/application)', making 'Increase data copies in memory' the incorrect option."
How can interrupt frequency be reduced to improve I/O efficiency?,By using smaller data transfers.,By decreasing the intelligence of controllers.,By always using interrupt-driven I/O.,"By using large transfers, smart controllers, or polling (if busy waiting minimal).",By increasing the number of context switches.,D,"The text lists: 'Reduce interrupt frequency: use large transfers, smart controllers, polling (if busy waiting minimal).'"
"What is the benefit of increasing concurrency in I/O operations, particularly with DMA-knowledgeable controllers/channels?",It increases the number of CPU interrupts.,It allows the CPU to directly handle all data copying.,It offloads data copying from the CPU.,It reduces the need for specialized hardware.,It simplifies the device driver design.,C,The text states: 'Increase concurrency: use DMA-knowledgeable controllers/channels to offload data copying from CPU.'
"Why is balancing the performance of CPU, memory subsystem, bus, and I/O crucial for system efficiency?",To ensure that one area's overload does not cause idleness in others.,To minimize the total power consumption.,To allow for dynamic clock frequency adjustments.,To simplify the operating system's kernel.,To reduce the physical size of the components.,A,"The text advises to 'Balance CPU, memory subsystem, bus, I/O performance: overload in one area causes idleness in others.'"
Which of the following best describes the complexity of I/O devices?,All I/O devices have uniform complexity.,"I/O device complexity varies greatly, from simple (mouse) to highly complex (Windows disk driver).",Complexity only relates to the physical size of the device.,Complexity is inversely proportional to device speed.,Complexity is determined solely by the amount of data transferred.,B,"The text states: 'I/O device complexity varies (mouse simple, Windows disk driver complex).'"
A Windows disk driver typically performs all of the following functions EXCEPT:,Managing individual disks.,Implementing RAID arrays.,Converting requests to disk I/O.,Directly rendering graphical output to the display.,Error handling and data recovery.,D,"The text lists functions of a Windows disk driver: 'manages individual disks, implements RAID arrays, converts requests to disk I/O, error handling, data recovery, optimizes performance.' Display rendering is not mentioned as its function."
Which of the following represents the typical progression observed when implementing I/O functionality?,Kernel -> Application -> Hardware,Application -> Hardware -> Kernel,Hardware -> Kernel -> Application,Application -> Kernel -> Hardware,Kernel -> Hardware -> Application,D,The text describes the progression as: 'Initially: experimental I/O algorithms at application level. -> When proven: reimplement in kernel. -> Highest performance: specialized implementation in hardware (device or controller).'
What is a disadvantage of implementing experimental I/O algorithms at the application level?,Bugs are likely to crash the entire system.,It requires frequent reboots and driver reloads after code changes.,It is generally less flexible compared to kernel implementation.,It is inefficient due to context switch overhead and lack of kernel access.,It provides the highest possible performance.,D,"The text lists disadvantages of application level implementation: 'Inefficient: context switch overhead, no internal kernel data/functionality (messaging, threading, locking).'"
What is a primary benefit of reimplementing proven I/O algorithms from the application level into the kernel?,It makes development easier and faster.,It improves system performance.,It eliminates the need for debugging.,It reduces the complexity of the kernel.,It allows user processes to directly access hardware.,B,The text states that reimplementation in kernel 'Improves performance.'
"What is a major drawback of implementing I/O functionality at the specialized hardware level (e.g., a device or controller)?",It offers lower performance than software implementations.,It significantly decreases development time.,It is flexible and allows kernel influence over I/O order.,"Difficulty and expense of improvements/bug fixes, and decreased flexibility.",It increases context switch overhead.,D,"The text lists disadvantages of hardware implementation: 'Disadvantages: difficulty/expense of improvements/bug fixes. ... Decreased flexibility (e.g., hardware RAID controller may not allow kernel to influence I/O order/location).'"
"Which of the following I/O technologies is nearing DRAM speeds, increasing pressure on I/O subsystems?",Hard Disk Drives (HDD),Solid-State Drives (SSD),Non-Volatile Memory (NVM) devices,Peripheral Component Interconnect Express (PCIe),Small Computer System Interface (SCSI),C,The text states: 'I/O devices increasing in speed (NVM devices nearing DRAM speed).'
Front-end processors are best described as:,The main CPU of a system.,Small computers that manage I/O and offload the main CPU.,Graphics processing units (GPUs).,Memory modules used for caching.,Network interface cards (NICs).,B,"The glossary defines 'front-end processors' as 'Small computers performing tasks in overall system; manage I/O, offload CPU.'"
Which of the following correctly identifies the basic hardware elements of an I/O system?,"CPUs, RAM, and hard drives","Buses, device controllers, and devices","Operating systems, applications, and networks","Keyboards, mice, and monitors","File systems, directories, and files",B,"The text explicitly states that 'Basic I/O hardware elements' are 'buses, device controllers, devices'."
Data movement for I/O operations can be managed by which two primary mechanisms?,User applications or network protocols,System calls or library functions,CPU (programmed I/O) or DMA controller,Interrupt handlers or signal processors,Caching mechanisms or buffering techniques,C,The text indicates 'Data movement: CPU (programmed I/O) or DMA controller'.
What is a device driver primarily defined as?,A user-level application for hardware diagnostics,A kernel module responsible for controlling a specific device,A hardware component that manages I/O operations,A network protocol used for device communication,A file system component for storing device configurations,B,The text defines 'Device driver' as a 'kernel module controlling a device'.
Which of the following is NOT listed as a basic hardware category handled by the system-call interface?,Block devices,Network sockets,Character-stream devices,Graphics processing units (GPUs),Programmed interval timers,D,"The text lists 'block devices, character-stream devices, memory-mapped files, network sockets, programmed interval timers' as categories handled by the system-call interface. GPUs are not mentioned."
What is the typical behavior of system calls in relation to the process that invokes them?,They always execute in parallel with the process.,They usually block the process until completion.,They immediately return control to the process without waiting.,They always trigger an error if the process tries to sleep.,They are exclusively handled by user-level libraries.,B,The text mentions 'System calls usually block processes'.
Under what circumstances are nonblocking or asynchronous system calls typically used?,To ensure maximum process sleep time,For applications that require user interaction to pause,When kernel/applications must not sleep,To simplify the process of context switching,Only for non-critical background tasks,C,The text states 'nonblocking/asynchronous calls used by kernel/applications that must not sleep'.
Which of the following is a service provided by the kernel's I/O subsystem?,User interface design,I/O scheduling,Database indexing,Web server management,Application compilation,B,The text lists 'I/O scheduling' as one of the services provided by the kernel's I/O subsystem.
The kernel's I/O subsystem provides a comprehensive set of services. Which of the following lists accurately represents some of these services?,"Process creation, memory allocation, and CPU scheduling","File encryption, network routing, and graphic rendering","I/O scheduling, buffering, and error handling","User authentication, printer configuration, and sound mixing","Device driver development, application debugging, and system backup",C,"The text explicitly lists 'I/O scheduling, buffering, caching, spooling, device reservation, error handling' as services provided by the kernel's I/O subsystem. Option C correctly includes three of these."
What is the primary purpose of 'Name translation' in the context of I/O?,To convert binary data into human-readable text.,To connect hardware devices to symbolic file names.,To translate network addresses into IP addresses.,To encrypt and decrypt data for security purposes.,To optimize the performance of CPU caches.,B,The text states 'Name translation: connects hardware devices to symbolic file names'.
Name translation for I/O devices involves multiple mapping levels. Which sequence best describes these levels?,Physical addresses → character-string names → device drivers/addresses,Device drivers/addresses → physical addresses → character-string names,Character-string names → physical addresses → device drivers/addresses,Character-string names → device drivers/addresses → physical addresses,Physical addresses → device drivers/addresses → character-string names,D,The text specifies the mapping levels as 'character-string names → device drivers/addresses → physical addresses (I/O ports/bus controllers)'.
"Where can device name mapping occur, according to the provided text?",Only within the file-system name space (UNIX),Only within a separate device name space (MS-DOS),Within the file-system name space (UNIX) or a separate device name space (MS-DOS),Exclusively in the kernel's memory space,"Only at the hardware level, independent of the operating system",C,The text states 'Mapping can be within file-system name space (UNIX) or separate device name space (MS-DOS)'.
What is 'STREAMS' in the context of UNIX systems?,A method for inter-process communication via shared memory,A mechanism for dynamic assembly of driver code pipelines,A specific type of network file system protocol,A utility for managing background processes,A command-line interpreter for system administration,B,The text defines 'STREAMS' as a 'UNIX mechanism for dynamic assembly of driver code pipelines'.
"When drivers are stacked using mechanisms like STREAMS, how does data typically flow?","Only in one direction, from top to bottom",Randomly jumping between stacked drivers,Sequentially and bidirectionally,In parallel streams that merge at the end,Only during the initialization phase,C,"The text notes that when drivers are stacked, 'data passes sequentially and bidirectionally'."
"Which of the following is identified as a primary cost associated with I/O system calls, specifically due to crossing the kernel protection boundary?",Increased network latency,Context switching,Disk defragmentation,Memory leak detection,User interface rendering,B,The text lists 'Context switching (kernel protection boundary)' as a cost of I/O system calls.
A significant CPU/memory load cost associated with I/O system calls comes from what operation?,Frequent CPU clock frequency adjustments,Dynamic memory allocation for user applications,Data copying between kernel buffers and application space,Execution of graphics rendering pipelines,Pre-fetching instructions for future execution,C,The text explicitly states 'CPU/memory load for data copying (kernel buffers ↔ application space)' as a cost.
"Besides context switching and data copying, what other factor contributes to the high cost of I/O system calls?",The need for physical device maintenance,User-level library function calls,Signal/interrupt handling,Compiler optimization levels,The size of the system's hard drive,C,The text lists 'Signal/interrupt handling' as another factor contributing to the cost of I/O system calls.
