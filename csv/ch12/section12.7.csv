Question,Option A,Option B,Option C,Option D,Option E,Answer,Explanation
Which of the following is identified as a major factor significantly impacting overall system performance?,CPU clock speed,Memory bus bandwidth,I/O operations,GPU processing power,Disk storage capacity,C,The text explicitly states: 'I/O: major factor in system performance.'
Heavy demands on the CPU due to I/O primarily involve which two activities?,Executing user application code and managing virtual memory,Performing floating-point calculations and handling network protocols,Executing device-driver code and scheduling processes (block/unblock),Managing file system access and caching frequently used data,Initializing hardware components and monitoring system temperature,C,"The text states that heavy I/O demands on the CPU include 'execute device-driver code, schedule processes (block/unblock).'"
What is the primary effect of context switches on system resources?,They reduce memory consumption by flushing caches.,They stress the CPU and hardware caches.,They eliminate the need for interrupt handling.,They always improve system throughput.,They increase network latency.,B,The text indicates: 'Context switches: stress CPU and hardware caches.'
How do data copies between controllers/physical memory and kernel buffers/application space impact the system?,They reduce the overall system latency.,They offload work from the main CPU.,They improve the efficiency of interrupt handling.,They load the memory bus.,They directly increase CPU clock speed.,D,"The text states: 'Loads memory bus: data copies between controllers/physical memory, and kernel buffers/application space.'"
Which statement accurately describes the cost of interrupt handling?,It is generally inexpensive and simple.,It involves only executing the handler code.,"It is relatively expensive due to state changes, handler execution, and state restoration.",It is more efficient than Programmed I/O (PIO) in all scenarios.,It primarily stresses the network interface card.,C,"The text explicitly mentions: 'Interrupt handling: relatively expensive (state change, execute handler, restore state).'"
Under what condition can Programmed I/O (PIO) be more efficient than interrupt-driven I/O?,When the system is experiencing low I/O demands.,If busy waiting is completely eliminated.,When the amount of data transferred is very large.,If busy waiting is minimized.,When the CPU is dedicated solely to I/O tasks.,D,The text states: 'Programmed I/O (PIO) can be more efficient than interrupt-driven I/O if busy waiting minimized.'
What is a direct consequence of an I/O completion unblocking a process?,Reduced CPU utilization.,Elimination of context switches.,An increase in memory bus bandwidth.,A full context switch overhead.,Improved cache hit rates.,D,The text notes: 'I/O completion unblocks process: leads to full context switch overhead.'
Which of the following activities is known to cause a high context-switch rate?,Intensive CPU computation,Large file transfers via local disk,Network traffic,Memory defragmentation,System boot-up sequence,C,The text states: 'Network traffic: high context-switch rate.'
"In the remote login character example, which component is responsible for receiving the typed character from the keyboard and generating an interrupt?",The user process,The kernel's network layers,The keyboard itself (or its controller),The network device driver,The interrupt handler,C,"The sequence starts with 'character typed -> keyboard interrupt', implying the keyboard hardware/controller generates the initial interrupt."
"During a remote login session, what is a significant overhead observed throughout the process of sending and receiving a character?",Excessive disk I/O operations,Continuous memory page faults,Frequent context switches and state switches,CPU idle time due to waiting for network packets,Graphics rendering delays,C,The text concludes the remote login example with: 'Throughout: context switches and state switches.'
What is the purpose of using separate front-end processors for terminal I/O in some systems?,To increase the main CPU's interrupt burden.,To solely manage network connections.,To reduce the main CPU's interrupt burden.,To perform only mathematical computations.,To act as a secondary storage device.,C,The text states: 'Some systems use separate front-end processors for terminal I/O to reduce main CPU interrupt burden.'
What is a 'terminal concentrator'?,A device that consolidates CPU processing from multiple servers.,A type of front-end processor that multiplexes traffic from hundreds of remote terminals into one port.,A specialized memory unit for high-speed I/O.,A software component that manages display output for terminals.,A network switch for local area networks.,B,The text and glossary define a 'terminal concentrator' as a 'Type of front-end processor for terminals' that 'multiplexes traffic from hundreds of remote terminals into one port.'
What is the primary role of an I/O channel in mainframes and high-end systems?,To handle user interface graphics.,To offload I/O work from the main CPU and ensure smooth data flow.,To manage inter-process communication within the kernel.,To perform general-purpose computing tasks.,To provide power supply redundancy.,B,"The text describes the 'Channel job' as: 'offload I/O work from main CPU, keep data flowing smoothly.' The glossary defines an 'I/O channel' as 'Dedicated, special-purpose CPU in large systems for I/O or offloading main CPU.'"
Which of the following is NOT listed as a principle to improve I/O efficiency?,Reduce number of context switches.,Increase data copies in memory.,Reduce interrupt frequency.,Increase concurrency using DMA-knowledgeable controllers.,"Balance CPU, memory subsystem, bus, I/O performance.",B,"One of the principles listed is to 'Reduce data copies in memory (between device/application)', making 'Increase data copies in memory' the incorrect option."
How can interrupt frequency be reduced to improve I/O efficiency?,By using smaller data transfers.,By decreasing the intelligence of controllers.,By always using interrupt-driven I/O.,"By using large transfers, smart controllers, or polling (if busy waiting minimal).",By increasing the number of context switches.,D,"The text lists: 'Reduce interrupt frequency: use large transfers, smart controllers, polling (if busy waiting minimal).'"
"What is the benefit of increasing concurrency in I/O operations, particularly with DMA-knowledgeable controllers/channels?",It increases the number of CPU interrupts.,It allows the CPU to directly handle all data copying.,It offloads data copying from the CPU.,It reduces the need for specialized hardware.,It simplifies the device driver design.,C,The text states: 'Increase concurrency: use DMA-knowledgeable controllers/channels to offload data copying from CPU.'
"Why is balancing the performance of CPU, memory subsystem, bus, and I/O crucial for system efficiency?",To ensure that one area's overload does not cause idleness in others.,To minimize the total power consumption.,To allow for dynamic clock frequency adjustments.,To simplify the operating system's kernel.,To reduce the physical size of the components.,A,"The text advises to 'Balance CPU, memory subsystem, bus, I/O performance: overload in one area causes idleness in others.'"
Which of the following best describes the complexity of I/O devices?,All I/O devices have uniform complexity.,"I/O device complexity varies greatly, from simple (mouse) to highly complex (Windows disk driver).",Complexity only relates to the physical size of the device.,Complexity is inversely proportional to device speed.,Complexity is determined solely by the amount of data transferred.,B,"The text states: 'I/O device complexity varies (mouse simple, Windows disk driver complex).'"
A Windows disk driver typically performs all of the following functions EXCEPT:,Managing individual disks.,Implementing RAID arrays.,Converting requests to disk I/O.,Directly rendering graphical output to the display.,Error handling and data recovery.,D,"The text lists functions of a Windows disk driver: 'manages individual disks, implements RAID arrays, converts requests to disk I/O, error handling, data recovery, optimizes performance.' Display rendering is not mentioned as its function."
Which of the following represents the typical progression observed when implementing I/O functionality?,Kernel -> Application -> Hardware,Application -> Hardware -> Kernel,Hardware -> Kernel -> Application,Application -> Kernel -> Hardware,Kernel -> Hardware -> Application,D,The text describes the progression as: 'Initially: experimental I/O algorithms at application level. -> When proven: reimplement in kernel. -> Highest performance: specialized implementation in hardware (device or controller).'
What is a disadvantage of implementing experimental I/O algorithms at the application level?,Bugs are likely to crash the entire system.,It requires frequent reboots and driver reloads after code changes.,It is generally less flexible compared to kernel implementation.,It is inefficient due to context switch overhead and lack of kernel access.,It provides the highest possible performance.,D,"The text lists disadvantages of application level implementation: 'Inefficient: context switch overhead, no internal kernel data/functionality (messaging, threading, locking).'"
What is a primary benefit of reimplementing proven I/O algorithms from the application level into the kernel?,It makes development easier and faster.,It improves system performance.,It eliminates the need for debugging.,It reduces the complexity of the kernel.,It allows user processes to directly access hardware.,B,The text states that reimplementation in kernel 'Improves performance.'
"What is a major drawback of implementing I/O functionality at the specialized hardware level (e.g., a device or controller)?",It offers lower performance than software implementations.,It significantly decreases development time.,It is flexible and allows kernel influence over I/O order.,"Difficulty and expense of improvements/bug fixes, and decreased flexibility.",It increases context switch overhead.,D,"The text lists disadvantages of hardware implementation: 'Disadvantages: difficulty/expense of improvements/bug fixes. ... Decreased flexibility (e.g., hardware RAID controller may not allow kernel to influence I/O order/location).'"
"Which of the following I/O technologies is nearing DRAM speeds, increasing pressure on I/O subsystems?",Hard Disk Drives (HDD),Solid-State Drives (SSD),Non-Volatile Memory (NVM) devices,Peripheral Component Interconnect Express (PCIe),Small Computer System Interface (SCSI),C,The text states: 'I/O devices increasing in speed (NVM devices nearing DRAM speed).'
Front-end processors are best described as:,The main CPU of a system.,Small computers that manage I/O and offload the main CPU.,Graphics processing units (GPUs).,Memory modules used for caching.,Network interface cards (NICs).,B,"The glossary defines 'front-end processors' as 'Small computers performing tasks in overall system; manage I/O, offload CPU.'"
