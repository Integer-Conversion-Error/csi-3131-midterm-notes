"What is the primary purpose of a computer system, and what must be true about programs and data during execution?",To manage networks; all programs and data must reside on external storage.,To execute programs; programs and data must be entirely in main memory.,To manage CPU scheduling; programs and data must be partially in main memory.,To execute programs; programs and data must be partially in main memory.,To store data; programs and data must be entirely on disk.,D,"The main purpose of a computer system is to execute programs, and during execution, programs and data must be partially in main memory."
Which of the following is true about modern computer systems regarding memory management?,They can only maintain one process in memory at a time.,Memory-management schemes are universal and do not vary.,Most memory management algorithms require specific software support only.,They maintain several processes concurrently in memory.,Memory management is solely handled by the user applications.,D,Modern systems are designed to maintain several processes in memory concurrently to improve CPU utilization and response speed.
What improves CPU utilization and response speed in a modern operating system?,Reducing the number of processes in memory.,Strictly limiting access to main memory.,"CPU Scheduling, which requires keeping many processes in memory.",Disabling hardware support for memory management.,Using only static linking for all programs.,C,"CPU Scheduling improves CPU utilization and response speed, and this requires keeping many processes in memory, necessitating memory sharing."
Which two general-purpose storage locations can the CPU access directly?,Hard disk and solid-state drive.,Main memory and registers.,Cache and external USB drives.,Network storage and CD-ROM.,Optical drives and magnetic tapes.,B,The CPU can only access instructions and data directly from main memory and registers.
How do access times for registers and main memory compare?,"Main memory is accessible within one CPU clock cycle, while registers take many cycles.",Registers and main memory have identical access times.,"Registers are accessible within one CPU clock cycle, while main memory may take many CPU cycles.",Access to main memory is faster than registers due to the memory bus.,Registers are slower than main memory because they are on the CPU chip.,C,"Registers are much faster, accessible within one CPU clock cycle, while main memory access via the memory bus can take many CPU cycles."
What is a 'stall' in the context of CPU operation?,A condition where the CPU runs at maximum speed.,"A state where the CPU is waiting for data from main memory, delaying execution.",An error that causes the CPU to halt permanently.,A process of transferring data between the CPU and registers.,A temporary increase in CPU clock speed to enhance performance.,B,"A 'stall' occurs when the CPU is forced to wait for data, typically from main memory, which delays its execution."
"What is the primary remedy for a CPU stall, and how is it managed?",Increasing the CPU clock speed; managed by the operating system.,Adding more main memory; managed by user programs.,Adding a fast memory called 'cache' between the CPU and main memory; managed automatically by hardware.,Implementing dynamic loading; managed by the application.,Using a faster memory bus; managed by the OS through privileged instructions.,C,"The remedy for a CPU stall is to add a fast memory called 'cache' between the CPU and main memory, and cache management is typically handled automatically by hardware with no OS control."
Why is memory protection necessary in a modern operating system?,To prevent unauthorized access to the CPU's registers.,To ensure that user processes can modify the operating system's code directly.,To protect the operating system from user processes and user processes from each other.,To allow all processes to share the same memory space without any restrictions.,To slow down memory access for security reasons.,C,"Memory protection is crucial for correct operation, protecting the OS from accidental or deliberate modification by user processes, and protecting user processes from each other."
How is memory protection typically implemented at the hardware level?,Through software-only checks by the operating system.,By assigning unique identifiers to each byte of memory.,Using a base register to store the smallest legal physical address and a limit register to store the size of the range.,By encrypting all memory contents to prevent unauthorized access.,By physically separating memory modules for different processes.,C,Memory protection is implemented by hardware using a base register to define the smallest legal physical memory address and a limit register to define the size of the legal address range.
What is the function of a base register in memory protection?,It defines the maximum legal physical memory address.,It stores the size of the memory region allocated to a process.,"It holds the starting address of an address space, representing the smallest legal physical memory address for a process.",It's used to store the last accessed memory address.,It manages the cache memory.,C,"The base register is a CPU register that holds the starting address of an address space, defining the smallest legal physical memory address for a process."
"What happens if a CPU, in user mode, attempts to access a memory address outside the range defined by its base and limit registers?",The access is silently redirected to a safe memory area.,"The operation completes successfully, but a warning is logged.",The CPU automatically adjusts the base and limit registers.,"A trap is generated to the operating system, indicating a fatal error.",The process is paused until the user manually corrects the address.,D,"An attempt to access memory outside the legal range defined by the base and limit registers results in a trap to the operating system, which treats it as a fatal error."
"Who is responsible for loading the base and limit registers, and what kind of instruction is used?",Any user process using a standard instruction.,The CPU hardware automatically during boot-up.,The operating system using a privileged instruction while in kernel mode.,The compiler during program compilation.,The linker/loader during program loading.,C,"The base and limit registers can only be loaded by the operating system using a privileged instruction while in kernel mode, ensuring proper memory protection."
Which of the following describes the sequence of address binding in a user program before execution?,Relocatable to symbolic to absolute.,Absolute to relocatable to symbolic.,Symbolic to absolute to relocatable.,Symbolic to relocatable to absolute.,Physical to logical to virtual.,D,"Addresses are initially symbolic in the source program, then the compiler binds them to relocatable addresses, and finally, the linker/loader binds relocatable addresses to absolute addresses."
What is 'binding' in the context of address management?,The process of compiling source code into an executable.,"The act of tying together different address spaces, such as symbolic to relocatable or relocatable to absolute.",The encryption of memory addresses for security.,The allocation of physical memory to a process.,The operation of moving data between cache and main memory.,B,"Binding refers to the process of tying together or mapping addresses from one address space to another, for example, from symbolic to relocatable or relocatable to absolute."
"Under what condition is 'absolute code' generated, and what type of address binding does it represent?",When the process can move during execution; execution-time binding.,When the process location is unknown at compile time; load-time binding.,When the process location is known at compile time; compile-time binding.,When dynamic loading is used; run-time binding.,When a relocation register is used; logical address binding.,C,"Absolute code is generated at compile time if the process's location in memory is known beforehand, representing compile-time binding."
When is 'relocatable code' typically generated?,Only when dynamic linking is employed.,If the process location in memory is unknown at compile time.,If the process location is fixed at compile time.,When the program is too large to fit in physical memory.,During the execution-time binding process.,B,Relocatable code is generated by the compiler if the process's location in main memory is not known until load time.
What is 'execution-time binding' used for?,When the program's memory location is fixed at compile time.,When the program's memory location is fixed at load time.,When the process can be moved in memory during its execution.,When static linking is preferred over dynamic linking.,When the program uses only registers for data storage.,C,"Execution-time binding is employed when the process can be moved around in memory during its execution, delaying the binding until run time."
What is the key difference between a logical address and a physical address?,"A logical address is seen by the memory unit, while a physical address is generated by the CPU.","A logical address is specific to the hardware, while a physical address is software-defined.",A logical address is generated by the CPU and translated before use; a physical address is the actual location in memory.,Logical and physical addresses are always identical in modern systems.,"A logical address refers to disk storage, while a physical address refers to main memory.",C,"A logical address is an address generated by the CPU, which is then translated by hardware to a physical address, which is the actual location in main memory."
"In the context of address binding, when do logical and physical addresses differ?","Always, as a fundamental principle of memory management.",Only when compile-time binding is used.,When execution-time binding is employed.,Only when load-time binding is used.,They never differ; they are just different names for the same thing.,C,"Logical and physical addresses differ when execution-time binding is used, meaning the process can be moved during execution, requiring run-time translation."
What is a 'virtual address' a synonym for?,Physical address.,Absolute address.,Logical address.,Relocatable address.,Symbolic address.,C,A logical address is also commonly referred to as a virtual address.
What hardware component is responsible for run-time mapping of virtual to physical addresses?,The CPU's arithmetic logic unit (ALU).,The hard disk controller.,The memory-management unit (MMU).,The graphics processing unit (GPU).,The network interface card (NIC).,C,The memory-management unit (MMU) is the hardware component responsible for translating logical (virtual) addresses to physical addresses at run time.
"In a simple MMU scheme, what is added to every address generated by a user process to create the physical address?",The value in the limit register.,The value in the program counter.,The value in the instruction register.,The value in the relocation register.,The base address of the operating system.,D,"In a simple MMU scheme, the value in the relocation register (a generalization of the base register) is added to every logical address generated by the user process to produce the physical address."
"From the perspective of a user program, what type of addresses does it typically deal with?",Only physical addresses directly.,"Real physical addresses, which it generates and accesses.","Logical addresses, with the memory-mapping hardware converting them to physical addresses.","Relocatable addresses, which are then manually converted to physical addresses.","Only symbolic addresses, without any direct interaction with memory locations.",C,A user program typically deals with logical addresses; it never accesses real physical addresses directly. The memory-mapping hardware (MMU) converts these logical addresses to physical ones.
What is 'dynamic loading' and what is its primary advantage?,"Loading the entire program into memory at process start, limiting process size.","Loading program routines only when they are called, improving memory-space utilization.",Loading data from a network drive instead of local storage.,The process of updating program code while it is running.,Loading system libraries at compile time to create a single executable.,B,"Dynamic loading means that a routine is not loaded until it is called. Its advantage is better memory-space utilization because routines are loaded only when needed, especially useful for large programs with infrequently used code."
Does dynamic loading typically require special operating system support?,"Yes, it is entirely managed by the OS.","No, it is primarily the responsibility of the user program.","Only for large programs, otherwise it's user responsibility.","It depends on the type of CPU, not the OS.","It requires special hardware, not OS support.",B,"Dynamic loading generally does not require any special operating system support; it is the responsibility of the user program to implement it, though the OS may provide library routines to help."
What are Dynamically Linked Libraries (DLLs) and when are they linked to user programs?,System libraries combined with user programs by the loader at compile time.,User-defined libraries that are linked manually by the developer.,"System libraries that are linked to user programs at run time, with linking postponed until execution.",Obsolete libraries no longer used in modern systems.,Libraries stored on a network drive and accessed remotely.,C,"Dynamically Linked Libraries (DLLs) are system libraries that are linked to user programs at run time, meaning the linking process is postponed until execution time."
What is a major advantage of using Dynamically Linked Libraries (DLLs) over static linking?,DLLs always result in larger executable file sizes.,DLLs provide better debugging capabilities for individual programs.,"DLLs allow system libraries to be shared among multiple processes, saving main memory.",Static linking offers better performance due to faster loading times.,DLLs make programs less portable across different operating systems.,C,"A significant advantage of DLLs (also known as shared libraries) is that they can be loaded once into memory and shared by multiple processes, which saves main memory space compared to static linking where each program has its own copy."
How do Dynamically Linked Libraries (DLLs) typically handle library updates and incompatible versions?,All programs must be recompiled and relinked manually when a DLL is updated.,"DLLs ignore version information, leading to potential crashes.","Programs use version information to ensure compatibility, and multiple versions of a library can be loaded concurrently.",DLLs are never updated once released to prevent compatibility issues.,Only programs compiled with the old library version can use the updated DLL.,C,"DLLs use version information to prevent incompatibilities. Multiple versions of a library can be loaded, and programs will use the version they were linked with. New versions only affect programs compiled with them, while older programs continue using older versions."
What is 'static linking'?,Linking that occurs only at execution time.,The process where system libraries are loaded dynamically when a routine is called.,A linking method where system libraries are combined by the loader into the binary program image.,A technique to move programs in memory during execution.,A method of memory management that uses a relocation register.,C,"Static linking is a linking method where system libraries are treated like object modules and combined by the loader into the final binary program image, meaning they become part of the executable file."
Does dynamic linking and the use of shared libraries generally require operating system help?,"No, it's entirely managed by the application program.","Yes, especially if processes are protected and need to access shared memory addresses.","Only for single-user systems, not multi-user.",Only if there is no cache memory present.,It depends on the amount of physical memory available.,B,"Dynamic linking and shared libraries generally require OS help, particularly if processes are protected, as the OS needs to check if a routine is already in another process's memory and allow multiple processes to access the same addresses."
"Which term describes a CPU state where it is waiting for data from main memory, causing delays in execution?",Cache hit,Bind,Stall,Trap,Relocation,C,"A 'stall' is defined as a CPU state when the CPU is waiting for data from main memory, which delays execution."
What is a 'cache' used for in a computer system?,To permanently store large datasets for archiving.,As a temporary copy of data in a reserved memory area to improve performance.,To convert logical addresses to physical addresses.,To manage network traffic between devices.,To perform arithmetic operations very quickly.,B,"A 'cache' is a temporary copy of data in a reserved memory area, strategically placed (like between CPU and main memory) to improve performance by reducing access times."
"In contiguous memory allocation, what is the fundamental characteristic of how each process is stored in main memory?",Each process is divided into multiple non-contiguous segments.,"Each process resides in a single, unbroken section of memory.","Processes are stored in fixed-size blocks, regardless of their actual size.","Memory is dynamically allocated to processes as needed, without fixed partitions.",Processes share a single memory partition to maximize utilization.,B,Contiguous memory allocation is defined as a method where each process is in a single contiguous memory section.
Main memory in a system using contiguous memory allocation is typically divided into two partitions. What do these two partitions accommodate?,"One for user data, one for system files.","One for active processes, one for swapped-out processes.","One for the operating system, one for user processes.","One for kernel modules, one for device drivers.","One for read-only memory, one for read-write memory.",C,"The text states: 'Memory usually divided into two partitions: one for OS, one for user processes.'"
"In many modern operating systems, including Linux and Windows, where is the operating system typically accommodated within main memory?",In low memory.,In high memory.,In the middle of user processes.,Dynamically partitioned across all memory.,Swapped in and out as needed.,B,"The text specifies: 'OS can be in low or high memory (many OS, including Linux/Windows, use high memory).'"
What is the primary goal of memory protection in a contiguous memory allocation scheme?,To optimize memory access speed.,To prevent a process from accessing memory that does not belong to it.,To allow dynamic resizing of memory partitions.,To facilitate efficient context switching between processes.,To ensure all memory is fully utilized at all times.,B,Memory protection's purpose is to 'Prevent process from accessing unowned memory.'
Which two registers are combined to implement memory protection in a system using contiguous memory allocation?,Program Counter and Stack Pointer.,Instruction Register and Memory Buffer Register.,Relocation Register and Limit Register.,Base Register and Index Register.,Segment Register and Offset Register.,C,Memory protection is implemented by combining a 'relocation register (smallest physical address) and limit register (range of logical addresses).'
"In the context of memory protection, what information does the 'relocation register' hold?",The largest physical address a process can access.,The range of logical addresses for a process.,The smallest physical address where a process's memory segment begins.,The current size of the operating system.,The address of the next instruction to be executed.,C,The relocation register stores the 'smallest physical address'.
How does the Memory Management Unit (MMU) dynamically map a logical address to a physical address using the relocation-register scheme?,It subtracts the limit register value from the logical address.,It multiplies the logical address by the relocation register value.,It adds the relocation register value to the logical address.,It divides the logical address by the limit register value.,It uses a lookup table to find the corresponding physical address.,C,The MMU maps logical addresses dynamically by 'adding relocation register value'.
When are the relocation and limit registers updated in a system utilizing this memory protection scheme?,Once at system startup and remain fixed.,Periodically by the operating system kernel.,During every CPU instruction fetch.,By the CPU scheduler during each context switch.,Only when a new process is loaded into memory.,D,The 'CPU scheduler loads relocation and limit registers during context switch'.
A significant benefit of the relocation-register scheme is its ability to allow what regarding the operating system?,For the OS to run entirely from read-only memory.,For the OS to be swapped out to disk when not in use.,For the OS size to change dynamically.,For the OS to reside in low memory exclusively.,For the OS to share memory partitions with user processes freely.,C,The 'Relocation-register scheme allows dynamic OS size changes'.
Which of the following is characteristic of the 'variable-partition' memory-allocation scheme?,Memory is divided into fixed-size partitions beforehand.,Each memory partition contains exactly one process.,Processes can occupy multiple non-contiguous partitions.,Only one process can reside in memory at a time.,The size of partitions is determined by the largest process.,B,The definition states: 'Each partition contains exactly one process (variable-partition scheme).'
"In a variable-partition memory allocation scheme, what is a 'hole'?",A section of memory reserved for the operating system.,A contiguous section of unused memory available for allocation.,"A small, fixed-size block of memory allocated to a process.",An area of memory currently being used by a terminated process.,A buffer used for inter-process communication.,B,A 'hole' is defined as 'a contiguous section of unused memory'.
What is the initial state of memory available for user processes in a variable-partition scheme?,It is completely occupied by a dummy process.,"It contains many small, scattered holes.","It consists of a single large block, known as a 'hole'.",It is divided into a predetermined number of fixed-size partitions.,It is entirely allocated to the operating system.,C,"Initially: 'all memory available for user processes, one large block (hole).'"
The challenge of satisfying a memory request of a given size from a list of free holes is an instance of what problem?,The producer-consumer problem.,The synchronization problem.,The dynamic storage-allocation problem.,The critical section problem.,The dining philosophers problem.,C,The text states: 'This procedure: instance of dynamic storage-allocation problem.'
Which memory allocation strategy involves allocating the first hole in the list that is large enough to satisfy the memory request?,Best-fit,Worst-fit,First-fit,Next-fit,Optimal-fit,C,First-fit is defined as: 'Allocate first hole big enough.'
"Which memory allocation strategy searches the entire list of free holes to find the smallest hole that is large enough for the request, often resulting in the smallest leftover hole?",First-fit,Worst-fit,Best-fit,Round-robin,Least-fit,C,Best-fit is defined as: 'Allocate smallest hole big enough. ... Produces smallest leftover hole.'
The 'Worst-fit' memory allocation strategy is characterized by selecting which type of hole for allocation?,The smallest hole that is big enough.,"The first available hole, regardless of size.",The hole that has been free for the longest time.,The largest available hole.,The hole closest to the operating system's memory partition.,D,Worst-fit is defined as: 'Allocate largest hole.'
"According to simulations, which memory allocation strategies are generally considered better than 'worst-fit' in terms of decreasing time and storage utilization?",Only First-fit.,Only Best-fit.,Both First-fit and Best-fit.,Random-fit and Next-fit.,All three strategies perform similarly.,C,"Simulations show: 'first-fit and best-fit better than worst-fit (decreasing time, storage utilization).'"
"Regarding storage utilization, what is the comparative performance between 'first-fit' and 'best-fit' strategies?",Best-fit is always superior for storage utilization.,First-fit is always superior for storage utilization.,"Neither is clearly better for storage utilization, but first-fit is generally faster.",Both strategies result in identical storage utilization.,Storage utilization is not a relevant metric for these strategies.,C,"'Neither first-fit nor best-fit clearly better for storage utilization, but first-fit generally faster.'"
"Which type of memory fragmentation occurs when there is enough total free memory to satisfy a request, but it is broken into many small, non-contiguous pieces?",Internal fragmentation.,Paging fragmentation.,External fragmentation.,Compaction fragmentation.,Process fragmentation.,C,"External fragmentation is defined as: 'enough total memory, but spaces not contiguous (storage fragmented).'"
Both the 'First-fit' and 'Best-fit' memory allocation strategies are known to suffer from which specific problem?,Internal fragmentation.,Excessive context switching.,External fragmentation.,Memory leaks.,Thrashing.,C,'First-fit and best-fit suffer from external fragmentation.'
What is 'internal fragmentation' in the context of memory management?,Memory that is free but cannot be allocated due to being too small.,Memory that is wasted between different processes.,Unused memory located within an allocated memory partition.,Memory that is used by the operating system for its own overhead.,The process of breaking down a large memory block into smaller ones.,C,Internal fragmentation is defined as: 'unused memory internal to a partition.'
Internal fragmentation typically occurs under which condition?,When memory is compacted to combine free space.,When the allocated memory block is slightly larger than the requested memory.,When a process attempts to access memory outside its allocated range.,When the system runs out of free memory altogether.,When processes are frequently swapped in and out of memory.,B,"It 'Occurs when allocated memory slightly larger than requested (e.g., fixed-sized blocks).'"
What is the primary solution proposed to address the problem of external fragmentation?,Increasing the total amount of physical memory.,Using a fixed-partition allocation scheme.,Implementing a compaction process.,Reducing the number of concurrent user processes.,Employing virtual memory techniques like swapping.,C,The 'Solution to external fragmentation: compaction.'
What is the main goal of 'compaction' in memory management?,To reduce the overall memory footprint of the operating system.,"To shuffle memory contents to consolidate all free memory into one large, contiguous block.",To reallocate memory to processes based on their priority.,To convert internal fragmentation into external fragmentation.,To identify and remove corrupted memory blocks.,B,"Compaction's 'Goal: shuffle memory contents, place all free memory together in one large block.'"
Compaction is only possible if what characteristic of memory relocation is present?,If relocation is static (assembly or load time).,If relocation is dynamic (execution time).,If memory is physically non-contiguous.,If the system uses fixed-size memory blocks.,If the operating system runs in low memory.,B,Compaction is 'Possible only if relocation dynamic (execution time).'
"The '50-percent rule' in the context of memory fragmentation, particularly with first-fit, suggests what outcome?",Fifty percent of memory requests will be denied due to lack of space.,Fifty percent of the allocated memory blocks are wasted.,Approximately one-third of memory may become unusable due to fragmentation.,Memory utilization will never exceed 50 percent.,Processes will only ever use 50% of their allocated memory.,C,The '50-percent rule' states: 'one-third of memory unusable.'
"What alternative solution to external fragmentation allows a process's logical address space to be noncontiguous, enabling it to be allocated physical memory wherever available?",Compaction.,The variable-partition scheme.,The best-fit allocation strategy.,Paging.,Fixed-size partitions.,D,Another solution to external fragmentation is to 'permit noncontiguous logical address space. ... Strategy used in paging'.
Which memory-management technique is described as the 'most common' and allows processes to be allocated physical memory in a noncontiguous manner?,Contiguous memory allocation.,Variable-partition scheme.,Compaction.,Paging.,Segmentation.,D,Paging is described as the 'most common memory-management technique' and allows noncontiguous physical memory allocation.
Which of the following best defines 'Paging' in the context of memory management?,A scheme that allocates contiguous physical memory blocks to processes.,A method to compress logical memory into smaller physical spaces.,A memory-management scheme that allows a process's physical address space to be noncontiguous.,A technique primarily used to speed up disk I/O operations.,A system for encrypting memory contents to enhance security.,C,"Paging is a memory-management scheme specifically designed to allow the physical address space of a process to be noncontiguous, which helps in avoiding external fragmentation."
What is one primary advantage of using Paging for memory management?,It eliminates internal fragmentation completely.,It guarantees faster CPU clock speeds.,It avoids external fragmentation and compaction issues.,It simplifies the physical memory layout for contiguous allocation.,It reduces the need for hardware support in memory translation.,C,"Paging is beneficial because it avoids external fragmentation, a common problem in contiguous memory allocation, and thus eliminates the need for compaction."
"In paging, what are the fixed-sized blocks of physical memory called?",Pages,Segments,Clusters,Frames,Blocks,D,"Physical memory is broken into fixed-sized blocks known as frames, while logical memory is broken into same-sized blocks called pages."
What are the two main parts into which a CPU-generated logical address is divided in a paged memory system?,Segment number and offset,Base address and limit register,Page number and page offset,Frame number and frame offset,Process ID and memory address,C,A CPU-generated logical address in a paged system is divided into a page number (p) and a page offset (d).
What is the primary function of the 'page table' in a paged memory system?,To store the contents of each logical page.,To record which processes are currently running.,To map logical page numbers to physical frame numbers.,To manage disk space allocation for backing store.,To store CPU register values for context switching.,C,The page table is a per-process data structure that contains the base address (or frame number) of each frame in physical memory corresponding to a logical page number.
"If a logical address space is $2^m$ bytes and the page size is $2^n$ bytes, how are the page number and page offset determined?",Page number: low-order $n$ bits; Page offset: high-order $m-n$ bits.,Page number: high-order $m-n$ bits; Page offset: low-order $n$ bits.,Page number: $m$ bits; Page offset: $n$ bits.,Page number: low-order $m-n$ bits; Page offset: high-order $n$ bits.,Page number: $n$ bits; Page offset: $m-n$ bits.,B,"For a logical address space of $2^m$ bytes and a page size of $2^n$ bytes, the high-order $m-n$ bits represent the page number, and the low-order $n$ bits represent the page offset."
What type of fragmentation is generally associated with paging?,External fragmentation only,Both external and internal fragmentation,Internal fragmentation only,No fragmentation,Contiguous fragmentation,C,"Paging avoids external fragmentation because any free frame can be allocated. However, it may result in internal fragmentation if the last frame allocated to a process is not completely filled."
What is the average internal fragmentation per process in a paged system?,One full page,No internal fragmentation,One-quarter page,One-half page,Varies significantly with no average,D,"The average internal fragmentation is approximately one-half page per process, as the last page may be partially used."
Which of the following statements about page size is generally true?,Smaller page sizes increase internal fragmentation.,Larger page sizes improve disk I/O efficiency.,Page sizes are typically not powers of 2.,Page sizes have decreased over time.,The optimal page size is always 1 KB.,B,"While smaller page sizes reduce internal fragmentation, larger page sizes reduce overhead per page-table entry and make disk I/O more efficient with larger data transfers."
What is the function of the 'frame table' maintained by the operating system?,It maps logical addresses to physical addresses for all processes.,It stores CPU register values during context switches.,It tracks the allocation status of each physical page frame (free/allocated) and which process/page it belongs to.,It contains the page tables for all active processes.,It caches frequently accessed page table entries.,C,"The frame table is a system-wide data structure with one entry per physical page frame, indicating whether the frame is free or allocated, and if allocated, to which process and page."
"When page tables are kept in main memory, what CPU register is used to point to the base of the current process's page table?",Instruction Pointer (IP),Stack Pointer (SP),Page-Table Base Register (PTBR),Memory Data Register (MDR),Program Counter (PC),C,"When the page table is stored in main memory, the Page-Table Base Register (PTBR) holds the base address of the current page table."
What is the primary drawback of storing page tables in main memory without additional hardware support?,Increased internal fragmentation.,Slower memory access times due to two memory accesses for each data access.,Inability to support shared pages.,Higher CPU utilization for page table management.,Elimination of dynamic relocation.,B,"Storing the page table in main memory means that accessing a data item requires two memory accesses: one to fetch the page-table entry and another to fetch the actual data, effectively doubling memory access time."
What is a 'Translation Look-aside Buffer' (TLB) primarily used for?,Buffering disk I/O operations.,Caching frequently used instructions.,"A small, fast-lookup hardware cache for page table entries.",Managing the queue of processes waiting for CPU time.,Translating assembly code into machine code.,C,"The TLB is a special, small, fast-lookup hardware cache designed to speed up address translation by caching a subset of the page table entries."
What happens during a 'TLB miss' when translating a logical address?,The system immediately generates a memory protection fault.,The CPU fetches the frame number directly from main memory without using the page table.,A memory reference is made to the page table in main memory to obtain the frame number.,The process is immediately swapped out to backing store.,The TLB automatically updates its contents from disk.,C,"If a page number is not found in the TLB (a TLB miss), a memory reference must be made to the page table in main memory to retrieve the corresponding frame number."
What is an 'Address-Space Identifier' (ASID) in a TLB entry used for?,To specify the size of the logical address space.,To uniquely identify a process and allow the TLB to contain entries for multiple processes simultaneously.,To indicate whether a page is valid or invalid.,To determine the priority of a process for TLB access.,To mark a TLB entry as 'wired down'.,B,"An ASID uniquely identifies the process that owns a TLB entry, allowing the TLB to hold translations for multiple processes concurrently without flushing on every context switch if the ASID matches."
"If a TLB does not use ASIDs, what must happen on every context switch?",The TLB must be expanded to accommodate new entries.,The TLB must be 'flushed' (erased) to prevent incorrect translations.,The operating system must rebuild the page table from scratch.,The CPU must halt all memory access until the TLB is manually reloaded.,All pages for the outgoing process must be written to disk.,B,"If a TLB does not store ASIDs, it must be flushed on every context switch to ensure that the next process does not use old, incorrect translation information from the previous process."
What is the 'hit ratio' in the context of a TLB?,The percentage of processes that use the TLB.,The total number of entries a TLB can hold.,The percentage of times a page number is found in the TLB.,The ratio of TLB size to main memory size.,The frequency of TLB flush operations.,C,"The hit ratio is the percentage of times that the requested page number is found in the TLB, indicating the effectiveness of the cache."
"Consider a system with a memory access time of 10 ns. If the TLB hit ratio is 80%, and a TLB miss adds an extra 10 ns (for page table lookup in main memory), what is the effective memory-access time?",10 ns,12 ns,14 ns,18 ns,20 ns,B,"Effective Memory-Access Time = (Hit Ratio * TLB Access Time) + (Miss Ratio * (TLB Access Time + Page Table Access Time)). Given 10 ns for memory access (which is also TLB access on a hit, and page table access on a miss), and a 80% hit ratio: (0.80 * 10 ns) + (0.20 * (10 ns + 10 ns)) = (0.80 * 10 ns) + (0.20 * 20 ns) = 8 ns + 4 ns = 12 ns."
How is memory protection implemented in a paged environment?,By encrypting all memory contents.,By storing protection bits in the CPU's general-purpose registers.,"By assigning protection bits to each frame in the page table, checked on every memory reference.",By requiring user confirmation for every memory write operation.,By physically separating user and kernel memory with hardware walls.,C,"Memory protection in a paged environment is achieved by associating protection bits (e.g., read-write, read-only, execute-only) with each frame entry in the page table, which are checked during the address translation process."
What is the purpose of the 'valid-invalid' bit in a page table entry?,To indicate if the page has been modified since it was loaded.,To mark whether the page is currently in physical memory or on disk.,To specify if the page is part of the process's legal logical address space or not.,To denote if the page is shared among multiple processes.,To control the caching policy for the specific page.,C,The valid-invalid bit indicates whether the corresponding page is a legal page within the process's logical address space. An attempt to access a page marked invalid results in a trap to the OS.
What is 'reentrant code' and why is it important for shared pages?,Code that can be loaded into memory multiple times for performance.,"Code that modifies itself during execution, ensuring uniqueness.","Non-self-modifying code that can be executed simultaneously by multiple processes, allowing memory sharing.",Code that automatically reconfigures its page table entries.,Code specifically designed for single-process execution to avoid conflicts.,C,"Reentrant code is non-self-modifying, meaning it does not change during execution. This property allows multiple processes to execute the same copy of the code simultaneously, making it suitable for sharing in a paged environment."
"In a system with shared pages, what typically happens if 40 processes all need to use the standard C library (libc)?",Each process loads its own full copy of libc into physical memory.,"Only one copy of libc is loaded into physical memory, and all processes' page tables map to it.",The operating system prevents processes from using libc simultaneously.,Libc is converted into a non-reentrant form for security.,Libc is stored exclusively in the TLB for fast access.,B,"If libc is reentrant code, only one copy needs to be loaded into physical memory. The page tables for all user processes can then map their logical pages to this single shared physical copy, resulting in significant memory savings."
What is the purpose of the 'page-table length register' (PTLR)?,To store the number of physical frames available in the system.,To indicate the size of the current process's page table.,To count the number of TLB misses.,To define the maximum allowable page size.,To track the total number of logical addresses generated by a process.,B,"The page-table length register (PTLR) indicates the size of the page table for the current process, which can be checked against a logical address to verify it falls within the valid range."
Which of the following is true regarding the impact of paging on context-switch time?,Paging significantly reduces context-switch time due to simpler memory management.,Paging has no impact on context-switch time.,Paging increases context-switch time because the OS needs to reload the hardware page table and potentially flush the TLB.,Paging only affects context-switch time if page tables are stored in dedicated hardware registers.,Paging decreases context-switch time because processes share page tables.,C,"Paging generally increases context-switch time because the CPU dispatcher must reload the hardware page table (e.g., PTBR) for the new process and, if ASIDs are not used, flush the TLB."
What is 'wired down' in the context of TLB entries?,An entry that is marked for immediate removal from the TLB.,"An entry that cannot be removed from the TLB by the usual replacement algorithms, typically used for frequently accessed kernel code.",An entry that signifies a page fault has occurred and the page needs to be loaded from disk.,An entry that points to an invalid or unallocated physical frame.,An entry that is temporarily disabled until a specific event occurs.,B,"Some TLBs allow entries to be 'wired down', meaning they are locked into the TLB and cannot be removed by standard replacement policies, often used for critical kernel code that needs constant fast access."
What are the three common techniques for structuring the page table mentioned in the text?,"Segmented paging, Indexed paging, Clustered paging","Hierarchical paging, Hashed page tables, Inverted page tables","Single-level paging, Multi-level paging, Forward-mapped paging","Direct-mapped paging, Cache-based paging, Linked-list paging","Virtual paging, Physical paging, Logical paging",B,"The text explicitly states that it ""Explores common techniques for structuring the page table: hierarchical paging, hashed page tables, and inverted page tables."""
What primary problem does the hierarchical paging scheme attempt to solve in modern computer systems?,Reducing the complexity of virtual address translation at the hardware level.,Minimizing the number of Translation Lookaside Buffer (TLB) misses.,Handling excessively large page tables that result from large logical address spaces.,Improving the speed of I/O operations by optimizing page transfers.,Enabling shared memory between multiple processes more efficiently.,C,"The text identifies that ""Modern computer systems support large logical address spaces... Page table itself becomes excessively large,"" and that hierarchical paging is a ""Solution: divide page table into smaller pieces."""
"For a 32-bit logical address space with a 4 KB page size, how many entries would a single-level page table typically have?",2^10 entries,2^12 entries,2^20 entries,2^32 entries,2^4 entries,C,"A 32-bit logical address space and 4 KB ($2^{12}$ bytes) page size implies a 12-bit page offset. The remaining bits for the page number are 32 - 12 = 20 bits. Thus, the page table would have $2^{20}$ entries."
"Considering a 32-bit logical address space with a 4 KB page size, if each page table entry is 4 bytes, how much physical memory could a single process's page table occupy?",4 KB,1 MB,4 MB,16 MB,1 GB,C,"The example calculates that with $2^{20}$ entries and 4 bytes per entry, the page table would consume ""up to 4 MB physical address space for page table alone"" ($2^{20} 	imes 4 	ext{ bytes} = 4,194,304 	ext{ bytes} = 4 	ext{ MB}$). "
"In a two-level paging algorithm for a 32-bit logical address space with a 4 KB page size, how is the 20-bit page number logically divided?",5-bit outer page number ($p_1$) and 15-bit inner page offset ($p_2$),12-bit outer page number ($p_1$) and 8-bit inner page offset ($p_2$),10-bit outer page number ($p_1$) and 10-bit inner page offset ($p_2$),15-bit outer page number ($p_1$) and 5-bit inner page offset ($p_2$),20-bit outer page number ($p_1$) and 0-bit inner page offset ($p_2$),C,"The text specifies: ""Page number further divided: $p_1$: 10-bit outer page number... $p_2$: 10-bit inner page offset."""
What is another term used to describe a hierarchical page table where address translation starts at the outer page table and moves inward?,Backward-mapped page table,Inverted page table,Hashed page table,Forward-mapped page table,Clustered page table,D,"The text explicitly states that this scheme is ""Also known as a forward-mapped page table."" The glossary also confirms this definition."
Why are hierarchical page tables generally considered inappropriate for 64-bit architectures?,They increase the complexity of I/O operations.,"They would require an excessive number of paging levels, leading to prohibitive memory accesses.",They are not compatible with the instruction sets of 64-bit CPUs.,They result in insufficient memory utilization for large address spaces.,They lack the necessary security features for modern 64-bit systems.,B,"The text states that a ""64-bit UltraSPARC: would require seven levels of paging (prohibitive memory accesses)"" and concludes that ""Hierarchical page tables generally inappropriate for 64-bit architectures."""
What is the primary purpose of hashed page tables?,To optimize physical memory allocation for small systems.,To handle address spaces larger than 32 bits.,To eliminate the need for a Translation Lookaside Buffer (TLB).,To provide direct mapping from virtual to physical addresses without intermediate structures.,To reduce the number of entries in the main system page table.,B,"The text states that hashed page tables are an ""Approach for handling address spaces larger than 32 bits."""
"In a hashed page table, what is typically used as the hash value?",The physical page number.,The page offset.,The virtual page number.,The process identifier (PID).,A combination of physical and virtual addresses.,C,"The text explicitly states: ""Hash value: virtual page number."""
How do hashed page tables typically resolve collisions when multiple virtual page numbers map to the same hash table entry?,By discarding the conflicting entry and marking it as an error.,By using a secondary hashing function to re-distribute entries.,By maintaining a linked list of elements at each hash table entry.,By dynamically resizing the hash table when collisions occur.,By triggering a page fault and loading the correct page.,C,"The text specifies that ""Each entry in hash table: linked list of elements (to handle collisions)."""
"What is a distinguishing characteristic of clustered page tables, a variation of hashed page tables for 64-bit address spaces?",Each entry refers to a single virtual page only.,They are exclusively used for mapping kernel memory regions.,"Each entry refers to several pages (e.g., 16), storing mappings for multiple physical-page frames.",They do not utilize a hash function for address lookup.,"They are optimized for dense, contiguous address spaces rather than sparse ones.",C,"The text states that in clustered page tables, ""Each entry refers to several pages (e.g., 16) instead of a single page,"" and they ""Single page-table entry stores mappings for multiple physical-page frames."""
For which type of address spaces are clustered page tables particularly useful?,Address spaces with very few entries.,Dense and contiguous address spaces.,"Sparse address spaces, where memory references are noncontiguous and scattered.",Physical address spaces exclusively.,"Small, fixed-size address spaces.",C,"The text states that clustered page tables are ""Useful for sparse address spaces (memory references noncontiguous, scattered)."" The glossary defines 'sparse' as a page table with noncontiguous, scattered entries or an address space with many holes."
What is the fundamental difference between an inverted page table and a standard page table regarding their entries?,"Standard page tables have one entry per process, while inverted have one entry per virtual page.","Standard page tables have one entry for each virtual address, while inverted page tables have one entry for each real physical page frame.","Inverted page tables are sorted by process ID, while standard page tables are sorted by virtual address.","Inverted page tables store only physical addresses, whereas standard page tables store only virtual addresses.","Standard page tables are managed by hardware, while inverted page tables are managed by software.",B,"The text clarifies: ""Standard page table: one entry for each page process is using (or each virtual address)... Inverted page table: one entry for each real page (frame) of memory."""
What information does each entry in an inverted page table typically contain?,Only the physical page number and permissions.,The virtual address of the page stored in that real memory location and process information.,The logical page number and page offset for all active processes.,A pointer to the next element in a linked list for collision resolution.,The hash value of the corresponding virtual page number.,B,"The text states that ""Each entry: virtual address of page stored in that real memory location, plus process information."""
How many inverted page tables typically exist within a single system?,One per active process.,One per CPU core.,One per physical memory block.,Only one for the entire system.,"Multiple, depending on the number of installed memory modules.",D,"The text specifies, ""Only one page table in system, one entry per physical memory page."""
What is a significant drawback of inverted page tables concerning address lookup performance?,They inherently cause more Translation Lookaside Buffer (TLB) misses.,"They increase the time to search the table because it's sorted by physical address, but lookups are by virtual address.","They are incompatible with multi-level paging schemes, slowing down translation.","They always require two physical memory reads for a single virtual memory reference, even with a hit.","They cannot support dynamic memory allocation, leading to fragmentation.",B,"The text notes, ""Drawback: increases time to search table (sorted by physical address, lookups by virtual address)."""
How is the increased search time drawback of inverted page tables commonly alleviated?,By reducing the page size to decrease table complexity.,By using a hash table to limit the search space.,By increasing the number of physical memory frames.,By storing the entire page table in the Translation Lookaside Buffer (TLB).,By implementing a Least Recently Used (LRU) page replacement policy.,B,"The text states, ""Alleviation: use a hash table to limit search."""
Which of the following describes a key issue with shared memory when using inverted page tables compared to standard paging?,Inverted page tables allow more flexible shared memory by design.,"Standard paging allows only one virtual address per physical page, while inverted allows many.","Inverted page tables allow only one virtual page entry for every physical page, making it difficult for multiple processes to directly share memory without special handling.",Shared memory segments are automatically swapped to disk with inverted page tables.,Inverted page tables do not support any form of shared memory.,C,"The text explains: ""Standard paging: multiple virtual addresses map to same physical address. Inverted page tables: only one virtual page entry for every physical page. One physical page cannot have two (or more) shared virtual addresses. Reference by another process sharing memory: page fault, replaces mapping."""
How does the Oracle SPARC Solaris system primarily solve the virtual memory problem efficiently for its 64-bit architecture?,By implementing a complex seven-level hierarchical page table structure.,"By exclusively using a single, centralized inverted page table.",Through the efficient use of hashed page tables.,"By eliminating the need for any form of page tables, using direct address mapping.",By relying solely on the Translation Lookaside Buffer (TLB) for all translations.,C,"The text states that Solaris ""Solves virtual memory problem efficiently using hashed page tables."""
How many distinct hash tables does Oracle SPARC Solaris typically utilize for virtual to physical memory mapping?,"One for all processes, including the kernel.",Two: one for the kernel and one for all user processes.,One for each active user process.,One per CPU core to minimize contention.,"Three: one for kernel, one for user, and one for shared memory.",B,"The text states, ""Two hash tables: one for kernel, one for all user processes."""
"In Oracle SPARC Solaris, what information does each hash-table entry typically represent for virtual memory mapping?",A single virtual page number mapped to a single physical page frame.,A linked list of all virtual pages that hash to that entry.,"A contiguous area of mapped virtual memory, including a base address and a span (number of pages represented).",A pointer to an entry in an inverted page table.,Only the permissions and dirty bit for a specific page.,C,"The text explains, ""Each hash-table entry: contiguous area of mapped virtual memory (more efficient than per-page entry). Entry has base address and span (number of pages represented)."""
What is the primary function of the TLB (Translation Lookaside Buffer) in the SPARC Solaris virtual memory system?,To store the complete page table in main memory.,To hold Translation Table Entries (TTEs) for fast hardware lookups.,To manage physical memory allocation and deallocation.,To handle page faults by initiating disk I/O.,To provide a software-managed cache for process IDs.,B,"The text states, ""TLB (Translation Lookaside Buffer): holds translation table entries (TTEs) for fast hardware lookups."""
What is the Translation Storage Buffer (TSB) in the SPARC Solaris system?,The primary disk storage area for virtual memory pages.,A hardware component responsible for hashing virtual addresses.,A cache of Translation Table Entries (TTEs) that includes an entry per recently accessed page.,A software routine that manages the page fault handling process.,The physical memory region where the kernel's hash table resides.,C,"The text defines it as a ""Cache of TTEs: translation storage buffer (TSB). TSB includes entry per recently accessed page."""
What specifically describes a 'TLB walk' in the context of virtual memory management?,The process of flushing all entries from the TLB.,The steps involved in traversing page-table structures to locate a needed translation and copying the result into the TLB.,A hardware error that occurs when the TLB cannot find a translation.,A software routine that preloads the TLB with frequently accessed translations.,The movement of a page from physical memory to disk when memory is low.,B,"The glossary defines ""TLB walk"" as ""Steps involved in traversing page-table structures to locate a needed translation and copying the result into the TLB."" The virtual address reference process also outlines this step."
Under what specific condition does the kernel get interrupted during the virtual address reference process in Oracle SPARC Solaris?,When the hardware successfully finds a translation in the TLB.,When a match is found in the Translation Storage Buffer (TSB).,When neither the Translation Lookaside Buffer (TLB) nor the Translation Storage Buffer (TSB) contains the required translation.,When the Memory Management Unit (MMU) successfully completes address translation.,When data is finally retrieved from the main memory location.,C,"The virtual address reference process outlines: ""1. Hardware searches TLB for translation. 2. None found: hardware walks through in-memory TSB... 4. No match in TSB: kernel interrupted to search hash table."""
The term 'sparse' in memory management refers to:,A memory region that is densely packed with frequently accessed data.,"A page table with noncontiguous, scattered entries; an address space with many holes.",A type of physical memory characterized by very fast access times.,A condition where a system has an abundance of available free physical memory.,A process that is designed to use a minimal amount of memory resources.,B,"The glossary defines 'sparse' as ""In memory management, describes a page table with noncontiguous, scattered entries; an address space with many holes."""
What is the primary reason process instructions and data are temporarily 'swapped' out of main memory?,To permanently archive the process data for future reference.,To prevent unauthorized access to sensitive information.,To free up main memory temporarily for other processes or portions.,To reduce the overall CPU load by offloading data processing.,To compress the data before it is loaded back into memory for faster access.,C,"Swapping is a mechanism to temporarily move a process or a portion of it out of main memory to a backing store, making room for other processes to execute, as process instructions and data must be in memory for execution."
Which of the following is a direct consequence of implementing swapping in an operating system?,It strictly limits the total physical address space of all processes to the real physical memory size.,It always decreases the overall degree of multiprogramming.,It allows the total physical address space of all processes to exceed the real physical memory.,It mandates the use of solid-state drives exclusively for backing stores.,It eliminates the need for any form of main memory in the system.,C,"Swapping allows the combined memory requirements of all processes to be larger than the available physical memory, thus enabling more processes to run than would otherwise be possible. It also increases the degree of multiprogramming."
What defines 'standard swapping'?,The movement of only a few select pages of a process between memory and backing store.,The primary method of memory management used by contemporary mobile operating systems.,The process of moving entire processes between main memory and a backing store.,The voluntary relinquishment of memory by applications when system resources are low.,A technique primarily focused on reducing the number of write operations to flash memory.,C,Standard swapping is defined as moving entire processes between main memory and a backing store. This method is generally no longer used in contemporary OS due to the prohibitive time involved.
"In the context of process swapping, what are the characteristics of a 'backing store'?",It is the main memory (RAM) and acts as the primary storage for active processes.,"It is a slow, archival storage area used for long-term data preservation.","It is a fast secondary storage, large enough for process parts, with direct access to memory images.","It is a dedicated cache within the CPU, designed for very rapid access to small data sets.",It refers to volatile memory that loses its contents when power is off.,C,"The backing store is described as a fast secondary storage area, large enough for process parts, and allowing direct access to memory images for efficient swapping operations."
"Why is standard swapping generally no longer used in contemporary operating systems like Linux and Windows, with few exceptions?",The metadata management for swapped-out processes became overly complex.,The time required to move entire processes between memory and backing store is prohibitive.,Backing stores available today are not fast enough to support it efficiently.,"It does not allow for physical memory oversubscription, which is a key modern requirement.","It only supports single-threaded applications, making it unsuitable for modern software.",B,The text states that standard swapping is largely replaced because the time to move entire processes between memory and backing store is prohibitive for efficient operation in modern systems.
"In the context of modern operating systems, what does the term 'paging' specifically refer to?",The standard swapping mechanism that moves entire processes.,The process of terminating applications when memory is low.,"A variation of swapping where only individual pages of a process are moved, not the entire process.",The initial loading of an application's executable code into memory.,The practice of allocating memory manually by application developers.,C,"The text clarifies that 'paging' refers to 'swapping with paging,' where only a subset of pages for processes are moved to/from the backing store, not the entire process, to avoid the high cost of moving whole processes."
What is the action described as 'page out' in the context of swapping with paging?,Moving a page from the backing store to main memory.,Moving a page from main memory to the backing store.,Deleting a page from the system without saving its contents.,Writing an application's current state to flash memory on a mobile device.,Loading an executable file from disk into the main memory.,B,The term 'page out' is specifically defined as the process of moving a page from main memory to the backing store.
Which of the following is NOT a stated reason why mobile systems typically do not support swapping?,"Their use of flash memory for nonvolatile storage, leading to space constraints.",The limited number of writes that flash memory tolerates before becoming unreliable.,Poor throughput between main memory and flash memory.,"Mobile systems are designed with an abundance of physical memory, negating the need for swapping.",The need for applications to voluntarily relinquish memory.,D,"The text explicitly lists flash memory constraints (space, limited writes) and poor throughput as reasons why mobile systems typically do not support swapping. It does not state that mobile systems have an abundance of physical memory; in fact, memory is a constraint that leads to alternative strategies. Option E is an alternative strategy, not a reason for *not* supporting swapping."
"How does Apple's iOS manage memory when free memory is low, as an alternative to traditional swapping?",It automatically swaps all idle processes to a cloud storage service.,It immediately terminates all background applications without warning.,It asks applications to voluntarily relinquish allocated memory.,It dynamically increases the physical memory capacity of the device.,It permanently deletes all read-only data from the system to free up space.,C,"Apple's iOS attempts to manage low memory by asking applications to voluntarily relinquish allocated memory. Read-only data (code) may be removed and reloaded, while modified data is never removed, and applications failing to comply may be terminated."
"What unique action might Android take when terminating a process due to insufficient free memory, which is a distinction from iOS's described approach?",It always swaps the entire process to a dedicated partition on the flash memory.,It prompts the user to manually select processes to terminate.,It writes the application's 'application state' to flash memory for a quick restart.,It compresses all remaining data in main memory to create more space.,It attempts to offload process execution to a connected desktop computer.,C,"While Android also terminates processes for insufficient memory, a distinguishing feature mentioned is that it writes the 'application state' to flash memory before termination, allowing for a quicker restart of the application later."
"According to the glossary, what is 'application state'?","The current execution status (e.g., running, paused) of an application.",A measure of an application's CPU and memory utilization.,"A software construct for data storage, noted for being written to flash memory for quick restart on Android.",The version number and developer information of an application.,The graphical user interface (GUI) layout of an application.,C,"The glossary defines 'application state' as a 'Software construct for data storage,' which the text elaborates is used by Android for quick restarts by writing it to flash memory."
"Excessive swapping, regardless of its form, is often an indicator of what system condition?",The CPU is idle and waiting for more processes to run.,The system has more active processes than available physical memory.,The backing store is operating at peak efficiency.,All applications are optimally managing their memory usage.,The network connection is experiencing high latency.,B,"The text explicitly states that swapping (in any form) is often a sign that there are more active processes than available physical memory, indicating a resource bottleneck."
What are the two common approaches suggested in the text to address system performance issues caused by excessive swapping?,Increasing the size of the backing store and compressing data in memory.,Terminating some processes or acquiring more physical memory.,Migrating to a mobile operating system and disabling virtual memory.,Implementing faster flash memory and optimizing the CPU's cache.,Converting standard swapping to paging and installing a new operating system.,B,The text provides two direct solutions for system performance issues under swapping: 'Terminate some processes' or 'Get more physical memory.'
Which types of processes are generally considered good candidates for standard swapping?,Processes that are constantly performing I/O operations.,Processes that are currently executing critical system functions.,Processes that are idle or mostly idle.,Processes requiring significant CPU-intensive computations.,Processes involved in real-time data streaming.,C,The text states that 'Idle/mostly idle processes [are] good candidates for swapping' because their memory can be temporarily freed and dedicated to active processes.
"When a process or part is swapped to a backing store, what happens to its associated data structures, including per-thread data for multithreaded processes?","They are automatically recreated when the process is swapped back in, so they are not saved.",They remain in main memory while only the core process code is swapped out.,They must be written to the backing store along with the process or its part.,They are permanently deleted to ensure data integrity during swapping.,"They are encrypted and stored in a separate, secure partition of the main memory.",C,"The text specifies that 'When process/part swapped to backing store, associated data structures (including per-thread data for multithreaded processes) must be written.' The OS also maintains metadata for restoration."
Which of the following Intel architectures was primarily 32-bit and included Pentium processors?,x86-64,ARM,IA-32,IA-64,Intel 8086,C,"The text states that '32-bit chips: IA-32, included Pentium processors'."
What is the primary memory management concept used in the Intel IA-32 architecture?,Swapping and Caching,Segmentation and Paging,Relocation and Protection,Virtualization and Emulation,Demand Paging and Thrashing,B,The text explicitly states: 'Memory management in IA-32: segmentation and paging'.
"In the IA-32 architecture, what is the correct sequence of address translation?",Logical address -> Paging unit -> Linear address -> Segmentation unit -> Physical address,Physical address -> Paging unit -> Linear address -> Segmentation unit -> Logical address,Logical address -> Segmentation unit -> Linear address -> Paging unit -> Physical address,Linear address -> Segmentation unit -> Logical address -> Paging unit -> Physical address,Physical address -> Segmentation unit -> Linear address -> Paging unit -> Logical address,C,The text describes the flow: 'CPU generates logical addresses -> segmentation unit. Segmentation unit produces linear address -> paging unit. Paging unit generates physical address in main memory.'
The memory-management unit (MMU) in IA-32 architecture is formed by which two units?,CPU and Main Memory,Cache and Registers,Segmentation and Paging units,I/O Controller and DMA,Arithmetic Logic Unit and Control Unit,C,The text states: 'Segmentation and paging units form memory-management unit (MMU)'.
What is the maximum segment size in IA-32 segmentation?,1 MB,4 KB,1 GB,4 GB,16 KB,D,The text specifies: 'IA-32 segment size: up to 4 GB'.
How many segments can a process have in the IA-32 segmentation architecture?,4 K,8 K,16 K,32 K,64 K,C,The text states: 'Max segments per process: 16 K'.
Which table holds information for segments private to a process in IA-32 segmentation?,Page Directory,Global Descriptor Table (GDT),Local Descriptor Table (LDT),Process Control Block (PCB),Translation Lookaside Buffer (TLB),C,"The text specifies: 'Information for first partition: local descriptor table (LDT)', and this partition is 'private to process'."
Each entry in the Local Descriptor Table (LDT) or Global Descriptor Table (GDT) is an 8-byte ______.,page table entry,segment descriptor,address translation entry,cache line,protection bit,B,The text states: 'Each LDT/GDT entry: 8-byte segment descriptor'.
A logical address in IA-32 segmentation is composed of which two parts?,Base and Limit,Page Number and Offset,Selector and Offset,Segment Register and Index,Linear Address and Physical Address,C,"The text defines a logical address as: '(selector, offset)'."
What is the purpose of the six segment registers in IA-32 segmentation?,To store physical addresses directly,"To act as a cache for segment descriptors, avoiding memory reads",To hold the base and limit of all 16K segments,To control I/O operations,To store the 32-bit linear address,B,The text states: 'Six 8-byte microprogram registers: hold descriptors (LDT/GDT cache). Cache avoids reading descriptor from memory for every reference.'
What is the length of a linear address in the IA-32 architecture?,16 bits,32 bits,48 bits,64 bits,128 bits,B,The text specifies: 'Linear address (IA-32): 32 bits long'.
"In IA-32 segmentation, what occurs if an address validity check fails against the segment limit?",The address is automatically corrected.,The system writes data to an invalid memory location.,A memory fault (trap to OS) is generated.,The operation is retried from a different segment.,The CPU enters a low-power state.,C,The text states: 'Limit checks address validity; invalid -> memory fault (trap to OS)'.
What are the typical page sizes supported by IA-32 paging?,1 KB or 2 MB,2 KB or 4 MB,4 KB or 4 MB,8 KB or 1 GB,16 KB or 2 GB,C,The text indicates: 'IA-32 page size: 4 KB or 4 MB'.
"For 4-KB pages in IA-32, a 32-bit linear address is divided into how many parts and what are their bit lengths?","Two parts: page number (20 bits), offset (12 bits)","Three parts: p1 (10 bits), p2 (10 bits), offset (12 bits)","Three parts: p1 (12 bits), p2 (10 bits), offset (10 bits)","Four parts: p1 (8 bits), p2 (8 bits), p3 (8 bits), offset (8 bits)","Two parts: page directory (16 bits), page table (16 bits)",B,The text details: '32-bit linear address division: Page number p1: 10 bits (high-order). Page number p2: 10 bits (inner). Page offset d: 12 bits (low-order).'
Which register points to the page directory for the current process in IA-32 paging?,EAX,ESP,CR0,CR3,EIP,D,The text specifies: 'CR3 register points to page directory for current process'.
"In IA-32 paging, if the `Page_Size` flag in a page directory entry is set, what is the size of the page frame and what happens to the paging process?","4 KB, and it uses a three-level paging scheme.","4 MB, and it bypasses the inner page table.","2 MB, and it triggers a memory fault.","1 GB, and it requires a TLB flush.","64 KB, and it swaps the page to disk.",B,The text states: 'If Page_Size set: page frame is 4 MB (bypasses inner page table)'.
What is the primary purpose of Page Address Extension (PAE) in IA-32 CPU hardware?,To enable 16-bit processors to run 32-bit software.,To allow 32-bit processors to access physical address space larger than 4GB.,To convert logical addresses directly to physical addresses without segmentation.,To increase the speed of the CPU clock.,To reduce the number of segment registers.,B,The glossary defines PAE as: 'Intel IA-32 CPU hardware allowing 32-bit processors to access physical address space larger than 4GB'.
How did PAE (Page Address Extension) change the paging scheme in IA-32?,It removed the paging hierarchy entirely.,It changed from a two-level to a three-level scheme.,It introduced a four-level hierarchy.,It reduced it to a single-level scheme.,It replaced paging with segmentation.,B,The text states: 'PAE changes paging from two-level to three-level scheme'.
"With PAE, what was the maximum physical memory supported by IA-32 systems?",4 GB,16 GB,32 GB,64 GB,128 GB,D,The text notes: 'PAE increased address space to 36 bits. Supports up to 64 GB physical memory'.
"Which company developed the x86-64 architecture, which extended the existing IA-32 instruction set?",Intel,IBM,ARM,Microsoft,AMD,E,The text states: 'AMD developed x86-64: extended existing IA-32 instruction set'.
What was Intel's initial 64-bit architecture that was not widely adopted?,x86-64,Pentium Pro,Itanium (IA-64),Atom,Core i7,C,"The text says: 'Intel's initial 64-bit architecture: IA-64 (later Itanium), not widely adopted'."
What is the practical virtual address space size used in the x86-64 architecture?,32-bit,48-bit,64-bit,96-bit,128-bit,B,The text specifies: 'x86-64 architecture: 48-bit virtual address'.
How many levels of paging hierarchy does the x86-64 architecture use?,Two,Three,Four,Five,One,C,The text states: 'Uses four levels of paging hierarchy'.
Which of the following page sizes are supported by the x86-64 architecture?,4 KB only,"4 KB, 2 MB, or 1 GB",4 MB or 1 GB only,64 KB or 2 MB,128 KB or 4 MB,B,"The text lists: 'Supports page sizes: 4 KB, 2 MB, or 1 GB'."
What is the primary reason for Intel's lack of dominance in mobile systems?,High power consumption of Intel chips.,Focus on server architectures.,ARM architecture's success in mobile.,Lack of 64-bit support in mobile devices.,Market saturation by competitors.,C,The text states: 'Intel dominance not in mobile systems; ARM architecture successful'.
Which statement accurately describes the primary application areas of ARM processors?,Primarily used in high-performance computing servers.,Mostly found in desktop computers and laptops.,"Common for mobile devices (smartphones, tablets) and real-time embedded systems.",Dominate the market for graphics processing units.,Are less common than Intel processors by quantity produced.,C,"The text states ARM processors are common for mobile devices (smartphones, tablets) and also for real-time embedded systems."
What is a key distinction between ARM and Intel's business models based on the provided text?,"Intel focuses on software development, while ARM focuses on hardware manufacturing.","ARM designs and manufactures chips, while Intel only licenses designs.","Intel designs and manufactures chips, while ARM only designs and licenses architectural designs.",Both companies primarily focus on cloud computing infrastructure.,"ARM specializes in graphics cards, whereas Intel specializes in CPUs.",C,"The text specifies that Intel designs and manufactures chips, while ARM only designs and licenses architectural designs to manufacturers."
"What is the bitness of the ARM v8 architecture, and how many bits are currently used for addressing?","32-bit architecture, 30 bits used.","64-bit architecture, 48 bits used.","64-bit architecture, 64 bits used.","128-bit architecture, 64 bits used.","32-bit architecture, 32 bits used.",B,"The text states 'ARM v8 is 64-bit architecture, but only 48 bits currently used'."
"In ARM v8 CPUs, what do 'translation granules' define?",The number of CPU cores and threads.,The clock speed and cache size.,Page sizes and regions.,Interrupt priority levels.,"The type of memory (e.g., DDR3, DDR4).",C,The glossary defines 'translation granules' as 'Features of ARM v8 CPUs defining page sizes and regions'.
What are 'regions' in the context of ARM v8 CPUs?,Logical divisions within a CPU's pipeline.,Physical memory banks on a motherboard.,Contiguous memory areas with separate privilege and access rules.,Sections of the operating system kernel.,Cache levels within the CPU.,C,"The glossary defines 'regions' as 'In ARM v8 CPUs, contiguous memory areas with separate privilege and access rules'."
"How many translation granules does ARM v8 have, and what are their sizes?",Two: 4 KB and 64 KB.,"Three: 4 KB, 16 KB, and 64 KB.","Four: 1 KB, 4 KB, 16 KB, and 64 KB.","Three: 8 KB, 32 KB, and 128 KB.",One: 4 KB.,B,"The text states 'ARM v8 has three translation granules: 4 KB, 16 KB, and 64 KB'."
"If a 4 KB translation granule is used in ARM v8, what are the corresponding page and region sizes?","Page Size: 16 KB, Region Size: 32 MB","Page Size: 64 KB, Region Size: 512 MB","Page Size: 4 KB, Region Size: 2 MB, 1 GB","Page Size: 4 KB, Region Size: 512 MB","Page Size: 16 KB, Region Size: 1 GB",C,"The table shows that for a 4 KB Translation Granule, the Page Size is 4 KB and the Region Size options are 2 MB, 1 GB."
Which page and region sizes are associated with the 16 KB translation granule in ARM v8?,"Page: 4 KB, Regions: 2 MB, 1 GB","Page: 16 KB, Region: 32 MB","Page: 64 KB, Region: 512 MB","Page: 16 KB, Region: 2 MB","Page: 4 KB, Region: 32 MB",B,"The table indicates that for a 16 KB Translation Granule, the Page Size is 16 KB and the Region Size is 32 MB."
Which page and region sizes are associated with the 64 KB translation granule in ARM v8?,"Page: 4 KB, Regions: 2 MB, 1 GB","Page: 16 KB, Region: 32 MB","Page: 64 KB, Region: 512 MB","Page: 64 KB, Region: 1 GB","Page: 4 KB, Region: 32 MB",C,"The table indicates that for a 64 KB Translation Granule, the Page Size is 64 KB and the Region Size is 512 MB."
What is the maximum number of paging levels supported by 4 KB and 16 KB translation granules in ARM v8?,One level,Two levels,Three levels,Four levels,Five levels,D,The text states: '4-KB and 16-KB granules: up to four levels of paging'.
How many levels of paging does the 64-KB translation granule support in ARM v8?,One level,Two levels,Three levels,Four levels,Five levels,C,The text states: '64-KB granules: up to three levels of paging'.
What is the function of the TTBR (translation table base register) in ARM v8?,It stores the current program counter value.,It points to the level 0 (outer) page table for the current thread.,It holds the address of the next instruction to be executed.,It controls the cache eviction policy.,It manages interrupt requests.,B,"The text defines TTBR as 'translation table base register, points to level 0 table for current thread.' The glossary further clarifies it as 'ARM v8 CPU register pointing to the level 0 (outer) page table for the current thread'."
"When all four levels of paging are used with a 4-KB granule, which bits refer to the offset within the 4-KB page?",Bits 0-7,Bits 0-11,Bits 0-15,Bits 0-20,Bits 0-29,B,The text states: 'If all four levels used (4-KB granule): offset (bits 0-11) refers to offset within 4-KB page'.
"If a Level-1 table entry refers to a 1-GB region, which low-order bits are used as the offset within that region?",Bits 0-11,Bits 0-20,Bits 0-29,Bits 0-31,Bits 0-39,C,The text specifies: 'Level-1 table refers to 1-GB region: low-order 30 bits (0-29) used as offset'.
"When a Level-2 table entry refers to a 2-MB region, how many low-order bits are used as the offset?",12 bits (0-11),21 bits (0-20),30 bits (0-29),32 bits (0-31),48 bits (0-47),B,The text states: 'Level-2 table refers to 2-MB region: low-order 21 bits (0-20) used as offset'.
How many levels of TLBs (Translation Lookaside Buffers) does the ARM architecture support?,One,Two,Three,Four,Five,B,The text states: 'ARM architecture supports two levels of TLBs'.
Which characteristic describes the inner-level TLBs in ARM architecture?,A single main TLB that does not support ASIDs.,"Two micro TLBs, one for data and one for instructions, which support ASIDs.",Three dedicated TLBs for different memory types.,A shared TLB for both data and instructions without ASID support.,A single L3 TLB that acts as a global cache.,B,"The text mentions: 'Inner level: two micro TLBs (one for data, one for instructions); support ASIDs'."
Where does the address translation process primarily begin in ARM architecture?,At the main TLB level.,At the page table walk in hardware.,At the micro-TLB level.,Directly accessing physical memory.,At the CPU's general-purpose registers.,C,The text states: 'Address translation process: Begins at micro-TLB level'.
What happens if a micro-TLB miss occurs during address translation in ARM?,The system immediately performs a page table walk.,The main TLB is checked next.,"An error is generated, halting the process.",The data is fetched directly from main memory.,The request is forwarded to another CPU core.,B,The text states: 'Micro-TLB miss: main TLB checked'.
What is the final step in the ARM address translation process if both micro TLB and main TLB miss?,The system requests a retry from the application.,The memory access is aborted.,A page table walk is performed in hardware.,The data is loaded from the swap file.,The operating system handles the translation in software.,C,The text states: 'Both TLBs miss: page table walk performed in hardware'.
"Which processor architecture is cited as the most widely used by quantity, with over 100 billion units produced?",Intel x86,RISC-V,PowerPC,ARM,SPARC,D,The text explicitly states: 'Over 100 billion ARM processors produced; most widely used architecture by quantity'.
What is the correct definition of a 'micro TLB' in ARM CPUs?,"The main, outer-level TLB.","A small, software-managed cache for page table entries.","Inner-level TLBs, one for instructions and one for data.",A dedicated TLB for I/O operations.,A unified TLB for both instructions and data at the highest level.,C,"The glossary defines 'micro TLB' as 'ARM CPU inner-level TLBs, one for instructions and one for data'."
How is the 'main TLB' described in the ARM architecture?,The first TLB checked during address translation.,An inner-level TLB specifically for instruction fetches.,"The outer-level TLB, checked after micro TLB lookup and before a page table walk.",A software-managed buffer that stores frequently accessed page table entries.,A TLB primarily used for storing kernel page table entries.,C,The glossary defines 'main TLB' as 'ARM CPU outer-level TLB; checked after micro TLB lookup and before page table walk'.
"What is a fundamental characteristic of memory in modern computer systems, as described?","A small, fixed-size cache for CPU data.","A large array of bytes, each with its own address.",A volatile storage unit used only for temporary data.,A non-addressable storage area for system files.,A component primarily used for long-term data archival.,B,"The text states that memory is 'a large array of bytes, each with own address'."
"Which mechanism is explicitly mentioned for address space allocation, involving two specific registers?",Virtual memory mapping using segment tables.,Dynamic memory allocation with heaps and stacks.,Address space allocation using base and limit registers.,Static allocation at compile time.,Paging with a single global page table.,C,The text highlights 'Address space allocation: using base and limit registers'.
"In the context of address space allocation using base and limit registers, what does the 'base register' define?",The largest legal physical memory address.,The total size of the allocated memory segment.,The smallest legal physical memory address.,The number of pages allocated to a process.,The starting address of the program's code segment.,C,The 'Base register' is defined as the 'smallest legal physical memory address'.
What is the primary function of the 'limit' register in address space allocation?,To specify the permission level for memory access.,To define the memory block size for caching.,To specify the total number of available physical frames.,To specify the size of the address range.,To indicate the maximum number of processes allowed in memory.,D,The 'Limit' is defined as specifying the 'size of address range'.
Which of the following is listed as a valid time for binding symbolic address references to physical addresses?,Installation time,Initialization time,Execution time,Shutdown time,Debugging time,C,"The text lists 'Compile time', 'Load time', and 'Execution time' as binding times."
What type of address is generated by the CPU?,Physical address,Hardware address,Logical address,Network address,Cache address,C,The 'Logical address' is explicitly stated as 'generated by CPU'.
What is the primary function of the Memory Management Unit (MMU)?,To allocate CPU time to processes.,To translate logical addresses to physical addresses.,To manage secondary storage devices.,To handle inter-process communication.,To control I/O operations.,B,The MMU is defined as translating 'logical address to physical address'.
"What is a common memory allocation approach mentioned, involving varying sizes?",Segmentation with fixed-size segments.,Paging with equal-sized pages.,Contiguous memory partitions of varying sizes.,Non-contiguous memory blocks.,Demand paging for all memory access.,C,The text specifies 'Memory allocation approach: contiguous memory partitions of varying sizes'.
Which of the following is listed as a partition allocation strategy?,Round Robin,Least Recently Used (LRU),Best fit,Shortest Job First (SJF),Aging,C,"The text lists 'First fit', 'Best fit', and 'Worst fit' as partition allocation strategies."
What memory management technique do modern operating systems primarily use?,Segmentation,Swapping,Contiguous allocation,Paging,Overlays,D,The text states 'Modern OS: use paging to manage memory'.
"In the context of paging, what are the fixed-sized blocks into which physical memory is divided called?",Segments,Pages,Frames,Blocks,Partitions,C,'Physical memory' is 'divided into fixed-sized blocks called frames'.
"In the context of paging, what are the blocks of logical memory, which are the same size as physical memory blocks, called?",Segments,Frames,Sections,Pages,Clusters,D,'Logical memory' is 'divided into blocks of same size called pages'.
How is a logical address structured in a paging system?,It's a direct pointer to a physical memory location.,It's divided into a segment number and an offset.,It's divided into a page number and a page offset.,It's a combination of base and limit register values.,"It's a single, unparsed integer representing the address.",C,Paging: 'logical address divided into page number and page offset'.
What is the purpose of the 'page number' component of a logical address in paging?,It specifies a specific location within a frame.,It serves as an index into a per-process page table.,It indicates the size of the page in memory.,It identifies the process that owns the page.,It points directly to the physical memory address.,B,'Page number: index into per-process page table'.
What essential information does a 'page table' contain?,The logical addresses of all pages.,The size of each page and frame.,The frame in physical memory holding the page.,The CPU's current instruction pointer.,A list of all active processes.,C,'Page table: contains frame in physical memory holding the page'.
"In paging, what does the 'offset' component of a logical address specify?",The starting address of the page table.,The specific location within the page table.,The total number of bytes in the page.,The specific location in the frame.,The distance from the base register.,D,'Offset: specific location in the frame'.
What is the Translation Look-aside Buffer (TLB)?,A software library for memory management.,A hardware cache of the page table.,A component that manages disk I/O operations.,A temporary storage for CPU registers.,A network buffer for data packets.,B,'Translation Look-aside Buffer (TLB): hardware cache of page table'.
What information is typically stored in each entry of a Translation Look-aside Buffer (TLB)?,Process ID and memory size.,Logical address and physical address.,Page number and corresponding frame.,Page size and offset value.,CPU register values and program counter.,C,'Each TLB entry: page number and corresponding frame'.
"During address translation using a TLB, what happens if the frame for a requested page is found in the TLB (a TLB hit)?",The system issues a page fault.,The frame is obtained directly from the TLB.,The page table must still be consulted.,The logical address is immediately used as a physical address.,The request is forwarded to the operating system kernel.,B,"According to the text, 'If in TLB: frame obtained from TLB'."
"If a frame for a given page is NOT found in the TLB during address translation (a TLB miss), where does the system retrieve the necessary information?",From the hard disk swap space.,By generating a new random frame number.,From the CPU registers.,From the page table.,By terminating the process.,D,"According to the text, 'If not in TLB: retrieve from page table'."
What is 'hierarchical paging' as described in the text?,A method of organizing pages on disk.,A technique for encrypting page table entries.,Logical address divided into multiple parts for different page table levels.,A system for prioritizing page access.,A way to back up page tables to secondary storage.,C,'Hierarchical paging: logical address divided into multiple parts for different page table levels'.
What problem is associated with hierarchical paging when logical addresses expand beyond 32 bits?,Increased TLB miss rate.,Decreased system security.,A large number of hierarchical levels.,Reduced CPU clock speed.,Incompatibility with older software.,C,The text states 'Problem with expanding addresses (beyond 32 bits): large number of hierarchical levels'.
Which of the following is a strategy mentioned to address the issue of a large number of hierarchical levels in paging for expanding addresses?,Segmented memory management.,Contiguous memory allocation.,Hashed page tables.,Static linking.,Using smaller page sizes exclusively.,C,Strategies to address this (large number of hierarchical levels): 'hashed page tables' and 'inverted page tables'.
What is the primary purpose of 'swapping' in memory management?,To reorder CPU instructions for faster execution.,To move pages to disk to increase the degree of multiprogramming.,To exchange data between CPU registers.,To ensure data integrity during power outages.,To convert logical addresses into physical addresses.,B,'Swapping: moves pages to disk to increase degree of multiprogramming'.
"How many levels of page tables does the Intel 32-bit architecture typically use, and what page sizes does it support?","One level, 2-KB or 8-KB.","Two levels, 4-KB or 4-MB.","Three levels, 1-KB or 2-KB.","Four levels, 16-KB or 64-KB.","No page tables, only segmentation.",B,Intel 32-bit architecture: 'two levels of page tables; supports 4-KB or 4-MB page sizes'.
What is 'Page-address extension' designed to allow?,32-bit processors to execute 64-bit applications.,32-bit processors to access physical address space > 4 GB.,64-bit processors to emulate 32-bit memory models.,Networking devices to extend their IP address range.,Processors to directly access hard disk sectors.,B,'Page-address extension: allows 32-bit processors to access physical address space > 4 GB'.
Which 64-bit architectures are mentioned as using hierarchical paging?,SPARC and MIPS.,PowerPC and Alpha.,x86-64 and ARM v8.,Z80 and 8086.,RISC-V and Itanium.,C,'x86-64 and ARM v8 architectures: 64-bit architectures using hierarchical paging'.
