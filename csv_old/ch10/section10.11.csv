Question,Option A,Option B,Option C,Option D,Option E,Answer,Explanation
What is the fundamental characteristic of virtual memory?,It is a hardware component that caches frequently accessed data.,It directly expands the physical RAM capacity of a system.,It abstracts physical memory into an extremely large uniform array of storage.,It is a software layer that eliminates the need for physical memory.,It manages CPU scheduling and process prioritization.,C,Virtual memory is defined as abstracting physical memory into an 'extremely large uniform array of storage'.
Which of the following is a key benefit provided by virtual memory?,Programs must be entirely loaded into physical memory before execution.,It restricts processes from sharing memory for security reasons.,It enables a program to be larger than the available physical memory.,It eliminates the need for any form of backing store for program data.,It solely focuses on optimizing disk I/O operations.,C,One of the listed benefits of virtual memory is that 'Program can be larger than physical memory'.
How does virtual memory impact the requirement for a program to be fully in memory?,It ensures the entire program is always resident in memory.,"It requires the program to be entirely in memory, but in a compressed format.",It means the program does not need to be entirely in memory to execute.,"It forces the program to be split into multiple smaller, independent executables.","It only loads the program's data segments, leaving code on disk.",C,A stated benefit is that 'Program does not need to be entirely in memory'.
"From the perspective of processes, what is a benefit facilitated by virtual memory?",Processes are completely isolated and cannot communicate or share resources.,Processes can share memory with each other.,Processes are forced to use only contiguous blocks of physical memory.,Processes can only access memory allocated to the kernel.,Processes are always allocated the same fixed amount of memory.,B,The text lists 'Processes can share memory' as a benefit of virtual memory.
In what way does virtual memory contribute to process creation?,It makes process creation more complex and time-consuming.,It allows processes to be created more efficiently.,It eliminates the need for distinct address spaces for new processes.,It requires manual memory mapping for every new process.,It restricts the number of concurrently active processes.,B,A benefit mentioned is that 'Processes can be created more efficiently'.
What is the core principle behind 'demand paging'?,All pages for a program are pre-loaded into memory before execution.,Pages are loaded into memory only when they are explicitly requested by the user.,Pages are loaded into memory only when they are demanded during program execution.,Pages are loaded based on a predictive algorithm to anticipate future needs.,"Pages are never loaded into memory; instead, they are accessed directly from backing store.",C,Demand paging is defined as 'pages loaded only when demanded during program execution'.
What is a direct consequence of using demand paging?,All pages of a program will eventually be loaded into memory.,Pages that are never demanded during execution are never loaded into memory.,The system experiences an increased number of page faults for all page accesses.,Programs must be designed to fit entirely within physical memory.,Memory access becomes significantly slower due to constant disk I/O.,B,"The text states, 'Pages never demanded are never loaded,' which is a direct consequence of demand paging."
When does a 'page fault' occur?,When a page is successfully written back to the backing store.,When a program attempts to access a page that is not currently in memory.,When the operating system is unable to allocate more physical memory.,When a program tries to access a memory location outside its allowed range.,When a new process is created and requires memory allocation.,B,A page fault 'occurs when page not in memory is accessed'.
"Upon the occurrence of a page fault, what is the required action from the system?",The process that caused the fault is immediately terminated.,The page is marked as invalid and becomes inaccessible.,The page must be brought from the backing store into an available page frame.,All other pages in memory are reloaded to prevent further faults.,The system attempts to compress the faulting page to fit it into memory.,C,"The text indicates that when a page fault occurs, the 'Page must be brought from backing store into available page frame'."
Which statement accurately describes the initial state when 'copy-on-write' is used for a child process?,The child process receives an entirely separate and independent copy of the parent's memory space.,The child process shares the same address space as the parent.,"The child process can only execute code from the parent, not its own data.","The parent process's memory is locked, preventing any modification by the child.",The child process immediately copies all read-only pages from the parent.,B,Copy-on-write specifies that 'child process shares same address space as parent'.
"Under the 'copy-on-write' mechanism, when is an actual copy of a shared page created?",Only when the parent process writes to the page.,Only when the child process writes to the page.,When either the child or the parent process attempts to modify the page.,Immediately upon the creation of the child process.,When the operating system needs to free up physical memory.,C,"The text explains, 'If child or parent modifies page, copy of page is made'."
When does a page-replacement algorithm typically select an existing page to replace?,During program initialization.,When a program explicitly requests a page swap.,When available memory is low.,After every successful page load from backing store.,Only when a process terminates.,C,Page-replacement algorithms are invoked 'When available memory low'.
What is the primary objective of a page-replacement algorithm?,To pre-load all necessary pages into memory for faster access.,To prevent any page faults from occurring during execution.,To select an existing page in memory to be swapped out.,To determine the optimal size for memory pages.,To manage the allocation of contiguous memory blocks.,C,The algorithm 'selects existing page to replace'.
Which set of algorithms are explicitly mentioned as page-replacement algorithms?,"LIFO, Random, Adaptive","FIFO, Optimal, LRU","Best Fit, First Fit, Worst Fit","Priority, Round Robin, Shortest Job First","Merge Sort, Quick Sort, Bubble Sort",B,"The text lists 'FIFO, optimal, LRU' as page-replacement algorithms."
Why is implementing pure LRU (Least Recently Used) often considered impractical?,It frequently leads to 'thrashing' due to its aggressive replacement policy.,It is conceptually too complex for modern operating systems.,It requires significant hardware or computational overhead to perfectly track page usage.,It always results in higher page fault rates compared to simpler algorithms.,It only works effectively with very small amounts of physical memory.,C,"The text states 'Pure LRU: impractical to implement; most systems use LRU-approximation algorithms,' implying the difficulty in tracking 'least recently used' perfectly."
"In a 'global page-replacement algorithm', from which set of pages can a page be chosen for replacement?",Only from the pages belonging to the currently faulting process.,Only from pages that are explicitly marked as 'dirty'.,From any process currently in memory.,Only from pages belonging to the kernel.,From pages that have been in memory for the longest time.,C,Global page-replacement algorithms 'select page from any process for replacement'.
What distinguishes a 'local page-replacement algorithm' from a global one?,Local algorithms only select pages from the operating system's internal memory.,Local algorithms select a page for replacement exclusively from the faulting process.,Local algorithms prioritize pages based on their physical location in memory.,Local algorithms are designed to minimize the total number of page faults across all processes.,Local algorithms allow pages to be replaced only if they are not shared.,B,Local page-replacement algorithms 'select page from faulting process'.
What is the definition of 'thrashing' in the context of virtual memory?,When the CPU is entirely idle due to a lack of runnable processes.,When the system spends more time executing processes than performing paging operations.,When the system spends more time paging than executing useful work.,When memory pages are consistently allocated in contiguous blocks.,"When a process exclusively accesses data within its cache, avoiding disk I/O.",C,Thrashing is defined as 'system spends more time paging than executing'.
What does the term 'locality' refer to in memory management?,The physical proximity of memory chips to the CPU.,The total amount of memory that can be accessed by a process.,A set of pages that are actively used together by a process.,The degree to which a process's memory is fragmented.,The geographical distribution of data centers in a cloud environment.,C,Locality is defined as a 'set of pages actively used together'.
How do processes generally interact with 'locality' during their execution?,"Processes remain confined to a single, fixed locality throughout their lifecycle.","Process execution involves constant, random jumps across all available memory pages.",Process execution typically moves from one locality to another over time.,Localities are only relevant during the initial loading phase of a process.,Processes do not exhibit any specific pattern related to memory access localities.,C,"The text states, 'Process execution: moves from locality to locality'."
"Based on the concept of locality, what is a 'working set'?",The maximum amount of physical memory reserved for a process.,"The complete collection of all pages associated with a program, whether loaded or not.",The set of pages currently in active use by a process.,The total number of page frames available in physical memory.,The portion of a program that resides exclusively on the backing store.,C,"Working set is defined as 'based on locality, set of pages currently in use by a process'."
What is the core operation performed by 'memory compression' as described?,It physically reduces the size of RAM modules.,It compresses multiple pages into a single page to save space.,It expands a single compressed page into several larger pages.,It encrypts memory content to secure data access.,It automatically deletes unused data from memory to free space.,B,Memory compression 'compresses number of pages into single page'.
Memory compression is mentioned as an alternative to which common virtual memory technique?,Segmentation,Caching,Swapping,Paging,Direct Memory Access (DMA),D,It is stated as an 'Alternative to paging'.
"On which types of systems is memory compression commonly utilized, especially when they lack paging support?",Large-scale enterprise servers.,High-performance computing clusters.,Desktop workstations with abundant RAM.,Mobile systems.,Traditional mainframe computers.,D,Memory compression is used 'on mobile systems without paging support'.
How is kernel memory allocation distinguished from user-mode process allocation?,"Kernel memory is always allocated in fixed, small, non-contiguous blocks.",Kernel memory is allocated using the same demand paging mechanism as user processes.,Kernel memory is allocated differently and in contiguous chunks of varying sizes.,Kernel memory is never explicitly allocated; it's a fixed part of the OS.,Kernel memory is entirely managed by user-level applications.,C,Kernel memory is 'allocated differently than user-mode processes' and 'Allocated in contiguous chunks of varying sizes'.
Which of the following describes the nature of kernel memory allocation?,It is typically non-contiguous and of uniform fixed size.,It is allocated in contiguous chunks of varying sizes.,It always uses virtual addresses that do not map to physical memory.,It is handled exclusively by hardware without software intervention.,It is designed to be easily swappable to disk.,B,Kernel memory is 'Allocated in contiguous chunks of varying sizes'.
What are the two common techniques specifically mentioned for kernel memory allocation?,First Fit and Best Fit,FIFO and LRU,Buddy system and Slab allocation,Demand Paging and Copy-on-write,Round Robin and Shortest Job First,C,The two common techniques listed are 'Buddy system' and 'Slab allocation'.
What does 'TLB reach' quantify?,The physical size of the Translation Lookaside Buffer (TLB).,The speed at which the TLB can perform address translations.,The total amount of memory that can be accessed without a TLB miss.,The number of entries available in the TLB.,The ratio of TLB hits to TLB misses.,C,TLB reach is defined as the 'amount of memory accessible from TLB'.
How is TLB reach calculated?,By dividing the total physical memory by the number of TLB entries.,By multiplying the number of entries in the TLB by the page size.,By adding the number of TLB entries to the page size.,By subtracting the TLB miss rate from the hit rate.,By summing the sizes of all active processes.,B,TLB reach is 'Equal to number of entries in TLB × page size'.
What technique is suggested to increase TLB reach?,Decreasing the page size.,Reducing the number of entries in the TLB.,Increasing the page size.,Increasing the frequency of TLB flushes.,"Using a smaller, faster CPU cache.",C,A technique to increase TLB reach is to 'increase page size'.
"How do Linux, Windows, and Solaris generally manage virtual memory, according to the text?",They utilize completely distinct and incompatible virtual memory systems.,They manage virtual memory similarly.,"Linux uses a unique approach, while Windows and Solaris are similar.",They primarily rely on memory compression instead of paging.,"They do not employ virtual memory, opting for direct physical memory access.",B,"The text states, 'Linux, Windows, Solaris: manage virtual memory similarly'."
"Which specific virtual memory techniques are common across Linux, Windows, and Solaris?","Segmentation, pure LRU, and LIFO.","Buddy system, Slab allocation, and Best Fit.","Demand paging, copy-on-write, and variations of LRU approximation (clock algorithm).","Thrashing prevention, direct memory access, and fixed-size partitions.","Memory compression, optimal page replacement, and strict memory isolation.",C,"They 'Use demand paging, copy-on-write, and variations of LRU approximation (clock algorithm)'."
