Question,Option A,Option B,Option C,Option D,Option E,Answer,Explanation
What is the primary issue addressed by the allocation of frames in an operating system?,How to distribute fixed free memory among competing processes.,How to determine the optimal size of a page for a process.,How to manage virtual memory addresses efficiently.,How to prevent deadlocks in memory access for frames.,How to reclaim memory from terminated processes only.,A,The text states the allocation issue is 'how to allocate fixed free memory among processes'.
"In a system with 128 frames where the operating system initially uses 35 frames, how many frames are typically placed on the free-frame list for user processes under a pure demand paging system?",128 frames,35 frames,93 frames,0 frames,"An unspecified number, depending on immediate demand.",C,"The example given is 128 total frames, OS takes 35, leaving 93 for user processes on the free-frame list."
"Under a pure demand paging system, what action is taken when a process experiences a page fault and free frames are available?",The process is immediately terminated.,A page-replacement algorithm is invoked.,The system allocates a free frame from the free-frame list.,The operating system takes frames from other processes.,The page is loaded from cache memory.,C,The text states that 'Page faults get free frames' from the free-frame list.
What mechanism is invoked if the free-frame list becomes exhausted when a page fault occurs?,The operating system panics and restarts.,A page-replacement algorithm is used to free a frame.,All user processes are temporarily suspended.,New frames are dynamically allocated from physical disk.,The process waits indefinitely for memory.,B,The text states: 'List exhausted → page-replacement algorithm used'.
"When a process terminates, what typically happens to the frames that were allocated to it?",They remain allocated to the process in case it restarts.,They are immediately zeroed out for security purposes.,They are returned to the free-frame list for reuse.,They are added to a special reserved pool for the OS.,They are swapped out to backing store.,C,The text states: 'Process terminates → frames back to free-frame list'.
"In some systems, the OS allocates buffer or table space from the free-frame list. How can this space be utilized when not in use by the OS?",It can be permanently locked for future OS use.,It is immediately returned to the backing store.,It can be used for user paging.,It must remain unused to prevent OS performance degradation.,It is converted into swap space.,C,The text mentions this variation: 'OS allocates buffer/table space from free-frame list (can be used for user paging when not in use)'.
A common variation in frame allocation strategy involves keeping a small number of free frames reserved. For what primary purpose are these reserved frames used?,To be immediately available for kernel operations only.,To ensure system security by holding critical data.,To quickly satisfy a page fault while a replacement frame is being selected.,To act as a buffer for network I/O operations.,To store frequently accessed system libraries.,C,"The text states: 'Keep 3 free frames reserved: free frame for page fault, replacement selected during swap'."
What is considered the basic strategy for allocating frames to a user process?,Allocating frames based on the process's priority.,Allocating frames proportionally to the process's size.,Allocating frames in a round-robin fashion.,Allocating any available free frame.,Allocating frames only from a dedicated user partition.,D,The text describes this as the 'Basic strategy: user process allocated any free frame'.
Which of the following is a constraint on frame allocation that prevents a process from acquiring too much memory?,"It must not exceed the total available frames, unless page sharing is involved.",It must be an even number of frames.,It cannot be less than the process's virtual memory size.,It is limited by the number of CPU cores available.,It must always be less than 10 frames per process.,A,One constraint listed is: 'Cannot exceed total available frames (unless page sharing)'.
"Besides not exceeding total available frames, what other fundamental constraint applies to the number of frames allocated to a process?",It must be an odd number to prevent alignment issues.,It must allocate at least a minimum number of frames for correct execution.,It must be divisible by the number of active CPUs.,It cannot be less than 100 frames for any user process.,It must be equal to the number of processes in the system.,B,The text states: 'Must allocate at least a minimum number of frames'.
What is a direct consequence of allocating fewer frames to a process for its execution?,Decreased page-fault rate and faster execution.,Higher page-fault rate and slower execution.,Increased system throughput and better resource utilization.,Reduced CPU utilization but improved I/O performance.,No significant impact on performance.,B,"The text states: 'Fewer frames → higher page-fault rate, slower execution'."
Why might an instruction need to be restarted if a page fault occurs during its execution?,The instruction's opcode itself was paged out.,The page fault occurred before the instruction could fully complete its operation.,The CPU cache was invalidated due to the fault.,The operating system always restarts processes after any page fault.,It's a security measure to prevent data corruption.,B,The text states: 'Page fault before instruction complete → instruction restart'.
What criterion must be met regarding frame allocation to ensure an instruction can complete without causing an immediate page fault?,The process must have access to all physical memory.,Enough frames must be allocated to hold all pages that the instruction can reference during its execution.,Only one frame is ever needed per instruction.,All instructions must be non-memory-referencing.,The instruction must be stored entirely in cache memory.,B,The text highlights the need for 'enough frames for all pages an instruction can reference'.
"For a single memory-reference instruction, what is the typical minimum number of frames required for a process to execute it?",One frame for the instruction.,One frame for the memory reference.,Two frames: one for the instruction and one for the memory reference.,Three frames for robustness.,"Zero frames, as instructions are executed directly by the CPU.",C,"The example given is: 'Single memory-reference instruction → 1 frame for instruction, 1 for memory reference'."
How many frames are considered the minimum necessary for a process that uses one-level indirect addressing?,One frame.,Two frames.,At least three frames.,Four frames.,Five frames.,C,The text specifies: 'One-level indirect addressing → at least 3 frames per process'.
What primarily defines the minimum number of frames that must be allocated to a process?,The current system load.,The size of the process's data segment.,The computer architecture.,The user's preference settings.,The number of concurrent processes.,C,The text explicitly states: 'Minimum frames defined by computer architecture'.
"According to the text, how many frames might be required for a complex instruction like a 'move instruction straddling two frames with two indirect operands'?",Two frames.,Three frames.,Four frames.,Six frames.,Eight frames.,D,"The example provided is: 'move instruction straddling two frames, two indirect operands → 6 frames'."
What characteristic of Intel architectures typically limits the minimum number of frames required for a process?,Their reliance on large CPU caches.,Their support for only register-to-register or memory-to-register operations.,Their use of a 64-bit address space.,Their strict adherence to the FIFO page replacement algorithm.,Their specialized hardware for handling page faults.,B,"The text states: 'Intel architectures: register-to-register/memory only, limits minimum frames'."
What ultimately defines the maximum number of frames that can be allocated in a system?,The operating system's kernel size.,The total available physical memory.,The number of active user processes.,The speed of the CPU.,The size of the swap space.,B,The text states: 'Maximum frames: defined by available physical memory'.
Which frame allocation method assigns an equal share of available frames to all requesting processes?,Proportional allocation.,Priority allocation.,Demand paging.,Equal allocation.,Local allocation.,D,"The glossary defines 'equal allocation' as assigning 'equal amounts of a resource to all requestors; in virtual memory, equal frames to each process'."
"If a system has 93 user frames available and 5 processes are running, how would frames be distributed using equal allocation, and how many would be leftover for purposes like a buffer?","20 frames each, 0 leftover.","15 frames each, 18 leftover.","18 frames each, 3 leftover.","93 frames to one process, 0 leftover for others.",Varies based on process priority.,C,"The example given is: '93 frames, 5 processes → 18 frames each, 3 leftover for buffer'."
What is a significant drawback of using equal allocation when processes have vastly different memory requirements?,It always results in system thrashing.,It favors large processes over small ones.,It can lead to wasted frames for processes with smaller memory needs.,It requires more complex scheduling algorithms.,It increases the likelihood of major page faults.,C,The text explains: 'Equal allocation (31 each) wastes frames for student process' if one is 10KB and another 127KB.
Which frame allocation method assigns page frames to processes based on their virtual memory size or 'needs'?,Equal allocation.,Proportional allocation.,Dynamic allocation.,Static allocation.,Threshold allocation.,B,The glossary defines 'proportional allocation' as assigning 'page frames in proportion to process size'.
"In proportional allocation, if $s_i$ is the virtual memory size of process $p_i$, $S$ is the total virtual memory size of all processes, and $m$ is the total available frames, which formula approximates the number of frames $a_i$ allocated to process $p_i$?",$a_i = s_i + m$,$a_i = (s_i / m) 	imes S$,$a_i \approx (s_i / S) 	imes m$,$a_i = S / s_i$,$a_i = m - s_i$,C,The text provides the formula: '$a_i \approx (s_i/S) 	imes m$ frames to $p_i$'.
"When applying proportional allocation, what are the crucial constraints on the calculated number of frames ($a_i$) for each process?","It must be a floating-point number, greater than total frames, and sum to exactly $m$.","It must be an integer, greater than minimum frames, and their sum must be less than or equal to $m$.","It must be a prime number, exactly equal to minimum frames, and sum to $S$.","It must be a multiple of 2, less than minimum frames, and sum to $s_i$.","It can be any positive number, ignoring minimum frames, and sum to more than $m$ if needed.",B,"The text states: '$a_i$ must be integer, greater than minimum frames, sum $\le m$'."
"Consider a system with 62 available frames. If one process has 10 virtual pages and another has 127 virtual pages (total 137 pages), approximately how many frames would the process with 10 virtual pages receive under proportional allocation?",10 frames,57 frames,31 frames,4 frames,1 frame,D,The calculation provided is: '(10/137) × 62 ≈ 4 frames'.
How does an increased level of multiprogramming generally affect the number of frames allocated to individual processes?,Processes gain more frames.,Processes lose frames.,The number of frames per process remains constant.,Frames are swapped to disk more frequently.,Only kernel processes are affected.,B,The text states: 'Increased level → processes lose frames'.
"Given that equal and basic proportional allocation methods treat high and low priority processes similarly, what is a proposed solution to account for process priority in frame allocation?",Mandatory use of local replacement.,Proportional allocation based on process priority or a combination of size and priority.,Exclusively using the OOM killer for low-priority processes.,Allowing only high-priority processes to access the free-frame list.,Disabling demand paging for low-priority processes.,B,The text suggests: 'Solution: proportional allocation based on process priority or size + priority'.
"In which page-replacement strategy can a process select a replacement frame from any frame in the system, even if that frame is currently allocated to another process?",Local replacement.,Static replacement.,Global replacement.,FIFO replacement.,LRU replacement.,C,"The glossary defines 'global replacement' as when a 'Process selects replacement frame from all frames in system, even if allocated to another process'."
Which page-replacement strategy limits a process to selecting a replacement frame only from its own set of allocated frames?,Global replacement.,Dynamic replacement.,Local replacement.,System-wide replacement.,Unified replacement.,C,The glossary defines 'local replacement' as when a 'Process selects replacement frame only from its own allocated frames'.
What is a direct consequence of using a global page-replacement algorithm for a process?,The process's allocated frames are guaranteed to remain constant.,The process can increase its number of frames by taking them from other processes.,The process is limited to its initial frame allocation.,It prevents any process from taking frames from another.,It always results in lower system throughput.,B,The text states: 'Global replacement: process can increase its frames by taking from others'.
What is the primary advantage of using a local replacement strategy in terms of process performance?,It maximizes system throughput.,"Process performance depends only on its own paging behavior, independent of other processes.",It allows high-priority processes to easily acquire frames from low-priority ones.,It simplifies the overall memory management system design.,It eliminates the need for a free-frame list.,B,The text states: 'Local replacement: performance depends only on its own paging behavior'.
Which page-replacement strategy is generally more common and leads to greater system throughput?,Local replacement.,Global replacement.,Hybrid replacement.,Fixed allocation.,Proportional allocation.,B,"The text states: 'Global replacement: generally greater system throughput, more common'."
What is a page fault generally defined as?,A situation where a process attempts to write to a read-only page.,An error where a page is corrupted in memory.,A reference to a page for which there is no valid logical mapping in memory.,A system crash caused by insufficient memory.,An instance where two processes try to access the same page simultaneously.,C,The text defines it as: 'Page fault: page no valid mapping'.
"In Windows operating systems, what are 'major page faults' and 'minor page faults' respectively referred to as?",Soft faults and hard faults.,Internal faults and external faults.,Hard faults and soft faults.,Kernel faults and user faults.,Primary faults and secondary faults.,C,The text states: 'Windows: hard and soft faults'.
Which type of page fault occurs when a referenced page is not in memory and requires reading data from the backing store?,Minor page fault.,Soft fault.,Non-fatal page fault.,Major page fault.,Cache fault.,D,The glossary defines 'major fault' as a 'Page fault resolved by I/O to bring page from secondary storage'.
"During the initial stages of demand paging for a new process, what type of page faults are typically observed to be high?",Minor faults.,Soft faults.,Major faults.,Cache misses.,Write-back faults.,C,The text states: 'Demand paging → initially high major faults'.
"Which type of page fault occurs when a process attempts to reference a page for which it has no logical mapping, but the page is already present in memory?",Major page fault.,Hard fault.,Secondary page fault.,Minor page fault.,Critical page fault.,D,The glossary defines 'minor fault' as a 'Page fault resolved without paging in data from secondary storage'.
One reason for a minor page fault is when a shared library is already in memory but a process does not have a mapping to it. How is this resolved?,The shared library is loaded again from disk.,The process's page table is updated to include the mapping.,The shared library is copied to the process's private memory space.,The process is terminated for attempting an invalid access.,The OS reboots the system to clear memory.,B,"The text explains: 'Shared library in memory, no mapping → update page table'."
Another reason for a minor page fault is when a page has been reclaimed to the free-frame list but has not been zeroed or reallocated. How is this particular minor fault resolved?,The page is written back to backing store.,The frame is removed from the free-frame list and reassigned to the process.,The system waits for a major page fault to occur.,The page is marked as invalid and remains on the free-frame list.,"The OS creates a new, empty frame for the process.",B,"The text explains: 'Page reclaimed to free-frame list, not zeroed/allocated → frame removed from list, reassigned'."
"In terms of time consumption, how do minor page faults compare to major page faults?",Minor faults are generally more time consuming.,Minor faults are generally less time consuming.,They are equally time consuming.,"Minor faults only consume CPU time, major faults only I/O time.",Time consumption is negligible for both.,B,The text states: 'Less time consuming than major faults'.
What Linux command is provided in the text to observe the number of minor and major page faults for processes?,`top -m`,`free -h`,"`ps -eo min_flt,maj_flt,cmd`",`vmstat 1`,`dmesg`,C,"The text explicitly gives the command: 'Linux command to observe: `ps -eo min_flt,maj_flt,cmd`'."
"What is a common observation regarding page faults on Linux systems, and what is the primary reason cited for this observation?",Both major and minor faults are consistently high due to inefficient memory management.,"Major faults are high, and minor faults are low, indicating frequent disk I/O.","Major faults are low, and minor faults are high, primarily due to heavy use of shared libraries.","Both major and minor faults are low, indicating ample physical memory.",Fault rates fluctuate wildly with no clear pattern.,C,"The text notes: 'Observation: major faults low, minor faults high. Linux processes use shared libraries heavily'."
"In a global page-replacement strategy for reclaiming pages, when are page replacements typically triggered to ensure sufficient free memory?",Only when the free-frame list is completely empty.,When the free-frame list falls below a predefined threshold.,"Periodically, regardless of the free-frame list status.",Upon system startup only.,When a process explicitly requests more memory.,B,"The text states: 'Trigger replacement when list below threshold, not at zero. Ensures sufficient free memory'."
"What is the primary purpose of triggering page replacement when the free-frame list falls below a certain threshold, rather than waiting for it to be completely exhausted?",To increase the system's susceptibility to thrashing.,To ensure a sufficient amount of free memory is always available for immediate requests.,To decrease the overall system throughput.,To force processes to use less memory.,To reduce the complexity of the page-replacement algorithm.,B,The text indicates it 'Ensures sufficient free memory'.
What are the kernel routines that scan memory and free frames to maintain a minimum amount of free memory known as?,Garbage collectors.,Memory defragmenters.,Reapers.,Page scrubbers.,Frame inspectors.,C,"The glossary defines 'reapers' as 'Routines that scan memory, freeing frames to maintain minimum free memory'."
When are 'reapers' typically triggered in a system that aims to keep free memory above a minimum threshold?,When free memory exceeds a maximum threshold.,When free memory falls below a minimum threshold.,Only during system idle periods.,After every major page fault.,Upon process termination only.,B,The text states: 'Below threshold → kernel routine (reapers) triggered'.
From which processes do reaper routines typically reclaim pages?,Only from low-priority processes.,Only from processes that are currently idle.,"From all processes, excluding the kernel.",Only from processes that have exceeded their allocated frame limit.,Only from processes that are causing thrashing.,C,The text states: 'Reclaims pages from all processes (excluding kernel)'.
What happens to a reaper routine when the amount of free memory reaches a maximum threshold?,It switches to a more aggressive page-replacement algorithm.,It increases its scanning frequency.,It is suspended until free memory falls below the minimum threshold again.,It terminates all inactive processes.,It begins writing frames to the swap space.,C,The text states: 'Reaches max threshold → reaper suspended. Resumes when free memory below min threshold'.
What page-replacement algorithm do reaper routines typically use in their continuous process of maintaining free memory?,"Pure FIFO (First-In, First-Out).",Optimal replacement.,LRU approximation.,LFU (Least Frequently Used).,Random replacement.,C,The text states: 'Reaper routine typically uses LRU approximation'.
"If a reaper routine is unable to maintain sufficient free frames using its typical algorithm, what might it do to reclaim memory more aggressively?",It will request more physical memory from the hardware.,It will notify the system administrator to manually free memory.,"It might switch to a less sophisticated but more aggressive algorithm, such as pure FIFO.",It will immediately trigger the OOM killer.,It will attempt to compress existing pages in memory.,C,"The text mentions: 'If unable to maintain free frames: reclaims more aggressively (e.g., pure FIFO)'."
"What is the Linux routine that terminates processes when free memory is critically low, in order to free up resources?",The Memory Manager.,The System Watchdog.,The Out-Of-Memory (OOM) killer.,The Process Reclaimer.,The Page Reaper.,C,The glossary defines 'out-of-memory (OOM) killer' as a 'Linux routine that terminates processes to free memory when free memory is very low'.
"In the context of the Linux OOM killer, what does a higher 'OOM score' for a process indicate?",A higher priority for receiving more memory.,A higher likelihood of being terminated by the OOM killer.,A measure of how efficiently the process uses memory.,The total amount of memory the process has ever requested.,That the process is protected from termination.,B,The text states: 'OOM score: higher score → higher termination likelihood'.
How is the OOM score for a process primarily calculated by the Linux OOM killer?,Based on its CPU utilization percentage.,Based on its total runtime.,Based on its memory usage percentage.,Based on its I/O activity.,Based on its process ID.,C,The text states: 'Calculated by memory usage percentage'.
Who is typically responsible for configuring the minimum and maximum thresholds for reaper routines in a system?,The application developer.,The end-user.,The system administrator.,The operating system kernel automatically.,The hardware manufacturer.,C,The text states: 'Min/max thresholds configurable by system administrator'.
What traditional assumption about memory access in virtual memory systems is increasingly challenged by modern multi-CPU architectures?,Memory access is always sequential.,"Memory access is always uniform in speed, regardless of CPU.",Memory access is always cached.,Memory access is limited to a single CPU core.,Memory access is managed entirely by hardware.,B,The text notes the 'Virtual memory assumption: uniform memory access. Not true for NUMA systems'.
What type of computer architecture is characterized by varying memory access times depending on which CPU core accesses the memory?,Symmetric Multiprocessing (SMP).,Uniform Memory Access (UMA).,Non-Uniform Memory Access (NUMA).,Massively Parallel Processing (MPP).,"Single Instruction, Multiple Data (SIMD).",C,The glossary defines 'non-uniform memory access (NUMA)' as an 'Architecture where memory access time varies based on CPU core'.
"In a NUMA system with multiple CPUs, how does a CPU typically access its local memory compared to memory located remotely (e.g., on another system board)?",Accesses local memory slower than remote memory.,Accesses local memory faster than remote memory.,Access times are identical for local and remote memory.,Remote memory access is not possible.,"Access speed depends solely on cache size, not location.",B,The text states: 'CPU accesses local memory faster than remote'.
"Despite memory access being slower than in uniform access systems, what primary benefit do NUMA systems offer?",They completely eliminate page faults.,"They allow for more CPUs, enabling greater throughput and parallelism.",They simplify memory management for the OS.,They reduce the total amount of physical memory required.,They are significantly cheaper to manufacture.,B,"The text states NUMA systems 'allow more CPUs, greater throughput/parallelism'."
What aspect is considered critical for performance in Non-Uniform Memory Access (NUMA) systems?,Minimizing the number of CPU cores.,Ensuring all memory is located on a single board.,Managing the page frame location effectively.,Disabling the use of virtual memory.,Increasing the frequency of I/O operations.,C,The text states: 'NUMA performance: managing page frame location critical'.
What is the primary goal of NUMA-aware allocation when a page fault occurs?,To allocate frames randomly across all available memory.,To allocate frames from the largest available memory bank.,To allocate frames 'as close as possible' to the CPU that caused the fault.,To allocate frames only from remote memory nodes.,To allocate frames only to the kernel.,C,The text states: 'NUMA-aware allocation: frames allocated 'as close as possible' to CPU'.
What specific information does a NUMA-aware scheduler track to optimize performance?,The process's total virtual memory size.,The number of page faults a process has incurred.,The last CPU on which a process executed.,The priority level of the process.,The total elapsed time since the system started.,C,The text states: 'NUMA consideration: scheduler tracks last CPU'.
"By scheduling a process on its previous CPU and allocating frames close to that CPU in a NUMA system, what two key performance metrics are primarily improved?",Increased power consumption and reduced battery life.,Reduced CPU utilization and increased I/O waiting time.,Improved cache hits and decreased memory access latency.,Higher process migration rates and increased context switching overhead.,Better disk utilization and slower network speeds.,C,"The text states: 'Schedule process on previous CPU + allocate frames close to CPU → improved cache hits, decreased memory access'."
What aspect of multi-threaded processes creates a significant memory allocation challenge in NUMA systems?,Threads are unable to share memory in NUMA.,Process threads might be scheduled and run on different system boards.,Threads consume too much CPU cache.,Threads always require more frames than single processes.,NUMA systems do not support multi-threading.,B,The text identifies: 'Threads complicate NUMA: process threads on different system boards. Memory allocation challenge'.
How does the Linux CFS scheduler address NUMA challenges related to thread migration?,It forces all threads of a process onto the same CPU.,It prevents thread migration across scheduling domains to avoid memory access penalties.,It migrates threads frequently to balance load.,It assigns a fixed memory region to each thread.,It prioritizes threads that migrate frequently.,B,The text states: 'CFS scheduler prevents thread migration across domains (avoids memory access penalties)'.
"In Linux's solution for NUMA, how is memory allocation facilitated for threads to optimize performance?","All threads share a single, large free-frame list.",Memory is allocated randomly from any available node.,"A separate free-frame list is maintained per NUMA node, allowing threads to allocate memory from their running node.",Memory is pre-allocated to threads at process startup.,Threads are not allowed to dynamically allocate memory.,C,The text states: 'Separate free-frame list per NUMA node → thread allocated memory from its running node'.
"In Solaris, what kernel construct gathers CPUs and memory into groups to optimize memory access in NUMA systems?",Memory partitions.,NUMA domains.,lgroups (locality groups).,CPU clusters.,Memory nodes.,C,The glossary defines 'lgroups' as 'Solaris locality groups in kernel; gather CPUs and memory for optimized access in NUMA'.
What is the hierarchical structure described for Solaris's lgroups?,They are organized as a flat list.,They form a strict tree structure.,"They can be nested within each other, forming a hierarchy.",They are independent and do not relate to each other.,They are formed dynamically and are non-persistent.,C,The text explicitly mentions: 'Hierarchy of lgroups'.
How does Solaris leverage its lgroups for scheduling threads and allocating memory?,It schedules threads and allocates memory randomly across all lgroups.,"It always schedules threads and allocates memory within the same lgroup; if not possible, it uses nearby lgroups.",It schedules threads in one lgroup and allocates memory in another to distribute load.,"It only uses lgroups for kernel threads, not user threads.",It ignores lgroups for memory allocation and relies on a global free list.,B,"The text states: 'Solaris schedules threads/allocates memory within lgroup; if not possible, uses nearby lgroups'."
What are the two primary benefits achieved by Solaris's lgroups strategy in a NUMA environment?,Increased memory latency and decreased CPU cache hit rates.,Maximized system downtime and reduced overall throughput.,Minimizing memory latency and maximizing CPU cache hit rates.,Simplifying hardware design and increasing power consumption.,Enabling more direct disk access and reducing network traffic.,C,"The text states: 'Minimizes memory latency, maximizes CPU cache hit rates'."
