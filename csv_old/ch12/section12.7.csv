Question,Option A,Option B,Option C,Option D,Option E,Answer,Explanation
"According to the text, what is identified as a major factor in overall system performance?",CPU clock speed,Memory bandwidth,I/O operations,Network latency,Disk storage capacity,C,The text explicitly states: 'I/O: major factor in system performance.'
Which of the following activities places heavy demands on the CPU during I/O operations?,Optimizing compiler output,Executing device-driver code and scheduling processes,Performing speculative execution,Managing virtual memory paging,Running anti-virus scans,B,"The text states that heavy demands are placed on the CPU to 'execute device-driver code, schedule processes (block/unblock).'"
"What specifically do context switches stress, according to the provided text?",Network adapters and routers,Hard disk drive platters,CPU and hardware caches,Memory RAM modules,Power supply units,C,The text indicates that 'Context switches: stress CPU and hardware caches.'
Heavy demands on I/O can expose inefficiencies in which specific kernel mechanism?,Memory management unit,File system journaling,Process scheduling algorithms,Kernel's interrupt-handling mechanisms,Network protocol stack,D,The text states that heavy I/O demands 'Exposes inefficiencies in kernel's interrupt-handling mechanisms.'
What causes the memory bus to be heavily loaded during I/O operations?,Excessive CPU clock cycles,Data copies between controllers/physical memory and kernel buffers/application space,Concurrent execution of multiple threads,Graphical rendering operations,Virtual memory swap file usage,B,"The text explains that I/O 'Loads memory bus: data copies between controllers/physical memory, and kernel buffers/application space.'"
What is identified as a major concern for computer architects regarding system performance?,Minimizing power consumption in idle states,Maximizing single-core processor speed,Graceful coping with I/O demands,Designing ergonomic computer cases,Developing new programming languages,C,The text states: 'Graceful coping with demands: major concern for computer architects.'
Why is interrupt handling considered relatively expensive?,It requires specialized hardware co-processors.,"It involves state change, execution of a handler, and state restoration.",It consumes large amounts of disk space.,"It typically runs in user space, increasing overhead.",It necessitates frequent reboots of the system.,B,"The text explains interrupt handling is expensive due to 'state change, execute handler, restore state.'"
Under what specific condition can Programmed I/O (PIO) be more efficient than interrupt-driven I/O?,When direct memory access (DMA) is fully utilized,If busy waiting is minimized,Only in real-time operating systems,When the CPU is entirely idle,If all I/O devices support asynchronous operations,B,The text states: 'Programmed I/O (PIO) can be more efficient than interrupt-driven I/O if busy waiting minimized.'
What overhead does the completion of an I/O operation lead to when it unblocks a process?,Increased memory paging,Disk defragmentation,Full context switch overhead,Network bandwidth saturation,CPU cache flushing,C,The text mentions: 'I/O completion unblocks process: leads to full context switch overhead.'
Which type of system activity is specifically noted for causing a high context-switch rate?,Running CPU-bound mathematical computations,Executing large file copies locally,Network traffic,Compiling source code,Decompressing archives,C,The text states: 'Network traffic: high context-switch rate.'
"In the remote login example, what is the very first event that occurs on the local machine when a character is typed?",A network I/O system call is issued.,The character is sent to the network device driver.,A keyboard interrupt is generated.,The user process directly receives the character.,The network layers begin packet construction.,C,The sequence described starts with: 'character typed → keyboard interrupt'.
"Following a keyboard interrupt on the local machine during a remote login, what is the correct sequence of components the character passes through before reaching the user process?",Device driver → Interrupt handler → Kernel,Interrupt handler → Device driver → Kernel,Kernel → Interrupt handler → Device driver,Device driver → Kernel → Interrupt handler,Interrupt handler → Kernel → Device driver,B,The text describes the path as: 'keyboard interrupt → interrupt handler → device driver → kernel → user process'.
"After the character reaches the user process on the local machine in a remote login, what is the next step initiated by the user process for network communication?",It directly transfers the character to the network controller.,It waits for an interrupt from the remote system.,It issues a network I/O system call.,It unpacks the character from network protocols.,It generates a keyboard interrupt.,C,The text states: 'User process issues network I/O system call'.
"In the remote login process, which component is responsible for packet construction after a network I/O system call is issued by the user process?",The local kernel,The network device driver,The network layers,The remote system's network hardware,The keyboard interrupt handler,C,The text outlines the path: 'local kernel → network layers (packet construction)'.
"After the network device driver transfers the packet to the controller in the remote login process, what subsequent actions occur?",The system call immediately completes.,The character is unpacked from protocols.,"The packet is sent, and an interrupt is generated.",The network daemon identifies the session.,The remote system echoes the character.,C,"The text specifies: 'Network device driver transfers packet to controller → sends character, generates interrupt.'"
What event signals the completion of the network I/O system call in the remote login process on the local machine?,The user process terminating.,An interrupt coming back up through the kernel.,The character being echoed by the remote system.,The local machine's network hardware receiving an acknowledgment.,The network device driver restarting.,B,The text states: 'Interrupt back up through kernel → network I/O system call completes.'
What is the initial event that occurs on the remote system upon receiving a packet in the remote login example?,The character is immediately unpacked.,An interrupt is generated.,The network daemon identifies the session.,The packet is passed to a subdaemon.,The character is echoed back to the sender.,B,The text states: 'Remote system: network hardware receives packet → interrupt generated.'
"On the remote system, after the character is unpacked from protocols, to which component is it passed?",The kernel's interrupt handler,The appropriate network daemon,The user process,The device driver,The memory bus,B,The text indicates: 'Character unpacked from protocols → appropriate network daemon.'
"After receiving the unpacked character, what is the primary action of the network daemon on the remote system in the remote login process?",It directly sends the character back to the local machine.,It constructs a new network packet.,It identifies the session and passes the packet to a subdaemon.,It generates another interrupt.,It stores the character in a temporary buffer.,C,The text describes: 'Network daemon identifies session → passes packet to subdaemon.'
What types of system overheads are frequently observed throughout the entire remote login process described?,Disk thrashing and page faults,CPU starvation and memory leaks,Context switches and state switches,Network latency and bandwidth contention,Power spikes and thermal throttling,C,The text explicitly states: 'Throughout: context switches and state switches.'
What action in the remote login process is specifically mentioned as doubling the work?,Packet retransmission due to errors,The initial keyboard interrupt generation,The receiver echoing the character,The local kernel processing the system call,The network device driver transferring the packet,C,The text notes: 'Receiver echoes character: doubles work.'
Some systems use separate 'front-end processors' for terminal I/O. What is their primary purpose in this context?,To accelerate graphical rendering,To reduce the main CPU's interrupt burden,To manage complex database queries,To perform cryptographic calculations,To act as a backup power supply,B,The text states: 'Some systems use separate front-end processors for terminal I/O to reduce main CPU interrupt burden.'
What is the function of a 'terminal concentrator'?,It converts analog signals to digital ones.,It encrypts data transmissions for security.,It multiplexes traffic from hundreds of remote terminals into one port.,It provides power over Ethernet to connected devices.,It isolates network segments for improved privacy.,C,The glossary defines 'terminal concentrator' as a device that 'multiplexes traffic from hundreds of remote terminals into one port.'
What is an 'I/O channel' in the context of mainframes and high-end systems?,A physical data cable connecting two systems.,"A dedicated, special-purpose CPU for I/O or offloading the main CPU.",A software interface for network communication.,A component responsible for managing printer queues.,A shared memory region for inter-process communication.,B,"The glossary defines 'I/O channel' as a 'dedicated, special-purpose CPU in large systems for I/O or offloading main CPU.'"
What are the primary jobs of an I/O channel in a computing system?,To perform CPU-intensive computations and run user applications.,To manage system security and user authentication.,To offload I/O work from the main CPU and keep data flowing smoothly.,To monitor network traffic and detect intrusions.,To execute operating system kernel functions exclusively.,C,"The text specifies the 'Channel job: offload I/O work from main CPU, keep data flowing smoothly.'"
How do I/O channels differ from simpler I/O mechanisms in terms of program processing capability?,"They can only process simple, pre-defined commands.",They are limited to handling only keyboard and mouse inputs.,"They process more general/sophisticated programs, tuned for workloads.",They require direct intervention from the main CPU for every instruction.,They are designed to handle only network protocols.,C,"The text states: 'Channels process more general/sophisticated programs, tuned for workloads.'"
Which of the following is listed as a principle to improve I/O efficiency?,Increase the number of context switches.,Increase data copies in memory.,Reduce interrupt frequency.,Decrease concurrency.,Keep processing primitives in software.,C,One of the principles to improve I/O efficiency listed is 'Reduce interrupt frequency'.
"To improve I/O efficiency, what type of data movement in memory should be reduced?",Data copies between the device and application.,Data transfers within the CPU registers.,Data written to the CPU's L1 cache.,Data sent to the display adapter.,Data moved to the swap file.,A,One principle for I/O efficiency is to 'Reduce data copies in memory (between device/application).'
How can interrupt frequency be reduced to improve I/O efficiency?,By increasing the frequency of small data transfers.,"By utilizing simple, unintelligent controllers.",By always using interrupt-driven I/O exclusively.,"By using large transfers, smart controllers, or polling (if busy waiting minimal).",By offloading all I/O processing to the main CPU.,D,"The text suggests to 'Reduce interrupt frequency: use large transfers, smart controllers, polling (if busy waiting minimal).'"
"For improved I/O efficiency, under what specific condition can polling be an effective method to reduce interrupt frequency?",When the CPU is heavily loaded.,If busy waiting is minimized.,Only when direct memory access is disabled.,When network traffic is extremely high.,If the system uses a single-core processor.,B,The text mentions polling as a way to reduce interrupt frequency 'if busy waiting minimal'.
"How can concurrency be increased for I/O efficiency, according to the text?",By dedicating the main CPU solely to data copying.,By using DMA-knowledgeable controllers/channels to offload data copying from CPU.,By forcing all I/O operations to be synchronous.,By reducing the number of available I/O devices.,By disabling interrupt coalescing.,B,To 'Increase concurrency' one should 'use DMA-knowledgeable controllers/channels to offload data copying from CPU.'
"To achieve concurrent operation with the CPU and bus, what processing primitives should be moved into hardware?",Operating system schedulers,Application-level error handling routines,I/O processing primitives,User interface rendering logic,Network routing tables,C,The text suggests to 'Move processing primitives into hardware: concurrent operation with CPU/bus.'
"What is crucial for overall system performance regarding CPU, memory subsystem, bus, and I/O performance?",Maximizing the performance of only the fastest component.,"Balancing their performance, as overload in one area causes idleness in others.",Minimizing the usage of all components to save power.,Configuring them to operate entirely independently.,Prioritizing CPU performance above all else.,B,"The text emphasizes: 'Balance CPU, memory subsystem, bus, I/O performance: overload in one area causes idleness in others.'"
Which of the following pairs correctly exemplifies the varying complexity of I/O devices as mentioned in the text?,Printer (simple) vs. Mouse (complex),Keyboard (complex) vs. USB drive (simple),Mouse (simple) vs. Windows disk driver (complex),Scanner (complex) vs. Webcam (simple),Speaker (simple) vs. Microphone (complex),C,"The text explicitly uses 'mouse simple, Windows disk driver complex' as examples."
"Which of these is NOT a functionality managed by a Windows disk driver, according to the text?",Managing individual disks,Implementing RAID arrays,Converting requests to disk I/O,Executing user applications,Performing error handling and data recovery,D,"The text lists managing individual disks, implementing RAID, converting requests, error handling, data recovery, and optimizing performance as functionalities of a Windows disk driver, but not executing user applications."
What are the three main locations where I/O functionality can be implemented?,"Cloud servers, virtual machines, bare metal.","Device hardware, device driver, application software.","CPU, GPU, network card.","Input, processing, output units.","BIOS, operating system, user applications.",B,"The text asks: 'Where to implement I/O functionality: device hardware, device driver, or application software?'"
Where were experimental I/O algorithms initially implemented due to their flexibility and lower risk of system crashes?,Directly in the device hardware,Within the operating system kernel,At the application level,In a specialized I/O channel,As firmware on the I/O controller,C,The text states: 'Initially: experimental I/O algorithms at application level.'
What is an advantage of implementing I/O algorithms at the application level?,Highest possible performance due to direct hardware access.,No need to reboot/reload drivers after code changes.,Access to internal kernel data and functionality.,Guaranteed data integrity across system restarts.,Automatic optimization by the operating system.,B,An advantage listed for application-level implementation is: 'No reboot/reload drivers after code changes.'
Which of the following is a disadvantage of implementing I/O algorithms at the application level?,They are more challenging to debug.,They can easily crash the entire system.,They require specialized hardware.,They are inefficient due to context switch overhead.,They increase development time significantly.,D,"The text identifies a disadvantage as: 'Inefficient: context switch overhead, no internal kernel data/functionality (messaging, threading, locking).'"
"What is cited as an example of a system interface that allows user-mode file systems, demonstrating application-level I/O functionality?",PCI Express (PCIe),Direct Memory Access (DMA),FUSE system interface,Advanced Host Controller Interface (AHCI),Network File System (NFS),C,The text provides 'FUSE system interface' as an example of user-mode file systems.
"Once I/O algorithms are proven stable and effective at the application level, where are they typically reimplemented to improve performance?",In cloud-based services,Directly into dedicated hardware chips,Into the operating system kernel,As part of a virtual machine monitor,Within the CPU's microcode,C,The text states: 'When proven: reimplement in kernel.' for improved performance.
What is a key benefit of reimplementing I/O functionality in the kernel?,It becomes easier to debug.,It significantly improves performance.,It removes the need for context switches.,It makes the system entirely crash-proof.,It simplifies hardware interactions.,B,A stated benefit of kernel-level implementation is that it 'Improves performance.'
Why is development for kernel-level I/O considered more challenging?,It requires less complex programming languages.,The kernel is typically large and complex.,Debugging tools are more advanced.,It allows for greater flexibility in I/O ordering.,It can be deployed without system reboots.,B,"The text notes: 'More challenging development (large, complex kernel).'"
Why is thorough debugging crucial for I/O functionality implemented in the kernel?,To ensure compatibility with legacy hardware.,To prevent data corruption and system crashes.,To optimize network latency for web applications.,To reduce the physical size of the kernel.,To increase the aesthetic appeal of the operating system.,B,"The text highlights the need to 'Must be thoroughly debugged (avoid data corruption, system crashes).'"
Where does I/O functionality achieve the highest performance?,Application-level software,Cloud-based virtual machines,Specialized implementation in hardware (device or controller),Kernel-level device drivers,Firmware embedded in the CPU,C,The text states: 'Highest performance: specialized implementation in hardware (device or controller).'
What is a disadvantage of implementing I/O functionality directly in hardware?,It offers superior flexibility for customization.,It significantly reduces development time.,It is difficult and expensive to improve or fix bugs.,It requires frequent software updates.,It increases context switch overhead.,C,Disadvantages listed for hardware implementation include: 'difficulty/expense of improvements/bug fixes.'
How does hardware-level I/O implementation affect development time compared to software implementations?,It significantly reduces development time to days.,It has no impact on development time.,"It leads to increased development time, often months instead of days.","It allows for continuous, real-time code changes.",It requires only a single developer.,C,The text states 'Increased development time (months vs. days)' as a disadvantage of hardware implementation.
"What is a consequence of implementing I/O functionality at the hardware level, as exemplified by a hardware RAID controller?",Increased flexibility for the kernel to influence I/O order.,Decreased flexibility for the kernel to influence I/O order/location.,Elimination of all interrupt handling overhead.,Automatic detection and correction of all software bugs.,Lower cost for improvements and bug fixes.,B,"A consequence is 'Decreased flexibility (e.g., hardware RAID controller may not allow kernel to influence I/O order/location).'"
"What trend is observed regarding the speed of I/O devices, particularly NVM devices?",They are becoming slower to conserve power.,They are reaching the speeds of traditional HDDs.,"They are increasing in speed, with NVM devices nearing DRAM speed.",Their speed is becoming irrelevant to overall system performance.,They are limited by the speed of the CPU clock.,C,The text notes: 'I/O devices increasing in speed (NVM devices nearing DRAM speed).'
The increasing speed of I/O devices places greater pressure on which components or aspects of a system?,Only on the CPU's processing power.,On I/O subsystems and OS algorithms to leverage read/write speeds.,On the amount of physical memory installed.,On the monitor's refresh rate.,On the power supply's wattage output.,B,Increasing device speed 'Increases pressure on I/O subsystems and OS algorithms to leverage read/write speeds.'
Which of the following components are listed as important for I/O performance related to storage and network latency?,"Printers, scanners, microphones.","CPU, caches, DRAM, NVM, PCIe, SSD, SAA, HDD.","User interface, graphic drivers, audio codecs.","Web browsers, office suites, video players.","Keyboards, mice, joysticks.",B,"The text lists: 'CPU, caches, DRAM, NVM, PCIe, SSD, SAA, HDD' as important for I/O performance of storage and network latency."
What is the definition of 'front-end processors'?,Main CPUs responsible for all system tasks.,"Small computers performing tasks in the overall system; managing I/O, offloading CPU.",Software applications that handle user input.,Memory modules used for temporary data storage.,Graphical processing units designed for rendering.,B,"The glossary defines 'front-end processors' as 'Small computers performing tasks in overall system; manage I/O, offload CPU.'"
What describes a 'terminal concentrator'?,A type of server rack for multiple terminals.,A device that consolidates network cables.,A type of front-end processor for terminals.,A software utility for terminal emulation.,A power distribution unit for remote devices.,C,The glossary defines 'terminal concentrator' as 'Type of front-end processor for terminals.'
What is an 'I/O channel' as defined in the glossary?,A general-purpose CPU for desktop computers.,A network switch used in large data centers.,"A dedicated, special-purpose CPU in large systems for I/O or offloading the main CPU.",A software library for input/output operations.,A bus architecture for connecting peripheral devices.,C,"The glossary defines 'I/O channel' as a 'Dedicated, special-purpose CPU in large systems for I/O or offloading main CPU.'"
