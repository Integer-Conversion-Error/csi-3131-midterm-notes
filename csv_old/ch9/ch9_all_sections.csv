Question,Option A,Option B,Option C,Option D,Option E,Answer,Explanation
What is the primary purpose of a computer system as it relates to memory management?,To manage network connections efficiently.,To execute programs.,To provide a user-friendly graphical interface.,To store data long-term on secondary storage.,To prevent unauthorized access to system resources.,B,"The text states, ""Main purpose of computer system: execute programs."""
"For a program to be executed in a modern computer system, where must its programs and data reside, at least partially?",On a solid-state drive (SSD).,In the CPU registers exclusively.,Partially in main memory.,Fully in the hard disk cache.,In a dedicated graphics processing unit (GPU).,C,"The text specifies, ""Programs and data must be partially in main memory during execution."""
How do modern computer systems typically handle multiple processes concerning memory?,Only one process is allowed in memory at a time.,Processes are exclusively stored on secondary storage.,Several processes are maintained concurrently in memory.,Processes are loaded into memory only upon completion of the previous one.,Memory is cleared entirely before loading any new process.,C,"The text states, ""Modern systems maintain several processes in memory."""
What is a common requirement for most memory-management algorithms to function effectively?,Extensive user configuration.,High-speed internet connectivity.,Specific hardware support.,A large number of CPU cores.,Software-only implementation without hardware intervention.,C,"The text mentions, ""Most algorithms require hardware support."""
What two key aspects are improved by sharing the CPU among multiple processes through CPU Scheduling?,Network bandwidth and data encryption.,CPU utilization and response speed.,Disk storage capacity and file compression.,Graphics rendering and audio processing.,Power consumption and thermal output.,B,"The text states that CPU sharing ""Improves CPU utilization and response speed."""
What is necessitated by the sharing of the CPU among multiple processes to improve utilization and response speed?,Reducing the number of active processes.,Keeping many processes in memory simultaneously.,Exclusive use of virtual memory.,Disabling memory protection mechanisms.,Storing all process data on external storage.,B,"The text indicates that CPU sharing ""Requires keeping many processes in memory (sharing memory)."""
"What factors influence the selection of a particular memory management approach, according to the text?",The brand of the operating system.,The amount of available hard disk space.,The specific hardware design.,The programming language used for the applications.,The number of concurrent network connections.,C,"The text mentions, ""Selection depends on hardware design."""
What is a common characteristic of modern memory management in terms of its implementation?,It is solely managed by user applications.,It is entirely a software responsibility.,It involves an integrated hardware/OS approach.,It relies only on external peripheral devices.,It functions without any direct CPU involvement.,C,"The text states, ""Many algorithms require hardware support; integrated hardware/OS memory management common."""
What is memory's role in the operation of a modern computer system?,It is a secondary component used only for archiving.,It serves as a temporary buffer for network traffic.,It is central to the operation.,It primarily stores system configuration files.,It is used only when the hard drive is full.,C,"The text states, ""Memory central to modern computer system operation."""
How is memory described in the context of a computer system?,A hierarchical tree structure.,"A large array of bytes, each with its own address.",A continuous stream of unindexed data.,"A collection of independent, isolated storage units.",A stack-based system without direct addressing.,B,"The text describes memory as a ""large array of bytes, each with its own address."""
Which CPU component is responsible for indicating the next instruction to be fetched from memory?,The instruction register.,The general-purpose register.,The program counter.,The memory-address register.,The status register.,C,"The text says, ""CPU fetches instructions from memory (program counter)."""
"When the memory unit receives a stream of addresses, what does it know about their generation or purpose?",It knows the exact purpose but not the generation.,It knows both the generation and purpose of each address.,It knows neither the generation nor the purpose.,It can differentiate between data and instruction addresses.,It only knows if the address is valid or invalid.,C,"The text explicitly states, ""Memory unit sees stream of addresses; doesn't know generation or purpose."""
What are the only two general-purpose storage types that the CPU can access directly?,Hard disk drives and solid-state drives.,Cache memory and secondary storage.,Main memory and registers.,Optical disks and USB drives.,Network-attached storage and cloud storage.,C,"The text states, ""Main memory and registers: only general-purpose storage CPU can access directly."""
How quickly are CPU registers typically accessible by the CPU?,Within multiple CPU clock cycles.,Within a single CPU clock cycle.,Slower than main memory.,Only after a significant delay.,"Through the memory bus, similar to main memory.",B,"The text indicates, ""Registers: accessible within one CPU clock cycle."""
"How is main memory typically accessed, and what is its characteristic access time relative to CPU cycles?",Directly by the CPU within one clock cycle.,"Via the memory bus, taking many CPU cycles.","Only through the cache, making it instantly available.",Through a direct connection to secondary storage.,By bypassing the CPU and directly interacting with I/O devices.,B,"The text says, ""Main memory: accessed via memory bus; may take many CPU cycles."""
"What is the primary cause for a processor to stall, and what is the common hardware remedy for this?",Excessive I/O operations; adding more hard drives.,Waiting for data from main memory; adding a fast cache.,Insufficient power supply; upgrading the power unit.,Software bugs; implementing stricter code reviews.,Network latency; improving internet connection speed.,B,"The text states, ""Processor may stall waiting for data. Remedy: add fast memory (cache) between CPU and main memory."""
Who or what is responsible for managing the cache to speed up memory access?,"The operating system, through specific device drivers.","The user, by manually optimizing memory usage.","The hardware, automatically, without OS control.","The application software, by pre-fetching data.",A dedicated kernel module requiring explicit configuration.,C,"The text specifies, ""Cache management: hardware automatically speeds up memory access (no OS control)."""
"In a multithreaded core, what action can be taken during a memory stall?",The core can power down to conserve energy.,The core can switch to a different thread.,The core must wait idly until the data arrives.,The core initiates a disk defragmentation process.,The core requests the operating system to increase clock speed.,B,"The text mentions, ""Multithreaded core can switch threads during memory stall."""
"What are the main concerns regarding the correct operation and protection in memory management, particularly handled by hardware?",Protecting network traffic and peripheral devices.,Protecting the OS from user processes and user processes from each other.,Protecting against physical damage to memory modules.,Protecting user data from accidental deletion.,Protecting the CPU from overheating.,B,"The text states, ""Concern: correct operation, protection of OS from user processes, user processes from each other."" It also notes, ""Protection by hardware (OS doesn't intervene for performance)."""
What is required for each process to ensure protection and concurrent execution?,Exclusive access to the entire main memory.,A shared memory space with all other processes.,A separate memory space.,Direct access to kernel memory.,The ability to modify any memory address.,C,"The text states, ""Each process needs separate memory space for protection and concurrent execution."""
How is memory protection typically implemented using hardware registers?,By using a single register to store all valid addresses.,By a combination of a base register and a limit register.,By relying solely on software checks at every memory access.,By encrypting all memory addresses before use.,By assigning a unique password to each memory block.,B,"The text explains, ""Implementation: base register (smallest legal physical memory address) and limit register (size of range)."""
"In memory protection using registers, what does the base register define?",The maximum legal physical memory address.,The total size of the allowed memory range.,The smallest legal physical memory address.,The number of active processes in memory.,The address of the next instruction to be executed.,C,"The text defines base register as ""smallest legal physical memory address."""
"In memory protection using registers, what does the limit register define?",The starting address of the program in memory.,The maximum number of instructions allowed.,The size of the memory range.,The last physical address accessible.,The virtual address translation offset.,C,"The text defines limit register as ""size of range."""
What action does the CPU hardware take with every address generated in user mode concerning memory protection?,It logs the address for debugging purposes.,It automatically converts it to a virtual address.,It compares it with the base and limit registers.,It transmits it directly to the memory bus.,It encrypts the address for security.,C,"The text states, ""CPU hardware compares every address generated in user mode with registers."""
"What happens if a user process attempts to access memory outside its legal range, specifically OS or other user memory?",The access is silently redirected to a safe area.,A warning message is displayed to the user.,"A trap to the OS occurs, indicating a fatal error.",The operating system automatically corrects the address.,The process is paused indefinitely until manual intervention.,C,"The text says, ""Attempt to access OS/other user memory â†’ trap to OS (fatal error)."""
What is the primary purpose of memory protection using base and limit registers?,To improve CPU performance by pre-fetching data.,To prevent accidental or deliberate modification of OS or other user code/data.,To allocate memory dynamically for growing processes.,To ensure data is written to disk before system shutdown.,To facilitate network communication between processes.,B,"The text states it ""Prevents accidental/deliberate modification of OS/other user code/data."""
Who or what has the exclusive privilege to load the base and limit registers?,"Any user process, in user mode.","The CPU hardware, automatically.","The operating system, using a privileged instruction in kernel mode.","The compiler, during program compilation.",The network administrator.,C,"The text says, ""Base/limit registers loaded only by OS (privileged instruction, kernel mode)."""
How much access does the operating system have to OS and user memory?,"Limited access, only through system calls.",Read-only access to user memory.,No access to user memory for security reasons.,Unrestricted access.,Access only during system boot-up.,D,"The text clarifies, ""OS has unrestricted access to OS/user memory."""
What are the initial steps for a program stored as a binary executable on disk to become eligible for execution?,It must be sent over the network to a central server.,It must be compressed and archived.,"It is brought into memory, placed in process context.",It needs to be manually converted into source code.,It requires a complete system reboot.,C,"The text states, ""To run: brought into memory, placed in process context, eligible for execution."""
What happens to the memory occupied by a process when it terminates?,It remains reserved for that process in case of restart.,It is released back to the operating system (reclaimed).,It is immediately overwritten by another process.,It is permanently marked as unusable.,It is automatically saved to disk as a hibernation file.,B,"The text notes, ""Terminates: memory reclaimed."""
Where can a user process reside in physical memory in most modern systems?,"Only at a fixed, predefined address.",Anywhere in physical memory.,Only in the lowest available memory addresses.,"In a dedicated, unmovable section of memory.","Exclusively in virtual memory, not physical.",B,"The text states, ""Most systems: user process can reside anywhere in physical memory."""
What type of address binding is performed by the compiler?,Binding symbolic addresses to absolute addresses.,Binding relocatable addresses to physical addresses.,Binding symbolic addresses to relocatable addresses.,Binding physical addresses to logical addresses.,Binding logical addresses to virtual addresses.,C,"The text says, ""Compiler binds symbolic to relocatable ('14 bytes from module start')."""
What type of address binding is performed by the linker/loader?,Binding relocatable addresses to absolute addresses.,Binding symbolic addresses to relocatable addresses.,Binding absolute addresses to physical addresses.,Binding virtual addresses to logical addresses.,Binding physical addresses to symbolic addresses.,A,"The text says, ""Linker/loader binds relocatable to absolute (e.g., 74014)."""
"What is the general definition of ""binding"" in the context of address spaces?",The process of encrypting data for security.,The act of compressing a file to save space.,Mapping from one address space to another.,Allocating a fixed block of memory.,Defragmenting storage media.,C,"The text defines binding as ""mapping from one address space to another."""
"When is ""absolute code"" generated for a program?",If the process can move during execution.,If the process location is unknown at compile time.,If the process location is known at compile time.,"During the linking phase, regardless of location.",Only for programs written in assembly language.,C,"The text states, ""Compile time: If process location known, absolute code generated."""
What type of code does the compiler generate if the process's starting location in memory is unknown at compile time?,Absolute code.,Relocatable code.,Virtual code.,Static code.,Position-dependent code.,B,"The text states, ""Load time: If process location unknown at compile time, compiler generates relocatable code."""
Under what condition is address binding delayed until run time?,If the program is very small.,If the program requires extensive I/O operations.,If the process can move during execution.,If the system has limited physical memory.,If the program uses only static libraries.,C,"The text states, ""Execution time: If process can move during execution, binding delayed until run time."""
What is the term for an address generated by the CPU?,Physical address.,Memory-address register.,Absolute address.,Logical address.,Hardware address.,D,"The text defines ""logical address"" as ""Address generated by CPU."""
"What is the term for the address seen by the memory unit (i.e., loaded into the memory-address register)?",Logical address.,Virtual address.,Relocatable address.,Physical address.,Symbolic address.,D,"The text defines ""physical address"" as ""Address seen by memory unit (loaded into memory-address register)."""
When is the logical address identical to the physical address?,Only with execution-time binding.,"Always, in all modern systems.",With compile-time or load-time binding.,When using dynamic linking.,Only in systems without an MMU.,C,"The text states, ""Compile/load time binding: identical logical and physical addresses."""
When do logical and physical addresses differ?,During static linking.,During compile-time binding.,During load-time binding.,During execution-time binding.,When using a simple base register scheme without relocation.,D,"The text states, ""Execution-time binding: differing logical and physical addresses."""
What is another common name for a logical address?,Absolute address.,Relocation address.,Virtual address.,Hardware address.,System address.,C,"The text states, ""Logical address also called virtual address."""
What is defined as the set of all logical addresses generated by a program?,Physical address space.,Virtual memory.,Relocation register.,Logical address space.,Cache memory.,D,"The text defines ""logical address space"" as ""set of all logical addresses generated by program."""
What is defined as the set of all physical addresses corresponding to logical addresses?,Logical address space.,Virtual address.,Physical address space.,Main memory.,Secondary storage.,C,"The text defines ""physical address space"" as ""set of all physical addresses corresponding to logical addresses."""
What hardware component performs the run-time mapping from virtual to physical addresses?,The CPU's arithmetic logic unit (ALU).,The disk controller.,The memory-management unit (MMU).,The network interface card (NIC).,The graphics processing unit (GPU).,C,"The text states, ""Run-time mapping (virtual to physical): done by memory-management unit (MMU)."""
"In a simple MMU scheme, what is the base register also called, and how does it function in address translation?",It's called the limit register and defines the size of the memory range.,It's called the program counter and points to the next instruction.,"It's called the relocation register, and its value is added to every logical address.",It's called the cache register and stores frequently accessed data.,It's called the stack pointer and manages function calls.,C,"The text explains, ""Base register called relocation register. Value in relocation register added to every address generated by user process."""
"In a system with memory-mapping hardware, how does a user program access real physical addresses?",It directly manipulates physical addresses.,"It accesses them indirectly, through the kernel.",It never directly accesses real physical addresses.,It accesses them only during program loading.,It retrieves them from a system-wide lookup table.,C,"The text says, ""User program never accesses real physical addresses. Program deals with logical addresses."""
When is the final location of a referenced memory address determined in a system with memory-mapping hardware?,At compile time.,At load time.,At system boot time.,At reference time (run time).,During static linking.,D,"The text states, ""Final location of referenced memory address determined at reference time."""
What was the limitation of program execution in traditional systems regarding memory?,Programs could only run in virtual memory.,Process size was limited by physical memory size.,Only one program could reside in memory at a time.,Programs had to be entirely resident on disk.,Memory was not directly accessible by programs.,B,"The text notes, ""Traditionally: entire program and data in physical memory for execution. Process size limited by physical memory size."""
What is the primary advantage of employing dynamic loading?,To reduce CPU clock cycles.,To improve network latency.,To achieve better memory-space utilization.,To simplify compiler design.,To eliminate the need for an operating system.,C,"The text states, ""Better memory-space utilization: dynamic loading."""
How does a routine behave in a system utilizing dynamic loading?,"It is loaded when the process starts, regardless of use.",It is never loaded into main memory.,It is loaded only when called.,It is executed directly from disk.,It requires manual intervention to load.,C,"The text explains, ""Routine not loaded until called."""
For what kind of program components is dynamic loading particularly useful?,Core functionalities used constantly.,"Small, frequently accessed data structures.","Large code amounts handling infrequent cases (e.g., error routines).",Kernel modules that must be loaded at boot.,Device drivers for essential hardware.,C,"The text notes, ""Useful for large code amounts handling infrequent cases (e.g., error routines)."""
What level of operating system support is generally required for dynamic loading?,Mandatory and extensive kernel modifications.,Explicit user-mode APIs and complex system calls.,No special OS support; it's user responsibility.,Real-time scheduling algorithms.,A dedicated hardware co-processor.,C,"The text says, ""Dynamic loading: no special OS support required (user responsibility)."" It also adds, ""OS may help by providing library routines for dynamic loading."""
What are Dynamically Linked Libraries (DLLs)?,User-created libraries compiled directly into the program.,System libraries combined by the loader into the binary image at compile time.,"System libraries linked to user programs at run time, with linking postponed until execution.",Static libraries that are always resident in memory.,Libraries used exclusively for network communication.,C,"The text defines DLLs as ""System libraries linked to user programs at run time; linking postponed until execution time."""
What is Static Linking?,Libraries linked at runtime based on demand.,"System libraries treated like object modules, combined by loader into binary program image.",Libraries that are recompiled every time a program runs.,A method for remote procedure calls.,A process of encrypting library files.,B,"The text defines ""Static linking"" as ""system libraries combined by loader into binary program image."""
What is a consequence of programs not using Dynamically Linked Libraries (DLLs)?,Reduced executable size.,Improved memory utilization.,Each program includes a copy of the language library in its executable image.,Programs can share a single instance of the library.,Linking is always postponed until execution time.,C,"The text states, ""Without DLLs: each program includes copy of language library in executable image. Increases executable size, wastes main memory."""
"What is a significant advantage of Dynamically Linked Libraries (DLLs) related to memory usage, also leading to them being called ""shared libraries""?",They are faster to load initially.,They eliminate the need for memory protection.,"They are shared among multiple processes, with one instance in memory.",They allow direct access to hardware registers.,They can only be used by a single process at a time.,C,"The text highlights, ""Second advantage of DLLs: shared among multiple processes (one instance in memory). Also known as shared libraries."""
"When a program references a dynamic library routine, what does the loader do?",It immediately copies the entire library into the program's memory space.,"It locates the DLL and loads it if needed, then adjusts addresses.",It sends a request to the network server to download the routine.,It re-compiles the entire program from source code.,It converts the dynamic library into a static library.,B,"The text states, ""Program references dynamic library routine: loader locates DLL, loads if needed. Adjusts addresses referencing DLL functions to DLL's memory location."""
How do Dynamically Linked Libraries (DLLs) facilitate library updates and bug fixes?,Programs must be manually recompiled to incorporate changes.,The old library version is always kept for backward compatibility.,"When the library is replaced by a new version, all referencing programs automatically use it.",Updates are applied only at system boot time.,DLLs prevent any future library updates.,C,"The text explains, ""Library replaced by new version: all referencing programs automatically use new version."""
How do systems using dynamic linking typically handle incompatible library versions?,"They force all programs to use the newest version, regardless of compatibility.",Only one library version can be loaded into memory at a time.,"Version information is stored, allowing multiple library versions to be loaded, with programs using their specific version info.",Incompatible versions cause system crashes.,Programs must be patched to work with new incompatible versions.,C,"The text mentions, ""Version information in program/library to prevent incompatible versions. Multiple library versions loaded; program uses its version info."" And ""Only programs compiled with new library version affected by incompatible changes. Programs linked before new library: continue using older."""
"What level of operating system help is generally required for dynamic linking and shared libraries, especially when processes are protected?",None; it's purely a user-space implementation.,"Minimal, restricted to file loading.","Significant, including checking if routines are in other processes' memory and allowing shared access.",It only involves setting up network communication.,It's handled entirely by the compiler during program generation.,C,"The text states, ""Dynamic linking/shared libraries: generally require OS help. If processes protected: OS checks if routine in another process's memory, allows multiple processes to access same addresses."""
"According to the provided text, what does the term ""stall"" refer to in the context of CPU operation?",A state where the CPU is performing complex calculations.,"A CPU state when the CPU is waiting for data from main memory, delaying execution.",A condition where the CPU is idle due to lack of tasks.,A process of saving CPU state to disk.,A power-saving mode activated by the OS.,B,"The glossary defines ""stall"" as ""CPU state when CPU waiting for data from main memory, delays execution."""
"What is the primary function of a ""cache"" in a computer system, as defined in the glossary?",To provide long-term storage for archives.,To securely encrypt sensitive data.,To create a temporary copy of data in a reserved memory area to improve performance.,To manage network packet flow.,To monitor CPU temperature.,C,"The glossary defines ""cache"" as ""Temporary copy of data in reserved memory area to improve performance."""
"How do the ""base register"" and ""limit register"" work together to define a logical address space?","The base register stores the maximum address, and the limit register stores the minimum.","The base register points to the program counter, and the limit register defines stack size.","The base register specifies the starting address, and the limit register defines the size of the range.",They are used exclusively for physical address translation.,They manage network addresses for inter-process communication.,C,"The glossary defines ""base register"" as ""CPU register with starting address of an address space. Defines logical address space with limit register."" and ""limit register"" as ""CPU register defining size of range. Defines logical address space with base register."" This combined definition fits C."
"What is ""absolute code""?",Code that generates random memory addresses.,Code that can only be executed on a specific hardware platform.,Code with bindings to absolute memory addresses.,Code that needs to be relocated at runtime.,Code that is entirely stored in the CPU cache.,C,"The glossary defines ""absolute code"" as ""Code with bindings to absolute memory addresses."""
"What is ""relocatable code""?",Code that cannot be moved once loaded into memory.,Code with bindings to memory addresses changed at loading time to reflect location in main memory.,Code that is only used for system boot processes.,Code that directly accesses physical memory without translation.,Code encrypted for secure storage.,B,"The glossary defines ""relocatable code"" as ""Code with bindings to memory addresses changed at loading time to reflect location in main memory."""
"According to the glossary, what is a ""logical address""?",The actual location in physical memory.,An address generated by the CPU; translated to a physical address before use.,An address used by the disk controller.,A network address for a remote resource.,A unique identifier for a process.,B,"The glossary defines ""logical address"" as ""Address generated by CPU; translated to physical address before use."""
"According to the glossary, what is a ""physical address""?",An address that exists only in the CPU's registers.,An address generated by the CPU before translation.,The actual location in physical memory of code or data.,An address that symbolic names are bound to.,An address that refers to a file on disk.,C,"The glossary defines ""physical address"" as ""Actual location in physical memory of code or data."""
"What is another name for a ""logical address"" as defined in the glossary?",Absolute address.,Relocatable address.,Virtual address.,Physical address.,Symbolic address.,C,"The glossary defines ""virtual address"" as ""Address generated by CPU; translated to physical address before use,"" which is identical to the definition of ""logical address"", meaning it's an alternate term."
What is the primary function of the Memory-Management Unit (MMU)?,To manage secondary storage devices.,To control network traffic.,To act as a hardware component of the CPU/motherboard allowing memory access.,To regulate CPU temperature.,To execute arithmetic operations.,C,"The glossary defines ""memory-management unit (MMU)"" as ""Hardware component of CPU/motherboard allowing memory access."""
"What is the role of the ""relocation register"" as defined in the glossary?",To store the size of an address space.,To define the end of a memory segment.,To add its value to every logical address to create a physical address.,To manage page faults.,To store the program counter value.,C,"The glossary defines ""relocation register"" as ""CPU register whose value added to every logical address to create physical address."""
"What best describes ""dynamic loading"" according to the glossary?",Loading all program routines at process start.,"Loading of process routine when called, not at process start.",Loading programs from a network server.,Loading data directly into CPU registers.,Loading of static libraries.,B,"The glossary defines ""dynamic loading"" as ""Loading of process routine when called, not at process start."""
"What are ""shared libraries"" commonly used for in systems supporting dynamic linking?",Libraries that are loaded once and used by many processes.,Libraries that are unique to each individual process.,Libraries that reside only on secondary storage.,Libraries used for inter-process communication.,Libraries that are compiled directly into the executable.,A,"The glossary defines ""shared libraries"" as ""Libraries loaded once, used by many processes; used in systems supporting dynamic linking."""
The concept of a logical address space bound to a separate physical address space is described as what?,Optional for modern operating systems.,Central to proper memory management.,"Primarily a security feature, not related to performance.",Only applicable in bare-machine environments.,A legacy system design no longer in use.,B,"The text states, ""Concept of logical address space bound to separate physical address space: central to proper memory management."""
The operating system's unrestricted access to OS and user memory allows it to perform which of the following tasks?,Run user applications directly without process context.,Directly modify hardware firmware.,"Load programs, dump on errors, access system call parameters, perform I/O, and context switches.",Bypass all hardware protection mechanisms for user processes.,Remotely control other machines on the network.,C,"The text lists these capabilities: ""Allows OS to load programs, dump on errors, access system call parameters, perform I/O, context switches."""
What are the primary entities that main memory is designed to accommodate?,Operating System (OS) and user processes,Device drivers and system utilities,CPU registers and cache data,Network protocols and I/O buffers,Virtual machines and hypervisors,A,"The text explicitly states: ""Main memory accommodates OS and user processes."""
How is main memory typically divided into partitions for the OS and user processes?,"Into three partitions: one for OS, one for kernel, and one for user processes","Into a low and high memory partition, both dedicated to user processes",Into two partitions: one for the OS and one for user processes,"Into multiple fixed-size partitions, dynamically assigned","Into a single, large partition shared by all components",C,"The text mentions: ""Memory usually divided into two partitions: one for OS, one for user processes."""
"Regarding the operating system's location in main memory, where can it reside, and what is the common practice for modern OS like Linux and Windows?","Only in low memory, as dictated by hardware limitations","Only in high memory, to protect it from user processes","In low or high memory, with many OS (including Linux/Windows) using high memory","In low or high memory, with many OS (including Linux/Windows) using low memory","Its location is dynamically assigned based on system load, but primarily in low memory",C,"The text states: ""OS can be in low or high memory (many OS, including Linux/Windows, use high memory)."""
What is the defining characteristic of 'contiguous memory allocation'?,Each process is divided into multiple non-contiguous memory sections,Processes are allocated memory in fixed-size blocks only,Each process resides in a single contiguous memory section,Memory is partitioned equally among all processes,Memory is dynamically reallocated every few milliseconds to prevent fragmentation,C,"The definition provided is: ""Contiguous memory allocation: each process in single contiguous memory section."""
What is the primary purpose of memory protection mechanisms in contiguous memory allocation?,To prevent memory leaks and improve system stability,To ensure processes run at their highest possible priority,To prevent a process from accessing memory it does not own,To optimize memory access speeds through caching,To facilitate faster context switching between processes,C,"The text explicitly states the purpose: ""Prevent process from accessing unowned memory."""
Which two registers are combined to implement memory protection in a contiguous memory allocation scheme?,Index register and program counter,Stack pointer and base register,Relocation register and limit register,General-purpose register and segment register,Instruction register and data register,C,"The text indicates: ""Combine relocation register (smallest physical address) and limit register (range of logical addresses)."""
"In the context of memory protection, what does the relocation register store?",The maximum logical address a process can access,The size of the memory partition allocated to a process,The smallest physical address a process can access,The starting address of the Operating System in memory,The address of the next instruction to be executed by the CPU,C,"The text defines it as: ""relocation register (smallest physical address)""."
What does the limit register specify in the memory protection scheme?,The smallest physical address a process can access,The total amount of available physical memory,The range of logical addresses that a process can access,The maximum number of processes allowed in memory,The size of the physical memory block allocated to the OS,C,"The text defines it as: ""limit register (range of logical addresses)""."
"For memory protection to work, what must be true for every logical address generated by the CPU?",It must be an even number,It must be less than the relocation register value,It must fall within the limit register range,It must be greater than the limit register value,It must directly correspond to a physical address,C,"The text states: ""Each logical address must fall within limit register range."""
How does the Memory Management Unit (MMU) dynamically map a logical address to a physical address in the described protection scheme?,By subtracting the limit register value from the logical address,By multiplying the logical address by the relocation register value,By adding the relocation register value to the logical address,By dividing the logical address by the limit register value,By performing a lookup in a pre-computed address table,C,"The text describes: ""MMU maps logical address dynamically by adding relocation register value."""
When does the CPU scheduler load the relocation and limit registers?,Only at system boot time,Continuously during process execution,During a context switch,Only when a process requests new memory,Once per hour as part of system maintenance,C,"The text specifies: ""CPU scheduler loads relocation and limit registers during context switch."""
What specifically do the relocation and limit registers protect from modification by a running process?,Only the process's own data and code,"Only other user programs, but not the OS",The OS and other user programs/data,CPU registers and system clock,Network interfaces and peripheral devices,C,"The text states: ""Protects OS and other user programs/data from modification by running process."""
What dynamic capability does the relocation-register scheme enable for the operating system?,Dynamic adjustment of process priorities,Dynamic OS size changes,Dynamic allocation of CPU time slices,Dynamic network configuration management,Dynamic file system caching,B,"The text mentions: ""Relocation-register scheme allows dynamic OS size changes."""
"For which type of software is the dynamic nature of the relocation-register scheme particularly desirable, allowing them to be loaded only when needed and removed when no longer needed?",Text editors,Compilers,Web browsers,Device drivers,Database servers,D,"The text highlights this benefit for: ""device drivers: load only when needed, remove when no longer needed."""
What is considered the simplest method for memory allocation where processes are assigned to variably sized partitions?,Assigning multiple processes to fixed-size partitions,Assigning processes to variably sized partitions,Using paging exclusively for all memory allocation,Implementing segmentation without protection,Dividing all memory into equal-sized blocks for all processes,B,"The text describes it as the ""Simplest method: assign processes to variably sized partitions."""
"In a 'variable-partition' memory allocation scheme, how many processes does each memory partition typically contain?",At least two processes to maximize utilization,Exactly one process,A variable number of processes depending on their size,"A fixed number of processes, usually four",No processes if it's currently an available 'hole',B,"The definition states: ""Each partition contains exactly one process (variable-partition scheme)."""
What does the operating system maintain to manage available and occupied memory parts in a variable-partition scheme?,A list of all active processes,A table of available/occupied memory parts,A log of all memory access errors,A cache of frequently used memory addresses,A queue of waiting I/O requests,B,"The text indicates: ""OS keeps table of available/occupied memory parts."""
"When system memory is initially available for user processes in a variable-partition scheme, how is it typically represented?","As many small, fragmented blocks","As a single large block, referred to as a 'hole'",As predefined fixed-size partitions,As an empty table with no entries,As a collection of occupied segments for system processes,B,"The text states: ""Initially: all memory available for user processes, one large block (hole)."""
"If an arriving process requests memory but there isn't enough available, what are the potential actions the OS might take?",Terminate the process immediately to free resources,Reject the process or place it in a wait queue,Force the process to use less memory than requested,Swap another process out to make immediate space,Increase the system's physical memory dynamically,B,"The text specifies: ""Insufficient memory for arriving process: reject or place in wait queue."""
What occurs if the OS allocates a 'hole' that is significantly larger than the memory requested by an arriving process?,"The entire hole is allocated to the process, leading to internal fragmentation",The process is immediately rejected due to inefficient allocation,"The hole is split into two parts: one allocated to the process, and the other returned to the list of holes",The hole is merged with an adjacent hole to form an even larger block,"The OS waits for a smaller, more suitable hole to become available",C,"The text explains: ""If hole too large: split into two parts (one allocated, other returned to holes)."""
"When a process terminates and releases its memory block, what can happen if the newly freed hole is adjacent to existing free holes?",It is immediately reallocated to the next process in the wait queue,It is marked as unusable to prevent further fragmentation,It is merged with the adjacent holes to form a larger contiguous hole,It is swapped out to disk for later use,"It creates a new, separate memory partition",C,"The text describes: ""New hole adjacent to others: merged to form larger hole."""
The procedure of satisfying a memory request of size 'n' from a list of free holes is an instance of what general computer science problem?,The producer-consumer problem,The critical section problem,The dynamic storage-allocation problem,The resource deadlock problem,The paging problem,C,"The text states: ""This procedure: instance of dynamic storage-allocation problem."" The glossary also defines it."
"Which memory allocation strategy involves allocating the first hole that is large enough for a request, typically searching from the beginning or the last search end?",Best-fit,Worst-fit,Next-fit,First-fit,Random-fit,D,"The text defines 'First-fit' as: ""Allocate first hole big enough. Search from beginning or last search end. Stop when large enough hole found."""
"Which memory allocation strategy requires searching the entire list of free holes (unless ordered by size) to find the smallest hole that is large enough for a request, and produces the smallest leftover hole?",First-fit,Worst-fit,Random-fit,Best-fit,Next-fit,D,"The text defines 'Best-fit' as: ""Allocate smallest hole big enough. Must search entire list (unless ordered by size). Produces smallest leftover hole."""
"Which memory allocation strategy involves allocating the largest available hole, potentially producing a large leftover hole?",First-fit,Best-fit,Worst-fit,Random-fit,Next-fit,C,"The text defines 'Worst-fit' as: ""Allocate largest hole. Must search entire list (unless sorted by size). Produces largest leftover hole (may be more useful)."""
"Based on simulations, which memory allocation strategies generally perform better in terms of decreasing time and storage utilization?",Worst-fit is consistently the best overall,First-fit and best-fit are better than worst-fit,"All three (first-fit, best-fit, worst-fit) perform equally well",Best-fit is always faster than first-fit,Only worst-fit shows significant improvement in storage utilization,B,"The text states: ""Simulations: first-fit and best-fit better than worst-fit (decreasing time, storage utilization)."""
"In a comparison between first-fit and best-fit strategies, what is generally true regarding their performance for storage utilization and speed?",Best-fit is clearly better for storage utilization,First-fit is clearly better for storage utilization,"Neither is clearly better for storage utilization, but first-fit is generally faster","Best-fit is generally faster, but results in more fragmentation",First-fit leads to significantly less external fragmentation,C,"The text notes: ""Neither first-fit nor best-fit clearly better for storage utilization, but first-fit generally faster."""
Which memory allocation strategies are specifically mentioned as suffering from external fragmentation?,Only worst-fit,Only first-fit,Only best-fit,First-fit and best-fit,All allocation strategies equally,D,"The text states: ""First-fit and best-fit suffer from external fragmentation."""
"What process leads to free memory being broken into small, non-contiguous pieces, causing external fragmentation?",Continuous memory access by a single process,Frequent CPU scheduling of lightweight processes,Processes being loaded and removed from memory,The system boot-up sequence and OS initialization,High rates of disk I/O operations,C,"The text attributes it to: ""Processes loaded/removed: free memory broken into small pieces."""
What is the definition of 'external fragmentation'?,Unused memory located within a process's allocated partition,"A state where the total memory is insufficient for a process, regardless of contiguity","A condition where available memory has holes that together are enough, but no single hole is large enough for a new request",Memory that is lost or corrupted due to system crashes,Memory being accessed by unauthorized processes or users,C,"The text and glossary define it as: ""External fragmentation: enough total memory, but spaces not contiguous (storage fragmented)."""
What is a key consequence if external fragmentation becomes severe?,Increased CPU utilization due to more efficient memory access,Improved overall system performance and responsiveness,"Wasted memory between processes, preventing new processes from loading despite sufficient total free space",Faster process termination as memory blocks are smaller,Reduced need for context switching between processes,C,"The text states: ""Problem can be severe: wasted memory between processes."" and ""If small pieces were one big block: could run more processes."""
"Besides the chosen allocation strategy (first-fit/best-fit), what other factor is mentioned as influencing the amount of fragmentation?",The CPU clock speed,The total size of the operating system kernel,Which end of the free block is allocated,The type of file system used for storage,The number of active users logged into the system,C,"The text notes: ""Strategy (first-fit/best-fit) affects fragmentation amount. Which end of free block allocated also a factor."""
"According to the text, is external fragmentation a sporadic or constant problem?",A sporadic problem that rarely occurs,A problem only with fixed-partition schemes,A problem only with certain operating systems,Always a problem in dynamic memory allocation,A problem only with very large memory systems,D,"The text explicitly states: ""External fragmentation always a problem."""
"According to the glossary, what is the '50-percent rule'?",A rule stating that 50% of processes must reside in high memory for optimal performance,A statistical finding that fragmentation may result in 50 percent space loss,A rule that allocates exactly 50% of memory to the operating system,A guideline for optimizing CPU utilization by 50%,A principle for equally dividing memory into 50% used and 50% free partitions,B,"The glossary defines: ""50-percent rule: Statistical finding that fragmentation may result in 50 percent space loss."""
"What is the practical consequence of the '50-percent rule' regarding memory usability, as described in the text?",Half of the total memory becomes inaccessible,Two-thirds of the memory becomes unusable,One-third of the memory may become unusable due to fragmentation,"No memory is lost, but access speeds are significantly reduced",All memory is eventually compacted to eliminate fragmentation,C,"The text specifies: ""50-percent rule: one-third of memory unusable."""
What are the two general types of memory fragmentation mentioned in the text?,Logical and physical fragmentation,Contiguous and noncontiguous fragmentation,Internal and external fragmentation,Active and passive fragmentation,Foreground and background fragmentation,C,"The text states: ""Memory fragmentation: internal and external."""
What is the definition of 'internal fragmentation'?,Memory that is inaccessible to the Operating System,Free memory scattered in small pieces between processes,Unused memory located within a process's allocated partition,Memory that has been corrupted by a faulty process,Memory exclusively allocated to system buffers,C,"The text and glossary define it as: ""Internal fragmentation: unused memory internal to a partition."""
Under what condition does internal fragmentation typically occur?,When a process terminates and releases its memory block,When the OS cannot find a large enough contiguous hole for a process,"When allocated memory is slightly larger than requested, such as with fixed-sized blocks",When processes are frequently swapped between main memory and disk,When a process attempts to access memory it does not own,C,"The text explains: ""Occurs when allocated memory slightly larger than requested (e.g., fixed-sized blocks)."""
What is the primary goal of 'compaction' as a solution to external fragmentation?,To reduce the total amount of physical memory available,"To shuffle memory contents, placing all free memory together in one large block",To compress data within memory to save space,To merge small processes into larger ones for efficiency,To defragment disk space rather than main memory,B,"The text defines its goal as: ""shuffle memory contents, place all free memory together in one large block."""
Under what specific condition is compaction possible as a solution to external fragmentation?,Only if relocation is static (assembly or load time),"Regardless of the type of relocation, it is always possible",Only if relocation is dynamic (execution time),Only if memory is partitioned into fixed-size blocks,Only if the system has an abundant amount of free memory,C,"The text explicitly states: ""Compaction not always possible: If relocation static (assembly/load time): cannot compact. Possible only if relocation dynamic (execution time)."""
"If dynamic relocation is supported, what actions are taken during compaction to achieve its goal?",The entire memory is reset to its initial empty state,"Program and data are moved, and the base register is changed",New physical memory is added to the system dynamically,Logical addresses are remapped at compile time,Only system files and kernel modules are moved to one end,B,"The text describes: ""If dynamic relocation: move program/data, change base register."""
What is a potential disadvantage or cost associated with performing memory compaction?,It significantly increases internal fragmentation,"It can be an expensive operation, requiring substantial CPU time",It makes memory protection more difficult to implement,It permanently reduces the overall memory capacity of the system,It requires frequent system reboots to be effective,B,"The text warns: ""Compaction can be expensive (e.g., move all processes to one end)."""
"What is an alternative solution to external fragmentation, besides compaction, mentioned in the text?",Implementing larger physical memory modules,Requiring all processes to be of a fixed size,Eliminating the need for memory protection mechanisms,Permitting noncontiguous logical address space,Reducing the number of concurrent processes allowed in memory,D,"The text introduces: ""Another solution to external fragmentation: permit noncontiguous logical address space."""
Which common memory-management technique allows a process to be allocated physical memory wherever available by permitting noncontiguous logical address space?,Swapping,Segmentation,Contiguous allocation,Paging,Overlays,D,"The text specifies: ""Allows process to be allocated physical memory wherever available. Strategy used in paging (most common memory-management technique)."""
"Is fragmentation a problem specific only to memory management, or is it a broader issue?","Yes, it only occurs in main memory allocation","No, it's a general problem found in various aspects of computing",It's only a problem with contiguous memory allocation schemes,It's a problem exclusive to older operating systems,It's primarily a problem when using Solid State Drives (SSDs),B,"The text concludes: ""Fragmentation: general problem in computing (storage management chapters)."""
What primary problem in memory management does paging address by allowing noncontiguous physical address space?,Internal fragmentation,Thrashing,External fragmentation and compaction issues,Memory leaks,Deadlock prevention,C,"Paging is a memory-management scheme specifically designed to allow noncontiguous physical address space, which avoids external fragmentation and the need for compaction that plague contiguous allocation schemes."
Which of the following best defines 'paging' in the context of memory management?,A scheme for managing contiguous physical memory blocks.,A technique to increase CPU clock speed for memory access.,A memory-management scheme allowing noncontiguous physical address space.,A method to cache frequently used data in registers.,A process of swapping entire processes between RAM and disk.,C,"Paging is defined as a memory-management scheme that enables a process's physical address space to be noncontiguous, which is its primary characteristic."
"Paging is widely adopted in most operating systems, ranging from servers to mobile devices, primarily due to what?",Its simplicity in implementation.,Its ability to eliminate all forms of memory fragmentation.,Its inherent security features.,Its advantages in managing noncontiguous physical memory.,Its minimal hardware requirements.,D,"Paging's widespread use is attributed to its advantages, mainly its effectiveness in managing memory by allowing noncontiguous physical address spaces, which solves issues like external fragmentation."
The implementation of paging requires cooperation between which two components?,Application software and network protocols,Operating system and hardware,User processes and the file system,Compilers and interpreters,Disk drives and solid-state drives,B,"Paging is a complex memory management technique that relies on the close cooperation between the operating system (for managing page tables, frame tables, etc.) and specialized hardware (for address translation via MMU, TLB, etc.)."
"In a paging system, what are the fixed-sized blocks of physical memory referred to as?",Pages,Segments,Frames,Clusters,Blocks,C,Physical memory is broken into fixed-sized blocks called 'frames' in a paging system.
What are the fixed-sized blocks of logical memory called in a paging system?,Frames,Segments,Partitions,Pages,Regions,D,Logical memory is broken into same-sized blocks called 'pages' in a paging system.
"During process execution in a paging system, how are pages loaded into memory?",Pages must be loaded into contiguous memory frames.,Pages are loaded only into frames at the beginning of physical memory.,Pages are loaded into any available memory frames.,Pages are loaded directly into the CPU's registers.,Pages are loaded only if the entire program can fit contiguously.,C,"A key benefit of paging is that pages can be loaded into any available memory frames, regardless of their physical location, due to the noncontiguous nature of the physical address space."
"In a paging system, how is the backing store (e.g., disk) typically divided?",Into variable-sized segments.,"Into fixed-sized blocks, the same size as frames or clusters.",Into one large contiguous block for each process.,"It is not divided; it functions as a single, undifferentiated space.",Based on file system directories.,B,"The backing store is divided into fixed-sized blocks, which are the same size as frames or clusters, to facilitate efficient swapping of pages between memory and disk."
What is the relationship between logical address space and physical address space in a paging system?,They are identical.,Logical address space is a subset of physical address space.,They are totally separate.,Physical address space is always larger than logical address space.,They are identical only when there is no fragmentation.,C,"In paging, the logical address space (what the CPU sees) is totally separate from the physical address space (where data actually resides in memory)."
A CPU-generated address in a paged memory system is divided into which two parts?,Segment number and offset,Base address and limit,Page number and page offset,Process ID and memory address,Register value and memory location,C,The CPU generates a logical address which is divided into a page number (p) and a page offset (d) for translation.
What is the 'page number (p)' used for in a paging system?,To specify the exact byte location within a frame.,As an index into the per-process page table.,To directly access physical memory.,To determine the size of a page.,To identify the process owning the memory.,B,The page number (p) is used as an index into the page table to find the corresponding physical frame number.
What information does a 'page table' typically contain?,The logical address of each page.,The base address of each frame in physical memory.,The size of each process.,The location of the backing store.,A list of all free memory blocks.,B,The page table's primary function is to store the base address (or frame number) of each corresponding frame in physical memory.
What does the 'page offset (d)' represent in a paged memory system?,The base address of the physical frame.,The index into the page table.,The location within the referenced frame.,The total size of the logical address space.,The number of pages allocated to a process.,C,The page offset (d) directly specifies the location or byte offset within the physical memory frame identified by the page table entry.
How is the physical memory address computed in a paging system?,Page number + Page offset,Base address of frame + Page offset,Frame number * Page size + Page offset,Logical address - Page table base register,Page number * Page size,B,The physical memory address is calculated by combining the base address of the frame (obtained from the page table using the page number) with the page offset.
Which of the following correctly describes the steps an MMU takes to translate a logical address to a physical address?,"Extract page offset (d), use as index, extract frame number (f), replace d with f.","Extract page number (p), use as index, extract frame number (f), replace p with f.","Extract frame number (f), use as index, extract page number (p), replace f with p.","Extract page number (p), directly access memory, add offset (d).","Extract page offset (d), replace page number (p) with d, then access memory.",B,"The MMU extracts the page number (p), uses it as an index into the page table to get the frame number (f), and then replaces p with f to form the physical address with the unchanged offset (d)."
"During the logical-to-physical address translation process, which component of the CPU-generated address remains unchanged?",The page number (p),The frame number (f),The page offset (d),The base address of the page table,The physical memory address,C,The page offset (d) directly specifies the location within the frame and is carried directly from the logical address to the physical address without modification.
"Who defines the page size (and consequently, frame size) in a paging system?",The programmer at compile time.,The operating system dynamically.,The user at runtime.,The hardware.,The application software.,D,"Page size, which is always equal to frame size, is a hardware-defined characteristic, typically a power of 2."
"Why is the page size typically a power of 2 (e.g., 4 KB, 1 GB)?",To minimize the number of page table entries.,To simplify the hardware design for disk access.,To make the translation of logical addresses into page numbers and offsets easier.,To reduce internal fragmentation to zero.,To increase the effective memory access time.,C,"A page size that is a power of 2 allows for simple and efficient division of a logical address into its page number and offset using bitwise operations, simplifying hardware translation."
"If a logical address space is $2^m$ bytes and the page size is $2^n$ bytes, how are the page number and page offset typically determined?",Page number uses low-order $n$ bits; page offset uses high-order $m-n$ bits.,Page number uses high-order $m$ bits; page offset uses low-order $n$ bits.,Page number uses high-order $m-n$ bits; page offset uses low-order $n$ bits.,Page number uses low-order $m-n$ bits; page offset uses high-order $n$ bits.,Page number and page offset are both $n$ bits.,C,"For a logical address space of $2^m$ and page size of $2^n$, the high-order $m-n$ bits represent the page number, and the low-order $n$ bits represent the page offset."
Paging is a form of which type of relocation?,Static relocation,Compile-time relocation,Load-time relocation,Dynamic relocation,Fixed relocation,D,"Paging performs address translation at runtime, meaning every logical address is bound to a physical address dynamically by the paging hardware, classifying it as a form of dynamic relocation."
Which type of memory fragmentation is entirely avoided by paging?,Internal fragmentation,External fragmentation,Both internal and external fragmentation,Stack fragmentation,Heap fragmentation,B,"Paging allocates physical memory in fixed-size frames, allowing any available frame to be used for any page, thus eliminating external fragmentation because there are no wasted 'holes' between allocated blocks."
What type of memory fragmentation can still occur in a paging system?,External fragmentation,Inter-process fragmentation,Internal fragmentation,Disk fragmentation,Cache fragmentation,C,"Internal fragmentation can occur in paging if the last page allocated to a process does not perfectly fill its frame, leaving some unused space within that frame."
What is the average amount of internal fragmentation expected per process in a paging system?,Zero,One full page,One-quarter page,One-half page,Two pages,D,"On average, a process might not fully utilize its last allocated page, resulting in approximately one-half page of internal fragmentation per process."
"To minimize internal fragmentation, what characteristic is generally desirable for page sizes?",They should be as large as possible.,They should be dynamically adjustable based on process needs.,They should be very small.,They should be prime numbers.,They should be equal to the process size.,C,"Smaller page sizes mean that the leftover space in the last page (internal fragmentation) is also smaller, thus reducing overall wasted space."
What is one benefit associated with using larger page sizes in a paging system?,Less internal fragmentation.,More efficient disk I/O due to larger data transfers.,Reduced context-switch time.,Simpler page table lookup.,Elimination of the need for a TLB.,B,"Larger page sizes enable larger data transfers during disk I/O, which is generally more efficient as it reduces the number of I/O operations."
What overhead is reduced by using larger page sizes in a paging system?,CPU context switch time.,Disk I/O latency.,Overhead per page-table entry.,Physical memory consumption.,TLB miss rate.,C,"Larger page sizes mean fewer pages are needed to cover a given logical address space, which in turn means fewer entries in the page table, reducing the memory overhead per page-table entry."
Why have page sizes generally increased over time in computing systems?,To reduce the complexity of the paging hardware.,"Due to processes, data sets, and main memory becoming larger.",To eliminate internal fragmentation completely.,To improve CPU clock speeds.,To make systems more compatible with older software.,B,"As processes, data sets, and available main memory have grown, larger page sizes have become more practical and efficient, reducing the number of page table entries needed and improving I/O efficiency."
What are typical page sizes in modern operating systems?,1 KB or 2 KB,4 KB or 8 KB,16 KB or 32 KB,64 KB or 128 KB,512 bytes or 1 KB,B,"Common page sizes today are 4 KB or 8 KB, though some systems like Windows 10 and Linux support multiple sizes including much larger 'huge pages'."
"In Linux, what term is used for especially large pages that can be designated for physical memory regions?",Superpages,Jumbopages,Megapages,Huge pages,Gigapages,D,"Linux supports a feature called 'huge pages' for designating regions of physical memory for particularly large page sizes (e.g., 2 MB or 1 GB)."
A 32-bit CPU typically has page-table entries of what size?,1 byte,2 bytes,4 bytes,8 bytes,16 bytes,C,"For a 32-bit CPU, a page-table entry is typically 4 bytes, which is sufficient to point to a frame number within a 32-bit address space."
"If a system uses 4-byte page-table entries and a frame size of 4 KB ($2^{12}$ bytes), what is the maximum physical memory it can address with these entries?",$2^{32}$ bytes (4 GB),$2^{36}$ bytes (64 GB),$2^{44}$ bytes (16 TB),$2^{48}$ bytes (256 TB),$2^{64}$ bytes (16 EB),C,"A 32-bit (4-byte) entry can point to $2^{32}$ distinct frame numbers. If each frame is $2^{12}$ bytes, then the total addressable physical memory is $2^{32} * 2^{12} = 2^{44}$ bytes (16 TB)."
"Besides the frame address, what other information might page-table entries contain, potentially reducing the number of bits available for frame addresses?",Process ID and priority.,Disk block number and file name.,"Protection bits (e.g., read/write) and valid-invalid bit.",CPU speed and cache size.,Network address and port number.,C,"Page-table entries often contain additional information such as protection bits (for read/write/execute permissions) and a valid-invalid bit, which reduces the total bits available for specifying the frame address."
"When a new process arrives, how does the operating system determine the physical memory requirements for its pages?",It allocates a fixed amount of memory regardless of process size.,It examines the process's size in terms of pages and ensures that enough frames are available.,It requests the user to specify the required memory.,It loads the process into a single large contiguous block.,It calculates the memory based on the CPU's current load.,B,"Upon a process's arrival, the OS determines its size in pages. For efficient loading, it must ensure that there are enough available physical frames to accommodate all 'n' pages required by the process."
Which statement accurately describes the relationship between the programmer's view of memory and actual physical memory in a paged system?,"The programmer views memory as a single contiguous space, which directly maps to a contiguous block in physical memory.","The programmer views memory as a single contiguous space, while the user program is scattered throughout physical memory.",The programmer is fully aware of the physical locations of their program's pages.,The programmer's view of memory is identical to the physical memory layout.,The OS directly exposes physical memory addresses to the programmer.,B,"In a paged system, the programmer perceives a single, contiguous logical address space for their program, but the OS and hardware scatter these pages across noncontiguous physical frames, transparently to the programmer."
How is a user process prevented from accessing memory it does not own in a paging system?,By hardware checks on physical addresses only.,By limiting the process to a specific physical memory partition.,By having no way to address memory outside its own page table.,By requiring explicit permission from the OS for every memory access.,By encrypting unowned memory regions.,C,"A user process can only generate logical addresses that are mapped through its own page table. There is no mechanism for it to generate a logical address that would translate to a physical address outside of the frames listed in its page table, thus preventing access to unowned memory."
"What system-wide data structure does the operating system use to keep track of physical page frames' allocation details (e.g., free/allocated, to which process/page)?",Process control block,Page table,Frame table,Translation Look-aside Buffer (TLB),Symbol table,C,"The 'frame table' is a system-wide data structure, distinct from per-process page tables, that contains one entry for each physical page frame, detailing its allocation status and ownership."
"When a system call passes an address parameter, how does the operating system handle it in a paged environment?",The OS executes the system call directly on the logical address.,The address parameter is mapped to the correct physical address by the OS.,The system call fails if the address is not already in the TLB.,The OS requests the user to confirm the address validity.,The address parameter is ignored by the OS.,B,"The OS is aware that user processes operate in their logical address space. When a system call includes an address parameter, the OS is responsible for translating that logical address to the correct physical address using its own copy of the process's page table."
The OS maintains a copy of the page table for each process. What is one of its primary uses?,To directly access physical memory without translation.,For manual logical-to-physical translation by the OS itself.,To cache frequently used data for the process.,To manage inter-process communication directly.,To perform garbage collection for the process.,B,"The OS maintains a copy of each process's page table for its own internal use, such as performing manual logical-to-physical address translation when necessary (e.g., for system calls) or setting up hardware page tables via the CPU dispatcher."
What is a recognized disadvantage of paging concerning system performance?,It eliminates the possibility of memory sharing.,It increases the overhead of disk I/O.,It significantly increases internal fragmentation.,It increases context-switch time.,It requires more physical memory than non-paging systems.,D,"Because page tables are per-process structures and potentially large, loading and restoring them during context switches can add overhead, thus increasing context-switch time."
Where is the pointer to a process's page table typically stored?,In the process's stack.,In a global system registry.,In the process control block (PCB).,In the Translation Look-aside Buffer (TLB).,In the main memory alongside the page table itself.,C,"The pointer to a process's page table, along with other registers and process-specific data, is stored in its process control block (PCB)."
What action does the CPU scheduler take regarding hardware page-table values when it selects a process?,It flushes all hardware page-table values.,It reloads user registers and hardware page-table values from the stored user page table.,It computes new page-table values from scratch.,It only modifies the page table if the process is new.,It ignores page-table values as they are managed by the MMU.,B,"When a CPU scheduler selects a process, it must load the correct context, which includes reloading the user registers and updating the hardware's page-table registers (or PTBR) to point to the selected process's page table."
"What is the simplest hardware implementation of a page table, and what is its primary characteristic?","Storing it in main memory, which is efficient for large tables.","Using dedicated high-speed hardware registers, providing efficient translation.","Implementing it as a software-managed data structure, offering flexibility.",Distributing it across multiple CPU cores for parallel access.,Storing it on disk for persistence.,B,"The simplest hardware implementation is using dedicated high-speed hardware registers. This provides very efficient translation because page-table entries are directly accessible, though it's only feasible for small page tables (e.g., 256 entries)."
Why are dedicated hardware registers not a feasible approach for storing page tables in contemporary CPUs?,Registers are too slow for memory access.,The number of entries in contemporary page tables is too large for registers.,Registers are too expensive to manufacture in large quantities.,Registers cannot be accessed by the operating system.,Registers do not support dynamic relocation.,B,"Contemporary CPUs use much larger page tables (e.g., 2^20 entries), far too many to be stored entirely in dedicated hardware registers, making this approach impractical due to cost and physical space."
Where are large page tables typically stored in contemporary CPU architectures?,In the CPU's L1 cache.,On the hard disk.,In the main memory.,In dedicated GPU memory.,In the firmware ROM.,C,"Given the size of modern page tables, they are typically stored in the main memory, with a register (Page-Table Base Register, PTBR) pointing to their starting location."
What is the function of the 'Page-Table Base Register (PTBR)'?,It holds the current page number being translated.,It points to the current page table in main memory.,It stores the size of the logical address space.,It manages the Translation Look-aside Buffer (TLB).,It keeps track of free physical frames.,B,"The PTBR is a CPU register that points to the base address of the current process's page table, which is typically stored in main memory."
How does using a Page-Table Base Register (PTBR) to change page tables affect context-switch time?,It significantly increases it because the entire page table must be reloaded.,"It reduces it, as only the PTBR needs to be changed.","It has no effect, as the MMU handles it independently.",It makes context switching impossible.,It requires flushing the entire physical memory.,B,"When the page table is in main memory, changing processes only requires updating the PTBR to point to the new process's page table, which is a single register write and thus reduces context-switch time compared to loading entire page tables into registers."
What is the performance drawback when page tables are stored solely in main memory?,Increased internal fragmentation.,Requirement for more physical memory.,Slower memory access times due to two memory accesses per data access.,Reduced CPU clock speed.,Difficulty in implementing memory protection.,C,"If the page table is in main memory, accessing data requires two memory accesses: one to retrieve the page-table entry (frame number) and another to access the actual data. This effectively slows down memory access by a factor of two, which is generally intolerable."
What is the standard solution to mitigate the performance penalty of storing page tables in main memory?,Increasing the size of physical memory.,Implementing a Translation Look-aside Buffer (TLB).,Using a larger page size.,Reducing the number of processes in memory.,Storing page tables on disk instead.,B,"The Translation Look-aside Buffer (TLB) is a small, fast-lookup hardware cache designed to store frequently used page-table entries, thereby avoiding the two-memory-access penalty for most memory references."
What type of memory is a Translation Look-aside Buffer (TLB)?,"Volatile, slow-speed memory.","Non-volatile, high-speed memory.","Associative, high-speed memory.",Sequential access memory.,Main memory (DRAM).,C,"The TLB is described as an associative, high-speed memory, meaning it can compare an input (page number) with all stored keys simultaneously for very fast lookup."
What does each entry in a Translation Look-aside Buffer (TLB) typically contain?,Only the physical address.,Only the logical address.,A key (tag) and a value.,The process ID and the page size.,The total number of available frames.,C,"Each TLB entry functions like an associative memory entry, comprising a 'key' (typically the page number) and a 'value' (the corresponding frame number), along with other bits like protection."
"Where is the TLB lookup typically performed within the CPU's operation, and what is its performance implication?","As a separate, slow operation after memory access, causing a performance penalty.","As part of the instruction pipeline, with no performance penalty.","Only during context switches, to reduce overhead.","By the operating system in software, making it very flexible.","Only for I/O operations, not for CPU instruction fetches.",B,"TLB lookup is designed to be highly efficient, typically integrated into the instruction pipeline itself, meaning it can perform its check without adding a significant performance penalty to memory access."
What is the typical size range for a Translation Look-aside Buffer (TLB) in terms of entries?,1 to 10 entries.,"32 to 1,024 entries.","4,096 to 16,384 entries.",1 million entries or more.,It varies dynamically based on system load.,B,"TLBs are designed to be small and fast. Their typical size ranges from 32 to 1,024 entries, balancing speed with coverage."
Some CPUs incorporate separate instruction and data address TLBs. What is the main advantage of this design?,It doubles the total number of entries that can be cached.,It allows for independent memory protection settings for code and data.,It reduces the need for the main memory page table.,It simplifies the TLB replacement policies.,It eliminates the need for context switching.,A,"By having separate instruction and data TLBs, the total capacity for cached address translations is effectively doubled, as entries for instruction pages and data pages can be stored independently without conflicting for space within a single TLB."
"During the MMU's address translation process, what happens first when a CPU generates a logical address, regarding the TLB?",The MMU immediately accesses the main memory page table.,The MMU checks if the page number is present in the TLB.,The MMU directly calculates the physical address without using the TLB.,The MMU writes the logical address to the TLB.,The MMU checks the frame table for available frames.,B,The first step in MMU address translation with a TLB is to check if the required page number's translation is already cached in the TLB.
What is a 'TLB hit'?,The page number is not found in the TLB.,"The frame number is immediately available from the TLB, allowing direct memory access.",The MMU needs to access the main memory page table.,An error occurs during address translation.,The TLB is full and an entry must be replaced.,B,"A TLB hit occurs when the page number generated by the CPU is found in the TLB, meaning the corresponding frame number is immediately available, leading to fast memory access."
What action is taken by the MMU on a 'TLB miss'?,The MMU immediately terminates the process.,The MMU proceeds to access main memory to retrieve the data directly.,A memory reference to the page table (in main memory) is made to obtain the frame number.,The MMU flushes the entire TLB.,The MMU generates a new random frame number.,C,"On a TLB miss, the required page-to-frame mapping is not in the TLB, so the MMU must perform a slower memory access to the page table, which resides in main memory, to obtain the correct frame number."
"After a TLB miss, and the frame number is obtained from the page table, what is a crucial step taken to optimize future access?",The page number and frame number are removed from the main memory page table.,The page number and frame number are added to the TLB.,The page number is permanently 'wired down' in the TLB.,The entire TLB is flushed.,The process's priority is increased.,B,"To improve performance for subsequent accesses to the same page, the page number and its corresponding frame number (the translation) are added to the TLB after a miss."
"When a TLB is full and a new entry needs to be added, what policy is typically used to select an existing entry for replacement?","First-In, First-Out (FIFO) only.",Random replacement only.,"Least Recently Used (LRU), round-robin, or random policies.","Last-In, First-Out (LIFO) only.",Always the entry with the lowest page number.,C,"When a TLB is full, an existing entry must be replaced, and common replacement policies include LRU (Least Recently Used), round-robin, and random policies."
What does it mean for a TLB entry to be 'wired down'?,The entry is marked as invalid and cannot be used.,The entry is permanently removed from the TLB.,The entry is locked into the TLB and cannot be removed by the usual replacement algorithm.,The entry is transferred to main memory for storage.,"The entry is exclusively for data access, not instruction access.",C,"Wired-down entries are those that are marked as non-removable from the TLB, typically for critical kernel code or data, ensuring they are always available for fast lookup."
What is the primary purpose of Address-Space Identifiers (ASIDs) in TLB entries?,To uniquely identify a page within a process.,To increase the size of the TLB.,To uniquely identify the process owning the entry and provide address-space protection.,To determine the age of a TLB entry for replacement policies.,To indicate whether a page is read-only or read-write.,C,"ASIDs are stored in TLB entries to uniquely identify the process that owns the translation. This allows the TLB to contain entries from multiple processes simultaneously, and it also contributes to address-space protection by ensuring the current process's ASID matches the entry's ASID."
How do ASIDs (Address-Space Identifiers) impact TLB behavior when resolving virtual page numbers?,"They always cause a TLB miss, requiring a page table lookup.",They allow the TLB to contain entries for only one process at a time.,"If the current process's ASID does not match the virtual page's ASID, it's treated as a TLB miss.",They eliminate the need for the MMU entirely.,They dictate which replacement algorithm is used for TLB entries.,C,"If the ASID associated with the current process does not match the ASID stored in a TLB entry for a virtual page number, it signals that the entry belongs to a different process's address space, and thus it's treated as a TLB miss, forcing a page table lookup."
What is the significant advantage of TLBs that support ASIDs for multi-process environments?,They eliminate internal fragmentation.,They allow the TLB to contain entries for multiple processes simultaneously.,They prevent external fragmentation.,They reduce the need for physical memory.,They make page-table entries smaller.,B,"By including ASIDs, the TLB can distinguish between entries from different processes. This means translations for multiple processes can coexist in the TLB, reducing the need for flushing the TLB on every context switch."
What must happen to a Translation Look-aside Buffer (TLB) without ASIDs on each context switch?,It must be expanded.,It must be flushed (erased).,It must be reconfigured for the new process's page size.,It must be backed up to disk.,It must load new entries from main memory proactively.,B,"Without ASIDs, a TLB cannot distinguish which process an entry belongs to. Therefore, on every context switch, the TLB must be flushed to prevent the next process from inadvertently using incorrect or invalid translation information from the previous process."
Why is a TLB without ASIDs typically 'flushed' (erased) on each context switch?,To save power.,To ensure data consistency in the cache.,To prevent the next process from using wrong translation information.,To increase the hit ratio for the new process.,To free up space for the operating system's kernel code.,C,"Flushing the TLB on a context switch is essential without ASIDs to prevent security and correctness issues. Old entries might correspond to physical addresses that are no longer valid or belong to a different process's address space, leading to incorrect memory accesses."
What is the 'hit ratio' in the context of a Translation Look-aside Buffer (TLB)?,The total number of entries in the TLB.,The percentage of times a page number is found in the TLB.,The rate at which the TLB is flushed.,The number of memory accesses that result in an error.,The ratio of CPU speed to memory speed.,B,"The 'hit ratio' is a measure of the TLB's effectiveness, representing the percentage of memory accesses where the required page-to-frame translation is found directly in the TLB (a TLB hit)."
"Calculate the effective memory-access time if a system has a TLB hit ratio of 80%, a TLB access time of 10 ns, and a memory access time of 10 ns (meaning a TLB miss costs 20 ns for page table lookup and data access, in addition to the initial 10 ns TLB lookup).",10 ns,12 ns,15 ns,18 ns,20 ns,B,"Effective memory-access time = (hit ratio * (TLB access time + memory access time)) + (miss ratio * (TLB access time + 2 * memory access time)). As per the text's example, it's (0.80 * 10 ns) + (0.20 * 20 ns) = 8 ns + 4 ns = 12 ns."
"If a TLB has a 99% hit ratio, a TLB access time of 10 ns, and a memory access time of 10 ns, what is the effective memory-access time?",9.9 ns,10.0 ns,10.1 ns,11.0 ns,19.9 ns,C,"Effective memory-access time = (0.99 * 10 ns) + (0.01 * 20 ns) = 9.9 ns + 0.2 ns = 10.1 ns. (The 20ns for miss includes the TLB check plus page table lookup and data access, hence 20 ns for the miss component)."
What is a common feature of TLB organization in modern CPUs like Intel Core i7?,"A single, very large TLB for all memory types.","No TLB at all, relying solely on main memory page tables.","Multiple TLB levels (e.g., L1 instruction TLB, L1 data TLB, L2 TLB).",TLBs that are entirely software-managed.,TLBs that are only used for kernel space addresses.,C,"Modern CPUs often employ multiple levels of TLBs, similar to cache hierarchies (e.g., L1 instruction TLB, L1 data TLB, L2 TLB), to further optimize translation performance."
What happens if a logical address translation results in a miss at the L2 TLB level?,The CPU immediately aborts the process.,The CPU accesses the L1 TLB again.,The CPU walks the page-table entries in main memory or interrupts the OS.,The CPU attempts to write the entry to a wired-down TLB entry.,The CPU reboots the system to clear the cache.,C,"A miss at the highest TLB level (L2 in this example) means the translation is not cached and must be retrieved from the page table in main memory, which involves a potentially costly 'page table walk' (hundreds of cycles) or an interrupt to the OS to handle the miss."
How do hardware features like TLBs influence operating system design related to paging?,OS designers can ignore TLB features as they are purely hardware concerns.,OS paging improvements are independent of hardware changes like TLBs.,OS designers must understand TLB function and features to implement optimal paging for a platform.,TLBs entirely replace the need for OS-managed page tables.,TLBs are a legacy feature and not relevant to modern OS design.,C,"Hardware features such as TLBs significantly impact memory performance, and OS designers must understand their function to implement paging optimally for a given platform, as TLB design changes may necessitate OS paging implementation changes."
How is memory protection typically implemented in a paged environment?,By encrypting sensitive memory regions.,By isolating processes in separate physical memory banks.,Through protection bits associated with each frame in the page table.,By requiring user confirmation for every memory write operation.,By using a firewall between processes.,C,"Memory protection in a paged environment is typically achieved by including protection bits (e.g., read-write, read-only, execute-only) with each frame's entry in the page table. Every memory reference is checked against these bits during translation."
What happens if a process attempts to write to a page that has its protection bits set to 'read-only'?,The write operation is silently ignored.,"The write operation is completed, and the protection bit is automatically changed.","A hardware trap to the OS occurs, indicating a memory-protection violation.",The operating system automatically corrects the data.,The process is paused until user input is received.,C,"If a memory reference attempts an operation (e.g., write) that violates the protection bits (e.g., trying to write to a read-only page), the hardware detects this and generates a trap (interrupt) to the operating system, signaling a memory-protection violation."
"Beyond simple read-write protection, what finer-grained protection types can be associated with pages in a paging system?","Network access, disk access, printer access.","User-level, kernel-level, supervisor-level.","Read-only, read-write, execute-only.","Compressible, decomcompressible, encrypted.","High-priority, medium-priority, low-priority.",C,"Paging systems can implement finer-grained protection by assigning separate bits for read-only, read-write, and execute-only access types, trapping illegal attempts to the OS."
What is the purpose of the 'valid-invalid' bit in a page table entry?,To indicate if the page has been modified since last loaded.,To indicate if the page is currently in physical memory.,To indicate if the page is part of the process's logical address space (legal page).,To specify if the page is cached in the TLB.,To define the page's priority for eviction.,C,The valid-invalid bit in a page table entry indicates whether the corresponding page is part of the process's current logical address space (valid) or not (invalid). Accessing an invalid page generates a trap to the OS.
What happens if an address lookup in the page table points to an entry where the 'valid-invalid' bit is set to 'invalid'?,The page is automatically loaded from disk.,The memory access is silently allowed.,"An illegal address is trapped by the valid-invalid bit, leading to an OS intervention.",The page is marked as 'wired down' in the TLB.,The page size is automatically adjusted.,C,"If a logical address maps to a page table entry marked as 'invalid', it indicates an attempt to access memory outside the process's defined logical address space, and the hardware generates a trap to the OS."
Who is responsible for setting the 'valid-invalid' bit for each page in a process's page table?,The CPU's MMU automatically.,The programmer at compile time.,The operating system.,The hardware manufacturer.,The user during program installation.,C,"The operating system has control over the page tables and sets the valid-invalid bit for each page, allowing or disallowing access to specific logical pages for a given process."
What is the function of the 'page-table length register (PTLR)' in some paging systems?,It specifies the total number of frames in physical memory.,It indicates the size of the logical address space.,It points to the base of the page table in memory.,"It indicates the size of the page table, used to verify addresses are in a valid range.",It stores the size of individual pages.,D,"The PTLR holds the size of the page table. This value is checked against logical addresses to ensure they fall within the allocated portion of the process's logical address space, thus providing an additional layer of protection."
"If a logical address is checked against the Page-Table Length Register (PTLR) and fails the test, what happens?",The address is automatically corrected by the MMU.,The process is swapped out to disk.,An error trap is generated to the operating system.,The page table is dynamically resized.,The TLB entry for that address is flushed.,C,"If a logical address falls outside the range indicated by the PTLR (meaning it attempts to access a part of its logical address space that is beyond its declared size), a hardware error trap is generated to the OS, indicating an illegal memory access."
What is the primary advantage of paging that becomes significant in a multi-process environment?,Reduced CPU power consumption.,Automatic garbage collection.,The possibility of sharing common code.,Direct access to hardware registers.,Simplified debugging for applications.,C,"One of the major advantages of paging in a multi-process environment is the ability to share common code (like standard libraries) among multiple processes by mapping their page tables to the same physical frames, saving significant memory."
What characteristic must code possess to be effectively shared among multiple processes using paging?,It must be compiled with a special shared library flag.,It must be written in a specific programming language like C++.,It must be 'reentrant' (non-self-modifying).,It must be stored on a solid-state drive.,It must be small in size.,C,"For code to be safely shared, it must be reentrant, meaning it does not modify itself during execution. This allows multiple processes to execute the same physical copy of the code without interfering with each other."
What is 'reentrant code'?,Code that can only be executed by a single process at a time.,Code that automatically adapts to different hardware architectures.,"Code that is non-self-modifying, allowing multiple concurrent executions.",Code that must be loaded entirely into contiguous memory.,Code that manages memory allocation for other programs.,C,"Reentrant code is defined as code that does not modify itself during execution, which makes it suitable for simultaneous execution by multiple processes or threads without conflict."
"How does shared reentrant code, like the standard C library (`libc`), lead to significant memory savings when used by multiple processes?",Each process loads a smaller portion of the library into its address space.,The library is stored on disk and only loaded on demand.,"Only one physical copy of the `libc` is kept in memory, mapped by multiple page tables.",It eliminates the need for any page tables for shared libraries.,It compresses the library's code before loading.,C,"Instead of each process loading its own copy, only one physical copy of the reentrant code (e.g., `libc`) resides in physical memory. The page tables of multiple processes are then configured to point to these same physical frames, resulting in significant memory savings."
Which of the following are examples of programs that commonly benefit from shared pages in a multi-process environment?,Custom user applications and private data files.,Device drivers and interrupt handlers.,"Compilers, window systems, and database systems.",Web browsers and email clients.,Antivirus software and firewalls.,C,"Compilers, window systems, and database systems are mentioned as examples of programs that are often shared among multiple processes using paging to save memory because their code is typically reentrant."
How are shared libraries (like DLLs on Windows or SOs on Linux) typically implemented in the context of paging?,By loading a separate copy for each process.,Through direct memory access (DMA) without page tables.,"Using shared pages, mapping to a single physical copy.",By storing them exclusively in the CPU's cache.,"As part of the operating system kernel, not user space.",C,"Shared libraries are typically implemented using shared pages. This means a single physical copy of the library code is loaded into memory, and multiple processes can map to it via their respective page tables."
"When sharing code using paging, what characteristic should the operating system enforce for the shared code?",It should be writable by all processes.,It should be read-only.,It should be executable only by the root user.,It should be non-pageable.,It should be encrypted.,B,"To maintain integrity and enable safe sharing, the OS should enforce the read-only nature of shared code (reentrant code) to prevent one process from inadvertently modifying the code being used by others."
"Which of the following is implemented using shared pages, similar to how shared libraries are handled?",Virtualization of entire operating systems.,Direct Memory Access (DMA) operations.,Interprocess communication (IPC) through shared memory.,Network packet routing.,CPU scheduling algorithms.,C,"Shared memory, a common mechanism for interprocess communication (IPC), is typically implemented by having multiple processes map a shared region of their logical address space to the same physical pages, thus using the shared page mechanism."
What is 'frames' in the context of paging?,Fixed-sized blocks of logical memory.,Fixed-sized blocks of physical memory.,Segments of the CPU cache.,Units of data transferred to the disk.,Portions of a process control block.,B,"Frames are defined as fixed-sized blocks of physical memory, which pages are loaded into."
What is a 'page' in the context of paging?,Fixed-sized blocks of physical memory.,Variable-sized blocks of logical memory.,Fixed-sized blocks of logical memory.,A region of the CPU's internal registers.,A temporary storage area on the hard drive.,C,"A page is defined as a fixed-sized block of logical memory, which corresponds in size to physical memory frames."
"Which term describes a table in paged memory containing base addresses of physical memory frames, indexed by logical page number?",Frame table,Process control block,Translation Look-aside Buffer,Page table,Directory table,D,"The 'page table' is explicitly defined as containing the base address of each frame in physical memory, indexed by the logical page number."
"Which system-wide data structure contains details about physical page frames, such as whether they are free or allocated, and to which process/page?",Page table,Process control block,Frame table,TLB,Resource allocation graph,C,"The 'frame table' is a system-wide structure that tracks the state (free/allocated, owner) of each physical page frame."
What is a 'Translation Look-aside Buffer (TLB)'?,A software component for managing virtual memory.,"A large, slow cache for disk data.","A small, fast-lookup hardware cache for address translation.",A register that points to the page table.,A component responsible for inter-process communication.,C,"The TLB is defined as a special, small, fast-lookup hardware cache used to speed up address translation in paged memory systems."
What does a 'TLB miss' signify?,The TLB has found the requested address translation.,The requested address translation is not found in the TLB.,A fatal memory error has occurred.,The TLB is being flushed.,The process is attempting to access protected memory.,B,A 'TLB miss' occurs when the TLB lookup fails to provide the required address translation because the entry is not present in the TLB.
What does it mean for a TLB entry to be 'wired down'?,The entry is marked as invalid and cannot be used.,The entry is permanently removed from the TLB.,The entry is locked into the TLB and cannot be removed by the usual replacement algorithm.,The entry is transferred to main memory for storage.,"The entry is exclusively for data access, not instruction access.",C,"Wired-down entries are those that are marked as non-removable from the TLB, typically for critical kernel code or data, ensuring they are always available for fast lookup."
What is the 'hit ratio' a measure of in the context of TLBs?,The speed of memory access.,The percentage of times a page number is found in the TLB.,The total number of memory accesses per second.,The rate of page faults.,The average number of entries replaced in the TLB.,B,The 'hit ratio' quantifies the effectiveness of a TLB by indicating the percentage of times a page number (and thus its translation) is successfully found in the TLB.
What is the 'effective memory-access time'?,The theoretical maximum speed of memory access.,The time it takes to access the TLB only.,"The statistical or real measure of CPU time to read/write to memory, considering TLB hits/misses.",The time taken to transfer data between disk and main memory.,The time required for a context switch.,C,"Effective memory-access time is a metric that considers the combined impact of TLB access times, page table access times, and hit/miss ratios to provide an overall measure of how long memory access takes."
What is the primary information contained in a 'valid-invalid' bit of a page table entry?,Whether the page has been modified (dirty bit).,Whether the page is in the process's logical address space (legal).,Whether the page is read-only or read-write.,Whether the page is currently in the TLB.,Whether the page can be swapped out to disk.,B,"The 'valid-invalid' bit primarily indicates if a page is a legitimate part of the process's logical address space. A 'valid' bit means it is, and an 'invalid' bit means it is not, and an attempt to access it will trigger a trap."
"What are the three common techniques for structuring the page table in modern computer systems, as described in the text?","Linear paging, segmented paging, and virtual paging.","Hierarchical paging, hashed page tables, and inverted page tables.","Direct mapping, associative mapping, and set-associative mapping.","Single-level paging, multi-level paging, and clustered paging.","Demand paging, pre-paging, and prepaging.",B,"The text explicitly states: 'Explores common techniques for structuring the page table: hierarchical paging, hashed page tables, and inverted page tables.'"
The need for hierarchical paging in modern computer systems primarily arises due to which of the following challenges?,The difficulty in implementing Translation Lookaside Buffers (TLBs) for 32-bit systems.,The excessive size of page tables caused by large logical address spaces.,The requirement for faster context switching between processes.,The need to support only contiguous memory allocations for processes.,The complexity of managing physical memory fragmentation.,B,The text explains that 'Modern computer systems support large logical address spaces ($2^{32}$ to $2^{64}$)' which causes the 'Page table itself becomes excessively large.' Hierarchical paging is a 'Solution: divide page table into smaller pieces.'
"For a 32-bit logical address space and a 4 KB page size ($2^{12}$ bytes), approximately how many entries would a single-level page table require?",$2^{10}$ entries,$2^{12}$ entries,$2^{20}$ entries,$2^{32}$ entries,$2^{64}$ entries,C,"A 32-bit logical address space means $2^{32}$ bytes. With a 4 KB page size ($2^{12}$ bytes), the number of pages is $2^{32} / 2^{12} = 2^{20}$. Each page corresponds to one entry in the page table."
"In a 32-bit logical address space with a 4 KB page size, if each page table entry is 4 bytes, how much physical address space could a single process's page table consume?",Up to 4 KB,Up to 1 MB,Up to 4 MB,Up to 16 MB,Up to 1 GB,C,"A 32-bit logical address space with 4 KB pages results in $2^{20}$ page table entries. With each entry being 4 bytes, the total size is $2^{20} 	imes 4$ bytes = $2^{20} 	imes 2^2$ bytes = $2^{22}$ bytes, which is 4 MB."
What is the fundamental principle behind a two-level paging algorithm?,The logical address space is divided into two equal parts.,The page table itself is paged.,Two separate TLBs are used for faster lookups.,Physical memory is divided into two distinct regions.,Virtual addresses are translated in two independent stages.,B,The text states that the 'Two-level paging algorithm' means 'page table itself is paged.'
"In a two-level paging scheme for a 32-bit logical address space with a 4 KB page size, how is the 20-bit page number typically divided?",10 bits for $p_1$ (outer page number) and 10 bits for $p_2$ (inner page offset).,12 bits for $p_1$ (outer page number) and 8 bits for $p_2$ (inner page offset).,8 bits for $p_1$ (outer page number) and 12 bits for $p_2$ (inner page offset).,15 bits for $p_1$ (outer page number) and 5 bits for $p_2$ (inner page offset).,10 bits for $p_1$ (inner page offset) and 10 bits for $p_2$ (outer page number).,A,The text specifies: 'Page number further divided: $p_1$: 10-bit outer page number (index into outer page table). $p_2$: 10-bit inner page offset (displacement within inner page table).'
What is another name for a hierarchical page table where address translation begins at the outermost page table and proceeds inward?,Inverted page table.,Hashed page table.,Clustered page table.,Forward-mapped page table.,Segmented page table.,D,The glossary defines 'forward-mapped' as: 'Scheme for hierarchical page tables where address translation starts at the outer page table and moves inward.' The main text also mentions: 'Also known as a forward-mapped page table.'
Why are two-level paging schemes considered inappropriate for 64-bit logical address spaces?,They require an excessive number of TLB entries.,The page offset becomes too large to manage effectively.,"Even with two levels, the outer page table remains excessively large, potentially gigabytes in size.",They introduce too many page faults due to inefficient memory access patterns.,64-bit systems do not use page tables for address translation.,C,"For 64-bit logical address spaces, the text states 'two-level paging scheme inappropriate' and provides an example where 'Outer page table: still $2^{42}$ entries, or $2^{44}$ bytes (16 GB)', which is excessively large."
"For a 64-bit logical address space with a 4 KB page size, what is the approximate size of the outer page table in a two-level paging scheme, considering each entry is 4 bytes?",$2^{10}$ bytes (1 KB),$2^{12}$ bytes (4 KB),$2^{20}$ bytes (1 MB),$2^{44}$ bytes (16 GB),$2^{52}$ bytes,D,"The text specifically gives this example: 'Outer page table: still $2^{42}$ entries, or $2^{44}$ bytes (16 GB).'"
"Based on the text, what is the general conclusion regarding the suitability of hierarchical page tables for 64-bit architectures?",They are highly efficient and are the preferred method.,They are only suitable if combined with extremely large TLBs.,They are generally inappropriate due to the prohibitive number of memory accesses required.,They are the only viable solution for managing 64-bit address spaces.,They require a minimum of ten levels of paging to be effective.,C,The text concludes: 'Hierarchical page tables generally inappropriate for 64-bit architectures' and mentions a 64-bit UltraSPARC 'would require seven levels of paging (prohibitive memory accesses).'
Hashed page tables are primarily introduced as an approach for handling which type of address spaces?,"Small, contiguous address spaces.",Address spaces larger than 32 bits.,Address spaces with strict security requirements.,Address spaces that do not require virtual memory.,Address spaces used only by kernel processes.,B,The text states: 'Approach for handling address spaces larger than 32 bits.'
"In a hashed page table, what serves as the hash value used to index into the hash table?",The physical page number.,The page offset.,The process ID.,The virtual page number.,The Translation Lookaside Buffer (TLB) entry.,D,The text states: 'Hash value: virtual page number.'
How do hashed page tables typically handle collisions when multiple virtual page numbers hash to the same location?,By discarding the colliding entries.,By using a secondary hash function.,By storing multiple entries directly in the hash table slot.,By using a linked list of elements at each hash table entry.,By re-hashing the entire table.,D,The text states: 'Each entry in hash table: linked list of elements (to handle collisions).'
What three fields are typically included in each element of the linked list within a hashed page table entry?,"Process ID, page size, and a timestamp.","Virtual page number, value of mapped page frame, and pointer to the next element.","Physical address, cache line number, and a flag for dirty pages.","Page fault count, TLB hit rate, and a reference bit.","Virtual address, page table entry size, and protection bits.",B,The text lists the three fields as: '1. Virtual page number. 2. Value of mapped page frame. 3. Pointer to next element in linked list.'
"According to the described algorithm for hashed page tables, what is the first step in translating a virtual address?",Search the Translation Lookaside Buffer (TLB).,Compare the virtual page number with field 1 in the first element of the linked list.,Hash the virtual page number in the virtual address into the hash table.,Retrieve the corresponding page frame from the physical memory.,Check for a match in the inner page table.,C,The algorithm description begins: 'Virtual page number in virtual address hashed into hash table.'
What is a key distinguishing characteristic of clustered page tables compared to standard hashed page tables?,They use a hierarchical structure instead of a flat hash table.,"Each entry refers to a single page, but with enhanced security.","Each entry refers to several pages (e.g., 16) instead of a single page.",They are only used for 32-bit address spaces.,They do not require a hash function for lookups.,C,"The text states: 'Each entry refers to several pages (e.g., 16) instead of a single page.'"
For which type of address spaces are clustered page tables particularly useful?,Contiguous address spaces where memory references are sequential.,Dense address spaces with very few unallocated regions.,Sparse address spaces where memory references are noncontiguous and scattered.,Address spaces used exclusively for kernel code.,Small address spaces where memory optimization is not critical.,C,"The text indicates they are 'Useful for sparse address spaces (memory references noncontiguous, scattered).'"
"In memory management, what does the term ""sparse"" describe with respect to an address space?",An address space with only a few allocated pages.,An address space where all memory references are contiguous.,An address space that is fully utilized with no free space.,An address space where page table entries are noncontiguous and scattered; an address space with many holes.,An address space that is specifically designed for multi-level paging.,D,"The glossary defines 'sparse' as: 'In memory management, describes a page table with noncontiguous, scattered entries; an address space with many holes.'"
What major drawback of standard page tables does the inverted page table scheme aim to alleviate?,The inability to support shared memory between processes.,The high computational cost of hash function calculations.,The consumption of large amounts of physical memory by potentially millions of entries per process's page table.,The increased time required for address translation lookups.,The difficulty in implementing them in hardware.,C,"The text states: 'Drawback [of standard page tables]: each page table may consist of millions of entries, consuming large amounts of physical memory.' The inverted page table is presented as a solution to this."
"In an inverted page table system, how many entries are there typically in the page table itself?",One entry for each logical page of a process.,One entry for each virtual address in the system.,One entry for each real physical page (frame) of memory.,One entry for each process currently running.,One entry for each CPU core in the system.,C,"The text defines an 'inverted page table' as having 'one entry for each real page (frame) of memory' and 'Only one page table in system, one entry per physical memory page.'"
What information is typically stored in an entry of an inverted page table?,The physical address of the page frame.,"The virtual address of the page stored in that real memory location, plus process information.",Only the process ID and a pointer to the next entry.,The page size and protection bits.,The number of times the page has been accessed.,B,"The text states: 'Each entry: virtual address of page stored in that real memory location, plus process information.'"
"In the simplified IBM RT inverted page table version, if a memory reference `<process-id, page-number>` is presented to the memory subsystem and a match is found at entry `i` in the inverted page table, how is the physical address generated?","The physical address is `<process-id, i>`.","The physical address is `<page-number, offset>`.","The physical address is `<i, offset>`.",The physical address is retrieved directly from the entry `i`.,An illegal address access is declared.,C,"The text describes: 'Match at entry $i$: physical address `<i, offset>` generated.'"
What is considered a primary drawback of inverted page tables regarding search efficiency?,They always require multiple TLB lookups.,They significantly increase the time to search the table because lookups are by virtual address but the table is implicitly sorted by physical address.,They cannot handle page faults efficiently.,"They are prone to collisions, which slows down access.",They make it difficult to determine if a page is dirty or not.,B,"The text states: 'Drawback: increases time to search table (sorted by physical address, lookups by virtual address).'"
What common technique is employed to alleviate the search time drawback of inverted page tables?,Implementing a multi-level paging scheme.,Using a hash table to limit the search.,Increasing the page size to reduce the number of entries.,Storing the inverted page table entirely in the CPU cache.,Converting the inverted page table to a forward-mapped table.,B,The text states: 'Alleviation: use a hash table to limit search.'
"When an inverted page table uses a hash table to speed up searches, how many real memory reads are required for a single virtual memory reference translation (excluding TLB hits)?",One real memory read (for the page table entry).,At least two real memory reads (hash-table entry + page table entry).,Three real memory reads (hash-table entry + two page table entries).,Four or more real memory reads depending on collisions.,Zero real memory reads if the hash table is in cache.,B,The text states: 'Each access to hash table adds memory reference: one virtual memory reference requires at least two real memory reads (hash-table entry + page table).'
How do inverted page tables typically complicate shared memory compared to standard paging?,They make it impossible for processes to share memory.,"They allow multiple virtual addresses to map to the same physical address, causing ambiguity.","They only allow one virtual page entry for every physical page, meaning a physical page cannot easily have two or more shared virtual addresses without issues.",They require a separate inverted page table for each shared memory segment.,They cause page faults when a process attempts to write to a shared memory page.,C,"The text explains: 'Inverted page tables: only one virtual page entry for every physical page. One physical page cannot have two (or more) shared virtual addresses. Reference by another process sharing memory: page fault, replaces mapping.'"
How does Oracle SPARC Solaris efficiently solve the virtual memory problem for its 64-bit architecture?,By implementing an advanced seven-level hierarchical paging scheme.,By using a highly optimized inverted page table with direct hardware support.,By utilizing hashed page tables.,By relying solely on a very large Translation Lookaside Buffer (TLB).,By employing a segmented memory management approach.,C,The text states: 'Solves virtual memory problem efficiently using hashed page tables.'
How many hash tables does Solaris on a SPARC CPU typically use for virtual to physical memory mapping?,One single hash table for all memory.,Two hash tables: one for kernel processes and one for all user processes.,A separate hash table for each running process.,"Three hash tables: one for data, one for code, and one for stack.",Only one hash table that serves as the TSB.,B,"The text states: 'Two hash tables: one for kernel, one for all user processes.'"
What feature of hash table entries in Solaris on SPARC makes them more efficient than a per-page entry system?,Each entry stores only the virtual page number.,"Each entry represents a single, fixed-size page.",Each entry stores the physical address directly without a lookup.,Each entry represents a contiguous area of mapped virtual memory with a base address and span.,Each entry includes a complete copy of the TLB.,D,The text notes: 'Each hash-table entry: contiguous area of mapped virtual memory (more efficient than per-page entry). Entry has base address and span (number of pages represented).'
What is the purpose of the Translation Storage Buffer (TSB) in Oracle SPARC Solaris?,It is the main page table for all kernel processes.,"It serves as a cache of Translation Table Entries (TTEs) for recently accessed pages, located in memory.",It is a hardware component that performs address translation without involving software.,It stores only the process IDs for active processes.,"It is a buffer for I/O operations, not related to virtual memory.",B,The text describes TSB as 'Cache of TTEs' and 'TSB includes entry per recently accessed page.'
"In the Oracle SPARC Solaris virtual address reference process (TLB walk), what is the very first step the hardware takes to find a translation?",It immediately interrupts the kernel to search the hash table.,It searches the in-memory Translation Storage Buffer (TSB).,It searches the Translation Lookaside Buffer (TLB) for the translation.,It performs a direct lookup in the main page table.,It checks the physical memory directly.,C,The first step listed is: 'Hardware searches TLB for translation.'
"If the hardware does not find a translation in the TLB during a virtual address reference in Oracle SPARC Solaris, what is the next step?",The CPU immediately generates a page fault.,The hardware walks through the in-memory Translation Storage Buffer (TSB) for the Translation Table Entry (TTE).,The operating system creates a new TTE from scratch.,The CPU accesses the main disk to find the entry.,The process is immediately terminated.,B,The second step listed is: 'None found: hardware walks through in-memory TSB for TTE. (TLB walk)'
Under what specific condition is the kernel interrupted during the virtual address translation process in Oracle SPARC Solaris?,When the hardware successfully finds a TTE in the TLB.,When the hardware finds a TTE in the TSB.,When no match is found for the TTE in both the TLB and the TSB.,When the physical memory is full.,When the process attempts to access a protected memory region.,C,The text states: 'No match in TSB: kernel interrupted to search hash table.'
"If the kernel is interrupted during a TLB walk in Oracle SPARC Solaris (due to a miss in both TLB and TSB), what is the kernel's primary responsibility?",To terminate the process causing the miss.,To load the entire hash table into the TSB.,To create the Translation Table Entry (TTE) from the hash table and store it in the TSB.,To flush the entire TLB and TSB.,To notify other processes of the memory access failure.,C,"The text states: 'Kernel creates TTE from hash table, stores in TSB for automatic loading into TLB by MMU.'"
"According to the glossary, what is the definition of a ""TLB walk""?",The process of the CPU moving data from the TLB to main memory.,The steps involved in traversing page-table structures to locate a needed translation and copying the result into the TLB.,A hardware operation that refreshes the TLB entries periodically.,The act of a user program explicitly requesting a TLB flush.,The sequence of events when a TLB entry is replaced due to a new memory access pattern.,B,The glossary defines 'TLB walk' as: 'Steps involved in traversing page-table structures to locate a needed translation and copying the result into the TLB.'
Which term describes a scheme for hierarchical page tables where address translation starts at the outer page table and moves inward?,Inverted mapping.,Backward-mapped.,Direct-mapped.,Forward-mapped.,Clustered mapping.,D,The glossary defines 'forward-mapped' as: 'Scheme for hierarchical page tables where address translation starts at the outer page table and moves inward.'
"A page table that is hashed for faster access, where the hash value is specifically the virtual page number, is known as a:",Hierarchical page table.,Inverted page table.,Forward-mapped page table.,Hashed page table.,Clustered page table.,D,The glossary defines 'hashed page table' as: 'A page table that is hashed for faster access; the hash value is the virtual page number.'
What type of page table is similar to a hashed page table but distinguishes itself by having an entry refer to a cluster of several pages rather than a single page?,Inverted page table.,Hierarchical page table.,Clustered page table.,Segmented page table.,Sparse page table.,C,"The glossary defines 'clustered page table' as: 'Similar to a hashed page table, but an entry refers to a cluster of several pages.'"
"Which page table scheme features one entry for each real physical page frame in memory, mapping to a logical page (virtual address) value?",Hierarchical page table.,Hashed page table.,Inverted page table.,Forward-mapped page table.,Clustered page table.,C,"The glossary defines 'inverted page table' as: 'A page-table scheme with one entry for each real physical page frame in memory, mapping to a logical page (virtual address) value.'"
"Which of the following best describes Solaris, as mentioned in the text?",A proprietary database management system by Oracle.,A type of RISC CPU architecture created by Sun Microsystems.,"A UNIX derivative, main operating system of Sun Microsystems (now Oracle); active open source version called Illumos.",An open-source project for developing new paging algorithms.,A network protocol for distributed computing.,C,"The glossary defines 'Solaris' as: 'A UNIX derivative, main operating system of Sun Microsystems (now Oracle); active open source version called Illumos.'"
What does SPARC refer to in the context of the provided text?,A type of specialized memory module.,A proprietary RISC CPU created by Sun Microsystems (now Oracle); active open source version called OpenSPARC.,An operating system designed for embedded systems.,A standard for inter-process communication.,A software framework for virtual machine management.,B,The glossary defines 'SPARC' as: 'A proprietary RISC CPU created by Sun Microsystems (now Oracle); active open source version called OpenSPARC.'
"For a process to execute, where must its instructions and data primarily reside?",On a hard disk for permanent storage.,In a network-attached storage device.,In main memory.,In a CPU cache.,On a USB drive.,C,The text states: 'Process instructions and data must be in memory for execution.'
What is the primary purpose of swapping a process or a portion of it temporarily out of memory to a backing store?,To provide a permanent storage solution for processes.,To archive old process data for future reference.,To free up main memory for other processes.,To perform a security scan on the process data.,To prepare the process for network transmission.,C,"The text defines 'swapped' as 'Moved between main memory and a backing store. Process swapped out to free main memory, then swapped back in to continue execution.'"
One of the key benefits of swapping is that it allows the total physical address space of all processes to do what?,Be permanently stored on the backing store.,Be limited to the size of the CPU registers.,Exceed the real physical memory available.,Be entirely contained within the CPU cache.,Be encrypted for security purposes.,C,The text explicitly states: 'Swapping allows total physical address space of all processes to exceed real physical memory.'
How does swapping typically affect the degree of multiprogramming in an operating system?,It decreases the degree of multiprogramming.,It has no impact on the degree of multiprogramming.,It significantly increases the degree of multiprogramming.,"It only affects single-threaded processes, not multiprogramming.",It causes multiprogramming to halt temporarily.,C,The text says: 'Increases degree of multiprogramming.'
"In the context of standard swapping, what is moved between main memory and the backing store?",Only the critical data segments of a process.,Entire processes.,Individual threads of a process.,Only the instruction code of a process.,Only the process metadata.,B,The 'Standard swapping' section states: 'Involves moving entire processes between main memory and backing store.'
Which of the following best describes a 'backing store' as defined in the context of swapping?,A specialized CPU register for storing temporary data.,The primary memory (RAM) used for active processes.,A network-attached storage device for long-term archiving.,"A fast secondary storage area, large enough for process parts, with direct access to memory images.",A dedicated partition on the main hard drive for system logs.,D,"The text defines 'backing store' as 'Secondary storage area used for process swapping' and further describes it as 'fast secondary storage, large enough for process parts, direct access to memory images' under Standard Swapping."
"When a process or part is swapped to a backing store, what associated data structures must also be written?",Only the process ID and creation time.,Only the memory addresses of the process.,"Associated data structures, including per-thread data for multithreaded processes.",Only the compiled executable code.,"None, as data structures remain in main memory.",C,"The text mentions: 'When process/part swapped to backing store, associated data structures (including per-thread data for multithreaded processes) must be written.'"
What is the operating system's role concerning processes that have been swapped out?,It permanently deletes all information about them.,It maintains metadata for their restoration.,It encrypts them and moves them to a secure archive.,It hands over their management to a user-level application.,It requires the user to manually restore them.,B,The text states: 'OS maintains metadata for swapped-out processes for restoration.'
What is a significant advantage of standard swapping regarding physical memory utilization?,It ensures that physical memory is never completely filled.,It reduces the total amount of physical memory required by the system.,"It allows physical memory to be oversubscribed, accommodating more processes than actual physical memory.",It strictly limits the number of processes that can be in memory at any time.,It dedicates a fixed amount of memory to each process regardless of its activity.,C,"The text lists as an advantage: 'allows physical memory to be oversubscribed, accommodates more processes than physical memory.'"
Which type of processes are considered good candidates for standard swapping?,Critical system processes that require constant execution.,Active processes currently interacting with the user.,Idle or mostly idle processes.,Processes with very small memory footprints.,Processes that are about to terminate.,C,The text states: 'Idle/mostly idle processes good candidates for swapping.'
"If an inactive process that has been swapped out becomes active, what must happen for its continued execution?",It must be terminated and restarted.,It must remain on the backing store and execute remotely.,It must be swapped back into main memory.,Its data can be accessed directly from the backing store without moving.,"The OS will create a new, identical process in memory.",C,"The text specifies: 'If inactive swapped-out process becomes active, must be swapped back in.'"
Which statement is true regarding the general use of standard swapping in contemporary operating systems?,It is the primary method used by all modern OS.,It is widely used due to its high efficiency.,"It is generally no longer used, with Solaris being a rare exception under dire circumstances.",It is used exclusively by Linux and Windows for all memory management.,It has been completely replaced by virtual memory techniques.,C,The 'Swapping with paging' section states: 'Standard swapping generally no longer used in contemporary OS (exception: Solaris under dire circumstances).'
What is the main reason standard swapping is generally no longer used in contemporary operating systems?,It causes system instability and crashes.,The time required to move entire processes is prohibitive.,It is not compatible with modern CPU architectures.,It significantly increases the cost of hardware.,It poses a major security risk.,B,The text explains: 'Reason: time to move entire processes prohibitive.'
"Instead of swapping entire processes, what variation do most contemporary systems like Linux and Windows use?",They completely disable swapping.,They swap only the kernel space.,They swap individual pages of a process.,They move processes directly to archival storage.,"They only swap process metadata, not the data itself.",C,"The text notes: 'Most systems (Linux, Windows) use variation: pages of a process swapped, not entire process.'"
"In the context of modern OS, when the text refers to 'swapping' without further qualification, what does it generally imply?",The movement of individual pages.,The transfer of application state to flash memory.,Standard swapping of entire processes.,The process of moving data between CPU caches.,The act of changing CPU cores.,C,The text clarifies: 'Term swapping now generally refers to standard swapping.'
"When referring to 'swapping with paging' in modern systems, what term is commonly used?",Context switching.,Migration.,Paging.,Hibernation.,Relocation.,C,The text states: 'Paging refers to swapping with paging.'
What is the process known as 'page out'?,Moving a page from backing store to memory.,Moving an entire process from memory to backing store.,Moving a page from memory to backing store.,Copying a page within main memory.,Deleting a page from the system.,C,The text defines: 'Page out: moves page from memory to backing store.'
What is the process known as 'page in'?,Moving an entire process from memory to backing store.,Moving a page from backing store to memory.,Moving a page from memory to backing store.,Copying a page to a new memory location.,Creating a new page in memory.,B,"The text states: 'Page in: reverse process' of page out, which is moving a page from memory to backing store. Thus, page in moves it from backing store to memory."
Which of the following is true about swapping on mobile systems?,They extensively use standard swapping due to limited RAM.,They typically do not support swapping.,They utilize a highly optimized version of page-based swapping.,"They swap only application code, not data.",They rely on user-initiated swapping through settings.,B,The 'Swapping on mobile systems' section begins with: 'Mobile systems typically do not support swapping.'
One reason mobile systems typically do not support swapping is related to their use of flash memory for nonvolatile storage. What is this reason?,Flash memory is too expensive for swapping operations.,"Flash memory has unlimited write cycles, making it unsuitable.",Flash memory has space constraints and limited write endurance.,Flash memory is not fast enough for data retrieval.,Flash memory causes excessive battery drain during swapping.,C,Reasons for not supporting swapping include: 'Flash memory (not hard disks) for nonvolatile storage -> space constraint' and 'Limited number of writes flash memory tolerates before unreliability.'
Another reason mobile systems avoid swapping is due to poor throughput between which two components?,CPU and cache memory.,Main memory and flash memory.,Network interface and external servers.,Graphics processing unit and display.,Sensors and the operating system.,B,One of the reasons listed is: 'Poor throughput between main memory and flash memory.'
"Instead of swapping, what strategy does Apple's iOS employ when free memory is low?",It automatically swaps entire applications to the cloud.,It asks applications to voluntarily relinquish allocated memory.,It terminates all background processes immediately.,It compresses all data in memory to free up space.,It notifies the user to manually close applications.,B,The text states: 'Apple's iOS: asks applications to voluntarily relinquish allocated memory when free memory low.'
"In Apple's iOS memory management strategy, what happens to read-only data (code) when free memory is low?",It is permanently deleted to free up space.,It is compressed and kept in main memory.,It is removed from main memory and reloaded from flash if needed.,It is moved to a special secure partition.,It is never affected by low memory conditions.,C,"For iOS: 'Read-only data (code) removed from main memory, reloaded from flash if needed.'"
"In Apple's iOS memory management strategy, how is modified data (e.g., stack) handled when free memory is low?",It is prioritized for removal to backing store.,It is compressed and kept in main memory.,It is always removed to free up space.,It is never removed from main memory.,It is written to a special log file for later recovery.,D,For iOS: 'Modified data (stack) never removed.'
What action might the iOS operating system take if applications fail to voluntarily free memory when requested?,It will prompt the user to intervene.,It will suspend the application indefinitely.,It may terminate the application.,It will automatically store the application's state to disk.,It will increase the system's virtual memory.,C,The text mentions: 'Applications failing to free memory may be terminated by OS.'
"Android employs a strategy similar to iOS for low free memory. What additional step does Android take before terminating a process, compared to iOS's handling of modified data?",It encrypts the entire process memory.,It performs a full backup of the device.,It writes the application state to flash memory for quick restart.,It prompts the user for permission to terminate.,It moves the process to a different CPU core.,C,"For Android: 'Before termination, writes application state to flash memory for quick restart.'"
What is 'application state' defined as in the provided glossary?,The current CPU usage of an application.,A software construct for data storage.,The graphical user interface of an application.,The security permissions assigned to an application.,The network connection status of an application.,B,The glossary defines 'application state' as 'Software construct for data storage.'
"What is typically indicated by a system experiencing a high amount of swapping, regardless of the form?",The system has an abundance of physical memory.,The CPU is underutilized and idling.,There are more active processes than available physical memory.,The network connection is slow.,The hard disk is failing.,C,The text states: 'Swapping (any form) often sign of more active processes than available physical memory.'
What are two common approaches to address system performance issues caused by excessive swapping?,Install a faster CPU or upgrade the GPU.,Increase network bandwidth or reduce power consumption.,Terminate some processes or get more physical memory.,Migrate to a different operating system or reinstall drivers.,Run a disk defragmenter or optimize the file system.,C,The text lists two approaches: 'Terminate some processes' or 'Get more physical memory.'
What is the general term for the process of moving a page from the backing store back into main memory?,Page flush,Page fault,Page in,Page out,Page cleanup,C,"The text defines 'page in' as the reverse process of 'page out' (moving a page from memory to backing store), meaning 'page in' moves a page from backing store to memory."
"Which company's chips dominated the personal computer (PC) landscape for decades, starting with 16-bit processors in the late 1970s?",AMD,NVIDIA,Intel,Qualcomm,IBM,C,The text states that 'Intel chips: dominated PC landscape for decades.'
What was the 16-bit Intel processor that was specifically mentioned as being part of the original IBM PC?,Intel 8086,Intel 80286,Intel 80386,Intel 8088,Intel Pentium,D,"The text specifies '16-bit Intel 8086 (late 1970s), then 8088 (original IBM PC).'"
"Which term refers to Intel's 32-bit chips, including Pentium processors?",x86-64,IA-64,ARM,IA-32,Itanium,D,"The text states: '32-bit chips: IA-32, included Pentium processors.'"
Intel's current 64-bit chips are based on which architecture?,IA-32e,IA-64,x86-64,ARM64,PowerPC,C,The text mentions '64-bit chips: based on x86-64 architecture.'
Which of the following operating systems are explicitly stated to run on Intel chips for current PCs?,"Windows, Chrome OS, Android","Windows, Mac, Linux","iOS, Android, Linux","Mac, Chrome OS, Windows Phone",All of the above,B,"The text says 'Current PC OS (Windows, Mac, Linux) run on Intel chips.'"
"In which computing segment has Intel not achieved dominance, with another architecture proving successful?",Server systems,Desktop systems,Mobile systems,Embedded systems,High-performance computing,C,The text notes 'Intel dominance not in mobile systems; ARM architecture successful.'
What architecture is explicitly mentioned as being successful in mobile systems where Intel does not dominate?,x86-64,IA-32,IA-64,ARM,MIPS,D,The text states 'Intel dominance not in mobile systems; ARM architecture successful.'
What are the two major memory-management concepts utilized in Intel IA-32 CPUs?,Caching and buffering,Segmentation and paging,Virtualization and emulation,Swapping and overlays,Protection and sharing,B,The text explicitly lists 'Memory management in IA-32: segmentation and paging.'
"In the IA-32 memory management process, what type of address does the CPU initially generate before it's sent to the segmentation unit?",Physical addresses,Linear addresses,Virtual addresses,Logical addresses,Symbolic addresses,D,The text describes the flow: 'CPU generates logical addresses -> segmentation unit.'
"What type of address is produced by the segmentation unit in IA-32, which is then sent to the paging unit?",Logical address,Physical address,Virtual address,Linear address,Segment address,D,The text describes the flow: 'Segmentation unit produces linear address -> paging unit.'
Which component in the IA-32 architecture is responsible for generating the final physical address in main memory?,CPU,Segmentation unit,Memory-Management Unit (MMU),Paging unit,Address bus,D,The text describes the flow: 'Paging unit generates physical address in main memory.'
What two units together form the Memory-Management Unit (MMU) in IA-32 architecture?,CPU and Registers,Cache and Main Memory,Segmentation and paging units,Arithmetic Logic Unit and Control Unit,Disk and RAM,C,The text states 'Segmentation and paging units form memory-management unit (MMU).'
What is the maximum segment size allowed in IA-32 segmentation?,64 KB,1 MB,2 GB,4 GB,16 GB,D,The text specifies 'IA-32 segment size: up to 4 GB.'
What is the maximum number of segments a process can have in IA-32 architecture?,8 K,16 K,32 K,64 K,256 K,B,The text states 'Max segments per process: 16 K.'
How many partitions is the logical address space divided into within IA-32 segmentation?,One,Two,Three,Four,Eight,B,The text indicates 'Logical address space divided into two partitions.'
"In IA-32 segmentation, how many segments are available in the partition that is private to a process?",Up to 4 K,Up to 8 K,Up to 16 K,Up to 32 K,Unlimited,B,"The text notes 'First partition: up to 8 K segments, private to process.'"
"In IA-32 segmentation, how many segments are available in the partition that is shared among all processes?",Up to 4 K,Up to 8 K,Up to 16 K,Up to 32 K,Unlimited,B,"The text notes 'Second partition: up to 8 K segments, shared among all processes.'"
What table holds information for segments private to a process in IA-32 segmentation?,Global Descriptor Table (GDT),Page Directory (PD),Local Descriptor Table (LDT),Translation Lookaside Buffer (TLB),Process Control Block (PCB),C,The text states 'Information for first partition: local descriptor table (LDT).'
What table holds information for segments shared among all processes in IA-32 segmentation?,Local Descriptor Table (LDT),Page Table (PT),Global Descriptor Table (GDT),Segment Register File (SRF),Master Page Table (MPT),C,The text states 'Information for second partition: global descriptor table (GDT).'
What is the size of each entry in the Local Descriptor Table (LDT) or Global Descriptor Table (GDT) in IA-32 segmentation?,4-byte,8-byte,16-byte,32-byte,64-byte,B,The text states 'Each LDT/GDT entry: 8-byte segment descriptor.'
A logical address in IA-32 architecture is composed of which two parts?,Base and Limit,Page Number and Offset,Selector and offset,Segment Number and Byte Address,Linear Address and Physical Address,C,"The text states 'Logical address: (selector, offset).'"
What is the bit size of the selector in an IA-32 logical address?,8-bit,16-bit,24-bit,32-bit,48-bit,B,The text states 'Selector: 16-bit number.'
Which three pieces of information are encoded within the 16-bit selector in an IA-32 logical address?,"Segment number, GDT/LDT indicator, and protection","Base address, limit, and permissions","Page number, page size, and valid bit","Process ID, thread ID, and privilege level","Virtual address, linear address, and physical address",A,"The text details the selector's components: 's: segment number, g: GDT or LDT, p: protection.'"
What is the bit size of the offset in an IA-32 logical address?,16-bit,20-bit,24-bit,32-bit,48-bit,D,The text states 'Offset: 32-bit number.'
"How many segment registers does an IA-32 machine typically have, allowing simultaneous addressing of segments?",Two,Four,Six,Eight,Sixteen,C,The text states 'Machine has six segment registers: allows six segments addressed at once.'
What is the primary purpose of the six 8-byte microprogram registers (LDT/GDT cache) associated with segment registers in IA-32?,To store logical addresses permanently,To increase the maximum segment size,To avoid reading segment descriptors from memory for every reference,To perform address validation checks,To directly store physical addresses,C,"The text explains, 'Cache avoids reading descriptor from memory for every reference.'"
What is the bit length of a linear address in IA-32 architecture?,16 bits,20 bits,32 bits,36 bits,48 bits,C,The text states 'Linear address (IA-32): 32 bits long.'
Which two pieces of information from a segment descriptor are used to generate a linear address in IA-32?,Selector and Offset,Page Number and Page Size,Base and limit,Protection and Segment Number,Entry Size and Table Pointer,C,The text says 'Base and limit from segment descriptor generate linear address.'
"What mechanism is used in IA-32 segmentation to check for the validity of an address, triggering a memory fault if invalid?",Page directory lookup,TLB hit/miss check,Offset calculation,Limit checks,Protection bits,D,The text states 'Limit checks address validity; invalid -> memory fault (trap to OS).'
What are the two standard page sizes supported by IA-32 paging?,1 KB or 2 KB,4 KB or 4 MB,8 KB or 8 MB,16 KB or 16 MB,32 KB or 32 MB,B,The text states 'IA-32 page size: 4 KB or 4 MB.'
"For 4-KB pages in IA-32, what type of paging scheme is employed?",Single-level paging,Two-level paging scheme,Three-level paging scheme,Four-level paging scheme,Inverted page table,B,The text states 'For 4-KB pages: two-level paging scheme.'
"When using 4-KB pages in IA-32, how are the 32-bit linear addresses typically divided into page numbers and offset?","12 bits (p1), 10 bits (p2), 10 bits (offset)","10 bits (p1), 10 bits (p2), 12 bits (offset)","10 bits (p1), 12 bits (p2), 10 bits (offset)","16 bits (p1), 16 bits (offset)","20 bits (p1), 12 bits (offset)",B,"The text details: 'Page number p1: 10 bits (high-order), Page number p2: 10 bits (inner), Page offset d: 12 bits (low-order).'"
"In IA-32 paging with 4-KB pages, what is the outermost page table called, referenced by the 10 high-order bits of the linear address?",Page table entry,Page directory,Page frame,Page descriptor table,Page pointer table,B,The text states '10 high-order bits reference entry in outermost page table: page directory.'
Which register points to the page directory for the current process in IA-32 paging?,CR0,CR2,CR3,CR4,EIP,C,The text states 'CR3 register points to page directory for current process.'
"In a two-level IA-32 paging scheme for 4-KB pages, what does a page directory entry typically point to?",A physical address directly,An inner page table,The main memory,A segment descriptor,The process control block,B,The text states 'Page directory entry points to inner page table (indexed by inner 10 bits).'
What are the low-order bits used for the offset within a 4-KB page in IA-32 paging?,Bits 0-7,Bits 0-11,Bits 0-15,Bits 0-19,Bits 0-21,B,The text states 'Low-order bits 0-11: offset in 4-KB page.'
"Which flag within a page directory entry indicates that the page frame is 4 MB in IA-32 paging, bypassing the inner page table?",Present flag,Dirty flag,Accessed flag,Page_Size flag,Write-Protect flag,D,The text states 'Page directory entry: Page_Size flag. If Page_Size set: page frame is 4 MB (bypasses inner page table).'
"When the Page_Size flag indicates a 4 MB page frame in IA-32, which low-order bits in the linear address are used as the offset?",The 12 low-order bits,The 10 low-order bits,The 22 low-order bits,The 32 low-order bits,The 20 low-order bits,C,The text states '22 low-order bits in linear address: offset in 4-MB page frame.'
"For efficiency, where can IA-32 page tables be temporarily stored?",In a dedicated hardware cache only,In CPU registers,Swapped to disk,In flash memory,In the BIOS ROM,C,The text says 'IA-32 page tables can be swapped to disk for efficiency.'
What does the 'invalid bit' in an IA-32 page directory entry indicate?,That the page frame is corrupt,That the page table is in memory or on disk,That the page is write-protected,That the page is currently being accessed by another process,That the page directory itself is invalid,B,The text says 'Invalid bit in page directory entry: indicates table in memory or on disk.'
What limitation of 32-bit architectures primarily led to the development of Page Address Extension (PAE)?,The limited number of segment registers,The complex two-level paging scheme,The 4-GB memory limitation,The inability to support multiple processes,The slow speed of context switching,C,The text states '4-GB memory limitations of 32-bit architectures led to page address extension (PAE).'
What is the primary function of Page Address Extension (PAE) in IA-32 CPUs?,To enable 64-bit processing on 32-bit CPUs,To allow 32-bit processors to access physical address space larger than 4 GB,To decrease the number of paging levels for efficiency,To increase the segment size beyond 4 GB,To completely eliminate the need for segmentation,B,"PAE allows 32-bit processors to access physical address space larger than 4 GB, overcoming the 4-GB memory limitation. This is explicitly stated: 'PAE: allows 32-bit processors to access physical address space > 4 GB.'"
How does PAE change the paging scheme in IA-32 architecture?,It simplifies it to a single-level scheme,It changes from a two-level to a three-level scheme,It introduces a five-level hierarchy,It replaces paging with segmentation,It makes paging optional,B,The text states 'PAE changes paging from two-level to three-level scheme.'
"In the PAE 3-level paging scheme, what does the top two bits of the address refer to?",The page directory,The inner page table,The page directory pointer table,The physical address,The segment selector,C,The text states 'Top two bits refer to page directory pointer table.'
"Besides the standard 4-KB pages, what other page size is explicitly mentioned as being supported by PAE?",1-MB pages,2-MB pages,8-MB pages,16-MB pages,64-MB pages,B,The text mentions 'PAE also supports 2-MB pages.'
How did PAE increase the size of page-directory and page-table entries?,From 16 to 32 bits,From 32 to 64 bits,From 64 to 128 bits,From 8 to 16 bits,It did not change entry sizes,B,The text states 'PAE increased page-directory and page-table entries from 32 to 64 bits.'
How did PAE extend the base address of page tables/frames?,From 12 to 16 bits,From 16 to 20 bits,From 20 to 24 bits,From 24 to 32 bits,From 32 to 36 bits,C,The text states 'Allowed base address of page tables/frames to extend from 20 to 24 bits.'
"Combining the extended base address with the 12-bit offset, what total address space in bits did PAE increase for physical memory?",32 bits,36 bits,40 bits,48 bits,64 bits,B,The text says 'Combined with 12-bit offset: PAE increased address space to 36 bits.'
What is the maximum amount of physical memory that PAE supports?,4 GB,16 GB,32 GB,64 GB,128 GB,D,The text states 'Supports up to 64 GB physical memory.'
Which operating systems are explicitly mentioned as supporting PAE for 32-bit systems?,Windows XP and Vista,Linux and Mac,MS-DOS and Windows 98,Unix and Solaris,All versions of Windows,B,"The text states 'OS support required for PAE (Linux, Mac support; 32-bit Windows desktop -> 4 GB limit).'"
What was Intel's initial 64-bit architecture that was not widely adopted?,x86-64,Pentium Pro,IA-64 (Itanium),Atom,Core 2 Duo,C,"The text states 'Intel's initial 64-bit architecture: IA-64 (later Itanium), not widely adopted.'"
Which company originally developed the x86-64 architecture by extending the existing IA-32 instruction set?,Intel,IBM,Microsoft,AMD,Motorola,D,The text states 'AMD developed x86-64: extended existing IA-32 instruction set.'
What was a key improvement brought by the x86-64 architecture over IA-32?,Reduced power consumption,Smaller chip size,Support for larger logical and physical address spaces,Elimination of segmentation,Increased clock speed only,C,"The text says 'x86-64: supported larger logical/physical address spaces, architectural advances.'"
Which company eventually adopted AMD's x86-64 architecture?,ARM Holdings,NVIDIA,Intel,VIA Technologies,Qualcomm,C,The text states 'Intel adopted AMD's x86-64 architecture.'
"What is the general term used to refer to the class of 64-bit CPUs running identical instruction sets, common in desktop/server systems?",IA-32,IA-64,ARM,x86-64,RISC,D,"The text states 'Use general term x86-64 (instead of AMD 64, Intel 64).' and the glossary defines it."
A 64-bit address space theoretically allows for how many bytes of addressable memory?,4 GB,64 GB,2^48 bytes,2^64 bytes (16 exabytes),Unlimited,D,The text states '64-bit address space: potentially 2^64 bytes (16 quintillion / 16 exabytes).'
"In practice, how many bits are used for the virtual address in the x86-64 architecture?",32-bit,36-bit,48-bit,52-bit,64-bit,C,The text states 'x86-64 architecture: 48-bit virtual address.'
What are the page sizes supported by the x86-64 architecture?,Only 4 KB,4 KB or 4 MB,"4 KB, 2 MB, or 1 GB",2 MB or 1 GB only,Any multiple of 4 KB,C,"The text states 'Supports page sizes: 4 KB, 2 MB, or 1 GB.'"
How many levels of paging hierarchy does the x86-64 architecture typically use?,Two,Three,Four,Five,One,C,The text states 'Uses four levels of paging hierarchy.'
Does the x86-64 architecture utilize the Page Address Extension (PAE) addressing scheme?,Yes,No,Only for 4KB pages,Only for 1GB pages,It uses an entirely different scheme unrelated to PAE,A,The text states 'Addressing scheme uses PAE.'
"With its 48-bit virtual addresses, what is the maximum physical address size supported by the x86-64 architecture?",32-bit (4 GB),36-bit (64 GB),48-bit (256 TB),"52-bit (4,096 terabytes)",64-bit (16 exabytes),D,"The text states 'Virtual addresses 48 bits, support 52-bit physical addresses (4,096 terabytes).'"
"According to the section glossary, what is a 'page directory'?",The innermost page table in Intel IA-32 CPU architecture.,A cache for physical addresses.,The outermost page table in Intel IA-32 CPU architecture.,A table used for segment-to-linear address translation.,A list of all active processes.,C,"The glossary defines 'page directory' as 'In Intel IA-32 CPU architecture, the outermost page table.'"
"According to the section glossary, what is the definition of 'Page Address Extension (PAE)'?",A software utility to extend RAM capacity.,Intel IA-32 CPU hardware allowing 32-bit processors to access physical address space larger than 4GB.,An architectural feature of 64-bit processors to increase virtual memory.,A method to compress page tables for efficiency.,A protocol for networked memory access.,B,The glossary defines 'page address extension (PAE)' as 'Intel IA-32 CPU hardware allowing 32-bit processors to access physical address space larger than 4GB.'
"According to the section glossary, what is a 'page directory pointer table'?",A table that points to segment descriptors.,A cache for frequently used page entries.,PAE pointer to page tables.,The table holding 4MB page entries.,A part of the x86-64 architecture for 1GB pages.,C,The glossary defines 'page directory pointer table' as 'PAE pointer to page tables.'
"According to the section glossary, what is 'Itanium'?",An AMD 64-bit CPU.,Intel IA-64 CPU.,A specific type of memory module.,An early 32-bit Intel processor.,A proprietary operating system.,B,The glossary defines 'Itanium' as 'Intel IA-64 CPU.'
"According to the section glossary, what is 'AMD 64'?",An Intel 64-bit CPU architecture.,A specific version of the IA-32 architecture.,A 64-bit CPU designed by Advanced Micro Devices; part of x86-64 class.,A memory standard for 64-bit systems.,A mobile processor architecture.,C,The glossary defines 'AMD 64' as 'A 64-bit CPU designed by Advanced Micro Devices; part of x86-64 class.'
"According to the section glossary, what is 'Intel 64'?",Intel's original 32-bit CPU line.,"Intel 64-bit CPUs, part of x86-64 class.",A server-specific 64-bit architecture unrelated to x86.,A brand name for Intel's mobile processors.,The name for Intel's IA-64 architecture.,B,"The glossary defines 'Intel 64' as 'Intel 64-bit CPUs, part of x86-64 class.'"
"According to the section glossary, what is 'x86-64'?",An obsolete 16-bit instruction set.,A proprietary Intel architecture for supercomputers.,Class of 64-bit CPUs running identical instruction set; common in desktop/server systems.,A specific type of graphics processing unit (GPU).,A network communication protocol.,C,The glossary defines 'x86-64' as 'Class of 64-bit CPUs running identical instruction set; common in desktop/server systems.'
"What is a key difference in the business models of ARM and Intel, according to the text?","Intel only designs chips, while ARM manufactures them.","ARM designs and manufactures chips, while Intel only licenses designs.","ARM only designs and licenses architectural designs, while Intel designs and manufactures chips.",Both ARM and Intel primarily focus on manufacturing chips for servers.,"Intel licenses designs to manufacturers, while ARM manufactures directly.",C,"The text states that 'Intel: designs and manufactures chips' and 'ARM: only designs, licenses architectural designs to manufacturers'."
"Which type of devices are ARM processors most commonly associated with, according to the overview?",High-performance servers,Desktop personal computers,Mobile devices like smartphones and tablets,Large mainframe systems,Specialized supercomputers,C,"The text explicitly states: 'ARM processors: common for mobile devices (smartphones, tablets)'."
"Besides mobile devices, ARM processors are also noted for their use in which specific type of systems?",High-end gaming consoles,Cloud data center infrastructure,Real-time embedded systems,Desktop publishing workstations,Large-scale enterprise databases,C,The text mentions ARM is 'Also for real-time embedded systems'.
What claim is made about ARM processors' prevalence in terms of quantity?,They are the least widely used architecture.,They are used exclusively in niche markets.,"Over 100 billion have been produced, making it the most widely used architecture by quantity.",Their production numbers are declining rapidly.,They are primarily used in experimental and research settings.,C,The text states: 'Over 100 billion ARM processors produced; most widely used architecture by quantity'.
Which specific ARM architecture is the primary focus of the provided text?,ARM v6 32-bit architecture,ARM v7-A architecture,ARM v8 64-bit architecture,ARM Cortex-M series,ARM Mali GPU architecture,C,The text explicitly states the 'Focus: 64-bit ARM v8 architecture'.
How many distinct translation granule sizes does ARM v8 architecture support?,One,Two,Three,Four,Five,C,"ARM v8 has three translation granules: 4 KB, 16 KB, and 64 KB."
Which of the following lists correctly identifies the three translation granule sizes supported by ARM v8?,"1 KB, 2 KB, and 4 KB","4 KB, 8 KB, and 16 KB","4 KB, 16 KB, and 64 KB","8 KB, 32 KB, and 128 KB","16 KB, 32 KB, and 64 KB",C,"The text lists the translation granules as: '4 KB, 16 KB, and 64 KB'."
What is the primary function of translation granules in ARM v8 architecture?,To define CPU clock speeds and bus interfaces.,To specify the number of available CPU registers.,To provide different page sizes and larger contiguous memory sections called regions.,To manage instruction pipelines and branch prediction.,To control I/O device access and interrupt handling.,C,The text states: 'Each granule provides different page sizes and larger contiguous memory sections called regions'.
"According to the glossary, what are 'regions' in ARM v8 CPUs?",The smallest addressable units of memory.,Contiguous memory areas with separate privilege and access rules.,Hardware caches used for fast data retrieval.,Registers that store CPU status information.,Software segments for application code.,B,"The glossary defines 'regions' as: 'In ARM v8 CPUs, contiguous memory areas with separate privilege and access rules'."
"For a 4 KB translation granule in ARM v8, what is the associated page size?",1 KB,4 KB,16 KB,64 KB,2 MB,B,The table shows that a 4 KB Translation Granule Size corresponds to a 4 KB Page Size.
Which region sizes are supported by a 4 KB translation granule in ARM v8?,32 MB only,512 MB only,2 MB and 1 GB,4 KB and 16 KB,1 GB only,C,"The table indicates that for a 4 KB granule, the Region Size can be '2 MB, 1 GB'."
What is the page size associated with a 16 KB translation granule in ARM v8?,4 KB,8 KB,16 KB,32 KB,64 KB,C,The table shows that a 16 KB Translation Granule Size corresponds to a 16 KB Page Size.
What is the region size provided when using a 16 KB translation granule in ARM v8?,2 MB,32 MB,512 MB,1 GB,4 KB,B,"The table indicates that for a 16 KB granule, the Region Size is '32 MB'."
"For a 64 KB translation granule in ARM v8, what is the corresponding page size?",16 KB,32 KB,64 KB,128 KB,256 KB,C,The table shows that a 64 KB Translation Granule Size corresponds to a 64 KB Page Size.
Which region size is associated with a 64 KB translation granule in ARM v8?,2 MB,32 MB,512 MB,1 GB,4 KB,C,"The table indicates that for a 64 KB granule, the Region Size is '512 MB'."
What is the maximum number of paging levels that can be used with 4-KB and 16-KB translation granules in ARM v8?,Two levels,Three levels,Four levels,Five levels,Six levels,C,The text states: '4-KB and 16-KB granules: up to four levels of paging'.
What is the maximum number of paging levels supported by 64-KB translation granules in ARM v8?,Two levels,Three levels,Four levels,Five levels,Six levels,B,The text states: '64-KB granules: up to three levels of paging'.
"Although ARM v8 is a 64-bit architecture, how many bits are currently used for addressing, according to the text?",32 bits,48 bits,52 bits,60 bits,64 bits,B,"The text mentions: 'ARM v8 is 64-bit architecture, but only 48 bits currently used'."
What is the primary role of the TTBR (Translation Table Base Register) in ARM v8?,It stores the physical address of the current instruction.,It points to the level 0 (outer) page table for the current thread.,It holds the base address for the interrupt vector table.,It manages the translation Lookaside Buffers (TLBs).,It defines the memory access permissions for a process.,B,"The text and glossary define TTBR as the 'translation table base register, points to level 0 table for current thread'."
"When all four paging levels are used with a 4-KB granule in ARM v8, which bits are used to refer to the offset within the 4-KB page?",Bits 0-7,Bits 0-11,Bits 0-15,Bits 0-19,Bits 0-20,B,The text specifies: 'offset (bits 0-11) refers to offset within 4-KB page'.
"If a Level-1 table entry refers to a 1-GB region, which low-order bits are used as the offset within that region?",Bits 0-11,Bits 0-20,Bits 0-29,Bits 0-31,Bits 0-39,C,The text states: 'Level-1 table refers to 1-GB region: low-order 30 bits (0-29) used as offset'.
"When a Level-2 table entry refers to a 2-MB region, which low-order bits are used as the offset?",Bits 0-11,Bits 0-20,Bits 0-29,Bits 0-31,Bits 0-39,B,The text states: 'Level-2 table refers to 2-MB region: low-order 21 bits (0-20) used as offset'.
How many levels of Translation Lookaside Buffers (TLBs) does the ARM architecture support?,One level,Two levels,Three levels,Four levels,No TLB support,B,The text indicates: 'ARM architecture supports two levels of TLBs'.
What components make up the inner level of TLBs in ARM architecture?,A single combined instruction/data TLB,Two micro TLBs: one for data and one for instructions,A main TLB for all translations,Four micro TLBs for different privilege levels,Only one micro TLB for instructions,B,"The text specifies: 'Inner level: two micro TLBs (one for data, one for instructions)'."
What specific feature do the inner-level micro TLBs in ARM support?,Virtualization extensions,Hardware breakpoints,ASIDs (Address Space Identifiers),Out-of-order execution,Dynamic frequency scaling,C,The text states that the micro TLBs 'support ASIDs'.
What is the single TLB at the outer level in ARM architecture called?,Micro TLB,Global TLB,Main TLB,Instruction TLB,Data TLB,C,The text specifies: 'Outer level: single main TLB'.
Where does the address translation process begin in the ARM architecture?,At the main TLB level,Directly with a page table walk,At the micro-TLB level,In the CPU's general-purpose registers,Within the instruction cache,C,The text explains: 'Address translation process: Begins at micro-TLB level'.
"If a micro-TLB miss occurs during address translation in ARM, what is the immediate next step?",A page table walk is performed immediately.,The main TLB is checked.,An exception or interrupt is generated.,The process is terminated.,Data is fetched directly from main memory.,B,The text describes the process: 'Micro-TLB miss: main TLB checked'.
What action is performed if both the micro-TLB and the main TLB miss during address translation in ARM?,The system reports a fatal error.,The CPU automatically loads data from disk.,A hardware page table walk is performed.,The operating system restarts the process.,The request is retried after a short delay.,C,The text specifies: 'Both TLBs miss: page table walk performed in hardware'.
"According to the glossary, what are 'translation granules'?",Small memory buffers used for temporary data storage.,Features of ARM v8 CPUs defining page sizes and regions.,Registers that hold the current program counter.,Software routines for memory management.,Types of instruction sets for different processors.,B,The glossary defines 'translation granules' as: 'Features of ARM v8 CPUs defining page sizes and regions'.
"Based on the glossary, which statement accurately describes the 'main TLB'?",It is the inner-level TLB specifically for instruction lookups.,"It is the outer-level TLB, checked after a micro TLB lookup and before a page table walk.",It is a cache for frequently accessed kernel data.,It is a register that stores the base address of the translation tables.,It is a buffer used exclusively for I/O operations.,B,The glossary defines 'main TLB' as: 'ARM CPU outer-level TLB; checked after micro TLB lookup and before page table walk'.
"According to the glossary, what is a 'micro TLB'?","A single, unified cache for both instructions and data.",The main outer-level TLB for global addresses.,"ARM CPU inner-level TLBs, one for instructions and one for data.",A specialized register for storing physical addresses.,A buffer used to optimize CPU pipeline stages.,C,"The glossary defines 'micro TLB' as: 'ARM CPU inner-level TLBs, one for instructions and one for data'."
"Which of the following best describes the fundamental nature of 'Memory' in modern computer systems, as described?","A small, fast cache dedicated to CPU arithmetic operations.","A large array of bytes, each with its own unique address, central to the system.",A network interface component for data transmission.,A permanent storage device for archival data.,A software component for process scheduling.,B,"The text states that 'Memory: central to modern computer systems; large array of bytes, each with own address.'"
What mechanism is primarily used for address space allocation according to the provided text?,Virtual address translation tables.,Memory-mapped I/O registers.,Base and limit registers.,Dynamic memory pooling algorithms.,Static address mapping tables.,C,The text explicitly mentions 'Address space allocation: using base and limit registers.'
What specific value does the 'base register' hold in the context of address space allocation?,The largest legal physical memory address.,The total size of the allocated memory segment.,The smallest legal physical memory address.,The number of pages currently in memory.,The starting address of the operating system kernel.,C,The text defines 'Base register: smallest legal physical memory address.'
"In memory management, what does the 'limit' value specify?",The maximum number of processes that can run concurrently.,The maximum clock speed of the CPU.,The total amount of available physical memory.,The size of the address range.,The minimum allowed page size.,D,The text states 'Limit: specifies size of address range.'
Which of the following are listed as binding times for symbolic address references to physical addresses?,"Compile time, Load time, Execution time","Design time, Development time, Testing time","Initialization time, Runtime, Shutdown time","Linking time, Relocation time, Swapping time","Analysis time, Optimization time, Deployment time",A,"The text lists 'Compile time, Load time, Execution time' as the binding times."
What entity is responsible for generating a 'logical address'?,Memory Management Unit (MMU),Disk Controller,Central Processing Unit (CPU),Input/Output (I/O) Device,Translation Look-aside Buffer (TLB),C,The text states 'Logical address: generated by CPU.'
What is the primary function of the Memory Management Unit (MMU)?,To allocate CPU time to various processes.,To translate logical addresses to physical addresses.,To manage the flow of data to and from peripheral devices.,To store frequently accessed instructions.,To perform disk defragmentation.,B,The text states 'Memory Management Unit (MMU): translates logical address to physical address.'
"Before discussing paging, what approach to memory allocation is mentioned, characterized by partitions of varying sizes?",Dynamic linking memory allocation.,Contiguous memory partitions.,Segmented memory allocation.,Overlays for memory management.,Virtual memory only.,B,The text states 'Memory allocation approach: contiguous memory partitions of varying sizes.'
Which of the following is NOT listed as a partition allocation strategy?,First fit,Best fit,Worst fit,Next fit,All are listed strategies.,D,"The text lists 'First fit, Best fit, Worst fit'. 'Next fit' is not mentioned."
What technique do modern operating systems primarily use to manage memory?,Segmentation,Swapping,Contiguous allocation,Paging,Overlays,D,The text states 'Modern OS: use paging to manage memory.'
"In the context of paging, what are the fixed-sized blocks into which 'physical memory' is divided called?",Pages,Segments,Frames,Clusters,Blocks,C,The text specifies 'Physical memory: divided into fixed-sized blocks called frames.'
"What are the blocks of 'logical memory' called, which are of the same size as physical memory blocks?",Frames,Segments,Sectors,Pages,Partitions,D,The text states 'Logical memory: divided into blocks of same size called pages.'
How is a 'logical address' conceptually divided in the paging scheme?,Into a base register and a limit register.,Into a segment number and an offset.,Into a process ID and a memory address.,Into a page number and a page offset.,Into a cache line and a block address.,D,The text states 'Paging: logical address divided into page number and page offset.'
What is the primary function of the 'page number' component of a logical address?,It indicates the exact byte location within a frame.,It serves as an index into a per-process page table.,It defines the size of the logical memory space.,It specifies the physical memory address directly.,It determines the type of data stored in the page.,B,The text states 'Page number: index into per-process page table.'
What information does a 'page table' primarily contain?,The total size of the process's logical address space.,The base and limit registers for a given process.,The frame in physical memory holding the corresponding page.,A list of all free pages in logical memory.,The history of recently accessed memory locations.,C,The text states 'Page table: contains frame in physical memory holding the page.'
What does the 'offset' component of a logical address represent in the context of paging?,The starting address of the page table.,The specific location within the frame.,The number of pages allocated to a process.,The difference between logical and physical addresses.,The version number of the memory page.,B,The text states 'Offset: specific location in the frame.'
What is a Translation Look-aside Buffer (TLB)?,A software component for managing virtual memory.,A hardware cache of the page table.,A database of all system processes.,A dedicated chip for graphical rendering.,A buffer for I/O operations.,B,The text defines 'Translation Look-aside Buffer (TLB): hardware cache of page table.'
What information does each entry in a Translation Look-aside Buffer (TLB) store?,The process ID and the memory limit.,The logical address and the calculated physical address.,The page number and the corresponding frame.,The page offset and the frame size.,The time of last access and a dirty bit.,C,The text states 'Each TLB entry: page number and corresponding frame.'
"In the TLB address translation process, what happens if the frame for a page is found in the TLB?",The system must then retrieve it from the main page table.,"A page fault occurs, and the page is loaded from disk.","The frame is obtained directly from the TLB, bypassing the page table.",The logical address is immediately marked as invalid.,The process is paused to update the TLB.,C,The text states 'If in TLB: frame obtained from TLB.'
"If the frame for a page is NOT found in the TLB during address translation, what is the next step?",The process terminates due to an access violation.,The frame is retrieved from secondary storage (disk).,The frame is retrieved from the main page table.,The TLB is flushed and reloaded.,A new page entry is created in the TLB.,C,The text states 'If not in TLB: retrieve from page table.'
What defines 'Hierarchical paging'?,"It uses a single, global page table for all processes.",Logical addresses are divided into multiple parts for different page table levels.,It is a method for organizing physical memory into tiers.,It involves binding addresses at compile time only.,It is a technique to move pages between RAM and disk.,B,The text states 'Hierarchical paging: logical address divided into multiple parts for different page table levels.'
What is a described problem with hierarchical paging when addresses expand beyond 32 bits?,A reduction in the number of required page tables.,An increase in TLB hit rates.,A large number of hierarchical levels.,The elimination of page faults.,Simplified memory access permissions.,C,The text identifies 'large number of hierarchical levels' as a problem with expanding addresses beyond 32 bits in hierarchical paging.
Which two strategies are specifically mentioned to address the issue of expanding addresses and numerous hierarchical levels?,Segmentation and fixed-size partitions.,First fit and best fit algorithms.,Hashed page tables and inverted page tables.,Direct mapped caches and fully associative caches.,Compile time binding and load time binding.,C,The text lists 'hashed page tables and inverted page tables' as strategies to address this.
What is the primary purpose of 'swapping' in memory management?,To reorder CPU instructions for optimal execution.,To move pages to disk to increase the degree of multiprogramming.,To transfer data between CPU registers and cache.,To adjust the size of physical memory frames dynamically.,To perform data compression on memory contents.,B,The text defines 'Swapping: moves pages to disk to increase degree of multiprogramming.'
"How many levels of page tables does the Intel 32-bit architecture typically employ, and what page sizes does it support?",One level; 1KB or 2MB.,Two levels; 4KB or 4MB.,Three levels; 8KB or 16MB.,Four levels; 2KB or 8MB.,No fixed number; variable sizes determined by OS.,B,The text states 'Intel 32-bit architecture: two levels of page tables; supports 4-KB or 4-MB page sizes.'
What is the main function of 'Page-address extension' (PAE)?,To extend the logical address space for 64-bit processors.,To allow 32-bit processors to access physical address space greater than 4 GB.,To increase the number of TLB entries.,To optimize the speed of disk I/O operations.,To provide hardware support for virtual machines.,B,The text states 'Page-address extension: allows 32-bit processors to access physical address space > 4 GB.'
Which architectures are mentioned as being 64-bit and utilizing hierarchical paging?,Intel Itanium and AMD K6.,SPARC and MIPS.,x86-64 and ARM v8.,PowerPC and Alpha.,Motorola 68k and Zilog Z80.,C,The text states 'x86-64 and ARM v8 architectures: 64-bit architectures using hierarchical paging.'
