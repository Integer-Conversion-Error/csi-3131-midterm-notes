Question,Option A,Option B,Option C,Option D,Option E,Answer,Explanation
What primary problem in memory management does paging address by allowing noncontiguous physical address space?,Internal fragmentation,Thrashing,External fragmentation and compaction issues,Memory leaks,Deadlock prevention,C,"Paging is a memory-management scheme specifically designed to allow noncontiguous physical address space, which avoids external fragmentation and the need for compaction that plague contiguous allocation schemes."
Which of the following best defines 'paging' in the context of memory management?,A scheme for managing contiguous physical memory blocks.,A technique to increase CPU clock speed for memory access.,A memory-management scheme allowing noncontiguous physical address space.,A method to cache frequently used data in registers.,A process of swapping entire processes between RAM and disk.,C,"Paging is defined as a memory-management scheme that enables a process's physical address space to be noncontiguous, which is its primary characteristic."
"Paging is widely adopted in most operating systems, ranging from servers to mobile devices, primarily due to what?",Its simplicity in implementation.,Its ability to eliminate all forms of memory fragmentation.,Its inherent security features.,Its advantages in managing noncontiguous physical memory.,Its minimal hardware requirements.,D,"Paging's widespread use is attributed to its advantages, mainly its effectiveness in managing memory by allowing noncontiguous physical address spaces, which solves issues like external fragmentation."
The implementation of paging requires cooperation between which two components?,Application software and network protocols,Operating system and hardware,User processes and the file system,Compilers and interpreters,Disk drives and solid-state drives,B,"Paging is a complex memory management technique that relies on the close cooperation between the operating system (for managing page tables, frame tables, etc.) and specialized hardware (for address translation via MMU, TLB, etc.)."
"In a paging system, what are the fixed-sized blocks of physical memory referred to as?",Pages,Segments,Frames,Clusters,Blocks,C,Physical memory is broken into fixed-sized blocks called 'frames' in a paging system.
What are the fixed-sized blocks of logical memory called in a paging system?,Frames,Segments,Partitions,Pages,Regions,D,Logical memory is broken into same-sized blocks called 'pages' in a paging system.
"During process execution in a paging system, how are pages loaded into memory?",Pages must be loaded into contiguous memory frames.,Pages are loaded only into frames at the beginning of physical memory.,Pages are loaded into any available memory frames.,Pages are loaded directly into the CPU's registers.,Pages are loaded only if the entire program can fit contiguously.,C,"A key benefit of paging is that pages can be loaded into any available memory frames, regardless of their physical location, due to the noncontiguous nature of the physical address space."
"In a paging system, how is the backing store (e.g., disk) typically divided?",Into variable-sized segments.,"Into fixed-sized blocks, the same size as frames or clusters.",Into one large contiguous block for each process.,"It is not divided; it functions as a single, undifferentiated space.",Based on file system directories.,B,"The backing store is divided into fixed-sized blocks, which are the same size as frames or clusters, to facilitate efficient swapping of pages between memory and disk."
What is the relationship between logical address space and physical address space in a paging system?,They are identical.,Logical address space is a subset of physical address space.,They are totally separate.,Physical address space is always larger than logical address space.,They are identical only when there is no fragmentation.,C,"In paging, the logical address space (what the CPU sees) is totally separate from the physical address space (where data actually resides in memory)."
A CPU-generated address in a paged memory system is divided into which two parts?,Segment number and offset,Base address and limit,Page number and page offset,Process ID and memory address,Register value and memory location,C,The CPU generates a logical address which is divided into a page number (p) and a page offset (d) for translation.
What is the 'page number (p)' used for in a paging system?,To specify the exact byte location within a frame.,As an index into the per-process page table.,To directly access physical memory.,To determine the size of a page.,To identify the process owning the memory.,B,The page number (p) is used as an index into the page table to find the corresponding physical frame number.
What information does a 'page table' typically contain?,The logical address of each page.,The base address of each frame in physical memory.,The size of each process.,The location of the backing store.,A list of all free memory blocks.,B,The page table's primary function is to store the base address (or frame number) of each corresponding frame in physical memory.
What does the 'page offset (d)' represent in a paged memory system?,The base address of the physical frame.,The index into the page table.,The location within the referenced frame.,The total size of the logical address space.,The number of pages allocated to a process.,C,The page offset (d) directly specifies the location or byte offset within the physical memory frame identified by the page table entry.
How is the physical memory address computed in a paging system?,Page number + Page offset,Base address of frame + Page offset,Frame number * Page size + Page offset,Logical address - Page table base register,Page number * Page size,B,The physical memory address is calculated by combining the base address of the frame (obtained from the page table using the page number) with the page offset.
Which of the following correctly describes the steps an MMU takes to translate a logical address to a physical address?,"Extract page offset (d), use as index, extract frame number (f), replace d with f.","Extract page number (p), use as index, extract frame number (f), replace p with f.","Extract frame number (f), use as index, extract page number (p), replace f with p.","Extract page number (p), directly access memory, add offset (d).","Extract page offset (d), replace page number (p) with d, then access memory.",B,"The MMU extracts the page number (p), uses it as an index into the page table to get the frame number (f), and then replaces p with f to form the physical address with the unchanged offset (d)."
"During the logical-to-physical address translation process, which component of the CPU-generated address remains unchanged?",The page number (p),The frame number (f),The page offset (d),The base address of the page table,The physical memory address,C,The page offset (d) directly specifies the location within the frame and is carried directly from the logical address to the physical address without modification.
"Who defines the page size (and consequently, frame size) in a paging system?",The programmer at compile time.,The operating system dynamically.,The user at runtime.,The hardware.,The application software.,D,"Page size, which is always equal to frame size, is a hardware-defined characteristic, typically a power of 2."
"Why is the page size typically a power of 2 (e.g., 4 KB, 1 GB)?",To minimize the number of page table entries.,To simplify the hardware design for disk access.,To make the translation of logical addresses into page numbers and offsets easier.,To reduce internal fragmentation to zero.,To increase the effective memory access time.,C,"A page size that is a power of 2 allows for simple and efficient division of a logical address into its page number and offset using bitwise operations, simplifying hardware translation."
"If a logical address space is $2^m$ bytes and the page size is $2^n$ bytes, how are the page number and page offset typically determined?",Page number uses low-order $n$ bits; page offset uses high-order $m-n$ bits.,Page number uses high-order $m$ bits; page offset uses low-order $n$ bits.,Page number uses high-order $m-n$ bits; page offset uses low-order $n$ bits.,Page number uses low-order $m-n$ bits; page offset uses high-order $n$ bits.,Page number and page offset are both $n$ bits.,C,"For a logical address space of $2^m$ and page size of $2^n$, the high-order $m-n$ bits represent the page number, and the low-order $n$ bits represent the page offset."
Paging is a form of which type of relocation?,Static relocation,Compile-time relocation,Load-time relocation,Dynamic relocation,Fixed relocation,D,"Paging performs address translation at runtime, meaning every logical address is bound to a physical address dynamically by the paging hardware, classifying it as a form of dynamic relocation."
Which type of memory fragmentation is entirely avoided by paging?,Internal fragmentation,External fragmentation,Both internal and external fragmentation,Stack fragmentation,Heap fragmentation,B,"Paging allocates physical memory in fixed-size frames, allowing any available frame to be used for any page, thus eliminating external fragmentation because there are no wasted 'holes' between allocated blocks."
What type of memory fragmentation can still occur in a paging system?,External fragmentation,Inter-process fragmentation,Internal fragmentation,Disk fragmentation,Cache fragmentation,C,"Internal fragmentation can occur in paging if the last page allocated to a process does not perfectly fill its frame, leaving some unused space within that frame."
What is the average amount of internal fragmentation expected per process in a paging system?,Zero,One full page,One-quarter page,One-half page,Two pages,D,"On average, a process might not fully utilize its last allocated page, resulting in approximately one-half page of internal fragmentation per process."
"To minimize internal fragmentation, what characteristic is generally desirable for page sizes?",They should be as large as possible.,They should be dynamically adjustable based on process needs.,They should be very small.,They should be prime numbers.,They should be equal to the process size.,C,"Smaller page sizes mean that the leftover space in the last page (internal fragmentation) is also smaller, thus reducing overall wasted space."
What is one benefit associated with using larger page sizes in a paging system?,Less internal fragmentation.,More efficient disk I/O due to larger data transfers.,Reduced context-switch time.,Simpler page table lookup.,Elimination of the need for a TLB.,B,"Larger page sizes enable larger data transfers during disk I/O, which is generally more efficient as it reduces the number of I/O operations."
What overhead is reduced by using larger page sizes in a paging system?,CPU context switch time.,Disk I/O latency.,Overhead per page-table entry.,Physical memory consumption.,TLB miss rate.,C,"Larger page sizes mean fewer pages are needed to cover a given logical address space, which in turn means fewer entries in the page table, reducing the memory overhead per page-table entry."
Why have page sizes generally increased over time in computing systems?,To reduce the complexity of the paging hardware.,"Due to processes, data sets, and main memory becoming larger.",To eliminate internal fragmentation completely.,To improve CPU clock speeds.,To make systems more compatible with older software.,B,"As processes, data sets, and available main memory have grown, larger page sizes have become more practical and efficient, reducing the number of page table entries needed and improving I/O efficiency."
What are typical page sizes in modern operating systems?,1 KB or 2 KB,4 KB or 8 KB,16 KB or 32 KB,64 KB or 128 KB,512 bytes or 1 KB,B,"Common page sizes today are 4 KB or 8 KB, though some systems like Windows 10 and Linux support multiple sizes including much larger 'huge pages'."
"In Linux, what term is used for especially large pages that can be designated for physical memory regions?",Superpages,Jumbopages,Megapages,Huge pages,Gigapages,D,"Linux supports a feature called 'huge pages' for designating regions of physical memory for particularly large page sizes (e.g., 2 MB or 1 GB)."
A 32-bit CPU typically has page-table entries of what size?,1 byte,2 bytes,4 bytes,8 bytes,16 bytes,C,"For a 32-bit CPU, a page-table entry is typically 4 bytes, which is sufficient to point to a frame number within a 32-bit address space."
"If a system uses 4-byte page-table entries and a frame size of 4 KB ($2^{12}$ bytes), what is the maximum physical memory it can address with these entries?",$2^{32}$ bytes (4 GB),$2^{36}$ bytes (64 GB),$2^{44}$ bytes (16 TB),$2^{48}$ bytes (256 TB),$2^{64}$ bytes (16 EB),C,"A 32-bit (4-byte) entry can point to $2^{32}$ distinct frame numbers. If each frame is $2^{12}$ bytes, then the total addressable physical memory is $2^{32} * 2^{12} = 2^{44}$ bytes (16 TB)."
"Besides the frame address, what other information might page-table entries contain, potentially reducing the number of bits available for frame addresses?",Process ID and priority.,Disk block number and file name.,"Protection bits (e.g., read/write) and valid-invalid bit.",CPU speed and cache size.,Network address and port number.,C,"Page-table entries often contain additional information such as protection bits (for read/write/execute permissions) and a valid-invalid bit, which reduces the total bits available for specifying the frame address."
"When a new process arrives, how does the operating system determine the physical memory requirements for its pages?",It allocates a fixed amount of memory regardless of process size.,It examines the process's size in terms of pages and ensures that enough frames are available.,It requests the user to specify the required memory.,It loads the process into a single large contiguous block.,It calculates the memory based on the CPU's current load.,B,"Upon a process's arrival, the OS determines its size in pages. For efficient loading, it must ensure that there are enough available physical frames to accommodate all 'n' pages required by the process."
Which statement accurately describes the relationship between the programmer's view of memory and actual physical memory in a paged system?,"The programmer views memory as a single contiguous space, which directly maps to a contiguous block in physical memory.","The programmer views memory as a single contiguous space, while the user program is scattered throughout physical memory.",The programmer is fully aware of the physical locations of their program's pages.,The programmer's view of memory is identical to the physical memory layout.,The OS directly exposes physical memory addresses to the programmer.,B,"In a paged system, the programmer perceives a single, contiguous logical address space for their program, but the OS and hardware scatter these pages across noncontiguous physical frames, transparently to the programmer."
How is a user process prevented from accessing memory it does not own in a paging system?,By hardware checks on physical addresses only.,By limiting the process to a specific physical memory partition.,By having no way to address memory outside its own page table.,By requiring explicit permission from the OS for every memory access.,By encrypting unowned memory regions.,C,"A user process can only generate logical addresses that are mapped through its own page table. There is no mechanism for it to generate a logical address that would translate to a physical address outside of the frames listed in its page table, thus preventing access to unowned memory."
"What system-wide data structure does the operating system use to keep track of physical page frames' allocation details (e.g., free/allocated, to which process/page)?",Process control block,Page table,Frame table,Translation Look-aside Buffer (TLB),Symbol table,C,"The 'frame table' is a system-wide data structure, distinct from per-process page tables, that contains one entry for each physical page frame, detailing its allocation status and ownership."
"When a system call passes an address parameter, how does the operating system handle it in a paged environment?",The OS executes the system call directly on the logical address.,The address parameter is mapped to the correct physical address by the OS.,The system call fails if the address is not already in the TLB.,The OS requests the user to confirm the address validity.,The address parameter is ignored by the OS.,B,"The OS is aware that user processes operate in their logical address space. When a system call includes an address parameter, the OS is responsible for translating that logical address to the correct physical address using its own copy of the process's page table."
The OS maintains a copy of the page table for each process. What is one of its primary uses?,To directly access physical memory without translation.,For manual logical-to-physical translation by the OS itself.,To cache frequently used data for the process.,To manage inter-process communication directly.,To perform garbage collection for the process.,B,"The OS maintains a copy of each process's page table for its own internal use, such as performing manual logical-to-physical address translation when necessary (e.g., for system calls) or setting up hardware page tables via the CPU dispatcher."
What is a recognized disadvantage of paging concerning system performance?,It eliminates the possibility of memory sharing.,It increases the overhead of disk I/O.,It significantly increases internal fragmentation.,It increases context-switch time.,It requires more physical memory than non-paging systems.,D,"Because page tables are per-process structures and potentially large, loading and restoring them during context switches can add overhead, thus increasing context-switch time."
Where is the pointer to a process's page table typically stored?,In the process's stack.,In a global system registry.,In the process control block (PCB).,In the Translation Look-aside Buffer (TLB).,In the main memory alongside the page table itself.,C,"The pointer to a process's page table, along with other registers and process-specific data, is stored in its process control block (PCB)."
What action does the CPU scheduler take regarding hardware page-table values when it selects a process?,It flushes all hardware page-table values.,It reloads user registers and hardware page-table values from the stored user page table.,It computes new page-table values from scratch.,It only modifies the page table if the process is new.,It ignores page-table values as they are managed by the MMU.,B,"When a CPU scheduler selects a process, it must load the correct context, which includes reloading the user registers and updating the hardware's page-table registers (or PTBR) to point to the selected process's page table."
"What is the simplest hardware implementation of a page table, and what is its primary characteristic?","Storing it in main memory, which is efficient for large tables.","Using dedicated high-speed hardware registers, providing efficient translation.","Implementing it as a software-managed data structure, offering flexibility.",Distributing it across multiple CPU cores for parallel access.,Storing it on disk for persistence.,B,"The simplest hardware implementation is using dedicated high-speed hardware registers. This provides very efficient translation because page-table entries are directly accessible, though it's only feasible for small page tables (e.g., 256 entries)."
Why are dedicated hardware registers not a feasible approach for storing page tables in contemporary CPUs?,Registers are too slow for memory access.,The number of entries in contemporary page tables is too large for registers.,Registers are too expensive to manufacture in large quantities.,Registers cannot be accessed by the operating system.,Registers do not support dynamic relocation.,B,"Contemporary CPUs use much larger page tables (e.g., 2^20 entries), far too many to be stored entirely in dedicated hardware registers, making this approach impractical due to cost and physical space."
Where are large page tables typically stored in contemporary CPU architectures?,In the CPU's L1 cache.,On the hard disk.,In the main memory.,In dedicated GPU memory.,In the firmware ROM.,C,"Given the size of modern page tables, they are typically stored in the main memory, with a register (Page-Table Base Register, PTBR) pointing to their starting location."
What is the function of the 'Page-Table Base Register (PTBR)'?,It holds the current page number being translated.,It points to the current page table in main memory.,It stores the size of the logical address space.,It manages the Translation Look-aside Buffer (TLB).,It keeps track of free physical frames.,B,"The PTBR is a CPU register that points to the base address of the current process's page table, which is typically stored in main memory."
How does using a Page-Table Base Register (PTBR) to change page tables affect context-switch time?,It significantly increases it because the entire page table must be reloaded.,"It reduces it, as only the PTBR needs to be changed.","It has no effect, as the MMU handles it independently.",It makes context switching impossible.,It requires flushing the entire physical memory.,B,"When the page table is in main memory, changing processes only requires updating the PTBR to point to the new process's page table, which is a single register write and thus reduces context-switch time compared to loading entire page tables into registers."
What is the performance drawback when page tables are stored solely in main memory?,Increased internal fragmentation.,Requirement for more physical memory.,Slower memory access times due to two memory accesses per data access.,Reduced CPU clock speed.,Difficulty in implementing memory protection.,C,"If the page table is in main memory, accessing data requires two memory accesses: one to retrieve the page-table entry (frame number) and another to access the actual data. This effectively slows down memory access by a factor of two, which is generally intolerable."
What is the standard solution to mitigate the performance penalty of storing page tables in main memory?,Increasing the size of physical memory.,Implementing a Translation Look-aside Buffer (TLB).,Using a larger page size.,Reducing the number of processes in memory.,Storing page tables on disk instead.,B,"The Translation Look-aside Buffer (TLB) is a small, fast-lookup hardware cache designed to store frequently used page-table entries, thereby avoiding the two-memory-access penalty for most memory references."
What type of memory is a Translation Look-aside Buffer (TLB)?,"Volatile, slow-speed memory.","Non-volatile, high-speed memory.","Associative, high-speed memory.",Sequential access memory.,Main memory (DRAM).,C,"The TLB is described as an associative, high-speed memory, meaning it can compare an input (page number) with all stored keys simultaneously for very fast lookup."
What does each entry in a Translation Look-aside Buffer (TLB) typically contain?,Only the physical address.,Only the logical address.,A key (tag) and a value.,The process ID and the page size.,The total number of available frames.,C,"Each TLB entry functions like an associative memory entry, comprising a 'key' (typically the page number) and a 'value' (the corresponding frame number), along with other bits like protection."
"Where is the TLB lookup typically performed within the CPU's operation, and what is its performance implication?","As a separate, slow operation after memory access, causing a performance penalty.","As part of the instruction pipeline, with no performance penalty.","Only during context switches, to reduce overhead.","By the operating system in software, making it very flexible.","Only for I/O operations, not for CPU instruction fetches.",B,"TLB lookup is designed to be highly efficient, typically integrated into the instruction pipeline itself, meaning it can perform its check without adding a significant performance penalty to memory access."
What is the typical size range for a Translation Look-aside Buffer (TLB) in terms of entries?,1 to 10 entries.,"32 to 1,024 entries.","4,096 to 16,384 entries.",1 million entries or more.,It varies dynamically based on system load.,B,"TLBs are designed to be small and fast. Their typical size ranges from 32 to 1,024 entries, balancing speed with coverage."
Some CPUs incorporate separate instruction and data address TLBs. What is the main advantage of this design?,It doubles the total number of entries that can be cached.,It allows for independent memory protection settings for code and data.,It reduces the need for the main memory page table.,It simplifies the TLB replacement policies.,It eliminates the need for context switching.,A,"By having separate instruction and data TLBs, the total capacity for cached address translations is effectively doubled, as entries for instruction pages and data pages can be stored independently without conflicting for space within a single TLB."
"During the MMU's address translation process, what happens first when a CPU generates a logical address, regarding the TLB?",The MMU immediately accesses the main memory page table.,The MMU checks if the page number is present in the TLB.,The MMU directly calculates the physical address without using the TLB.,The MMU writes the logical address to the TLB.,The MMU checks the frame table for available frames.,B,The first step in MMU address translation with a TLB is to check if the required page number's translation is already cached in the TLB.
What is a 'TLB hit'?,The page number is not found in the TLB.,"The frame number is immediately available from the TLB, allowing direct memory access.",The MMU needs to access the main memory page table.,An error occurs during address translation.,The TLB is full and an entry must be replaced.,B,"A TLB hit occurs when the page number generated by the CPU is found in the TLB, meaning the corresponding frame number is immediately available, leading to fast memory access."
What action is taken by the MMU on a 'TLB miss'?,The MMU immediately terminates the process.,The MMU proceeds to access main memory to retrieve the data directly.,A memory reference to the page table (in main memory) is made to obtain the frame number.,The MMU flushes the entire TLB.,The MMU generates a new random frame number.,C,"On a TLB miss, the required page-to-frame mapping is not in the TLB, so the MMU must perform a slower memory access to the page table, which resides in main memory, to obtain the correct frame number."
"After a TLB miss, and the frame number is obtained from the page table, what is a crucial step taken to optimize future access?",The page number and frame number are removed from the main memory page table.,The page number and frame number are added to the TLB.,The page number is permanently 'wired down' in the TLB.,The entire TLB is flushed.,The process's priority is increased.,B,"To improve performance for subsequent accesses to the same page, the page number and its corresponding frame number (the translation) are added to the TLB after a miss."
"When a TLB is full and a new entry needs to be added, what policy is typically used to select an existing entry for replacement?","First-In, First-Out (FIFO) only.",Random replacement only.,"Least Recently Used (LRU), round-robin, or random policies.","Last-In, First-Out (LIFO) only.",Always the entry with the lowest page number.,C,"When a TLB is full, an existing entry must be replaced, and common replacement policies include LRU (Least Recently Used), round-robin, and random policies."
What does it mean for a TLB entry to be 'wired down'?,The entry is marked as invalid and cannot be used.,The entry is permanently removed from the TLB.,The entry is locked into the TLB and cannot be removed by the usual replacement algorithm.,The entry is transferred to main memory for storage.,"The entry is exclusively for data access, not instruction access.",C,"Wired-down entries are those that are marked as non-removable from the TLB, typically for critical kernel code or data, ensuring they are always available for fast lookup."
What is the primary purpose of Address-Space Identifiers (ASIDs) in TLB entries?,To uniquely identify a page within a process.,To increase the size of the TLB.,To uniquely identify the process owning the entry and provide address-space protection.,To determine the age of a TLB entry for replacement policies.,To indicate whether a page is read-only or read-write.,C,"ASIDs are stored in TLB entries to uniquely identify the process that owns the translation. This allows the TLB to contain entries from multiple processes simultaneously, and it also contributes to address-space protection by ensuring the current process's ASID matches the entry's ASID."
How do ASIDs (Address-Space Identifiers) impact TLB behavior when resolving virtual page numbers?,"They always cause a TLB miss, requiring a page table lookup.",They allow the TLB to contain entries for only one process at a time.,"If the current process's ASID does not match the virtual page's ASID, it's treated as a TLB miss.",They eliminate the need for the MMU entirely.,They dictate which replacement algorithm is used for TLB entries.,C,"If the ASID associated with the current process does not match the ASID stored in a TLB entry for a virtual page number, it signals that the entry belongs to a different process's address space, and thus it's treated as a TLB miss, forcing a page table lookup."
What is the significant advantage of TLBs that support ASIDs for multi-process environments?,They eliminate internal fragmentation.,They allow the TLB to contain entries for multiple processes simultaneously.,They prevent external fragmentation.,They reduce the need for physical memory.,They make page-table entries smaller.,B,"By including ASIDs, the TLB can distinguish between entries from different processes. This means translations for multiple processes can coexist in the TLB, reducing the need for flushing the TLB on every context switch."
What must happen to a Translation Look-aside Buffer (TLB) without ASIDs on each context switch?,It must be expanded.,It must be flushed (erased).,It must be reconfigured for the new process's page size.,It must be backed up to disk.,It must load new entries from main memory proactively.,B,"Without ASIDs, a TLB cannot distinguish which process an entry belongs to. Therefore, on every context switch, the TLB must be flushed to prevent the next process from inadvertently using incorrect or invalid translation information from the previous process."
Why is a TLB without ASIDs typically 'flushed' (erased) on each context switch?,To save power.,To ensure data consistency in the cache.,To prevent the next process from using wrong translation information.,To increase the hit ratio for the new process.,To free up space for the operating system's kernel code.,C,"Flushing the TLB on a context switch is essential without ASIDs to prevent security and correctness issues. Old entries might correspond to physical addresses that are no longer valid or belong to a different process's address space, leading to incorrect memory accesses."
What is the 'hit ratio' in the context of a Translation Look-aside Buffer (TLB)?,The total number of entries in the TLB.,The percentage of times a page number is found in the TLB.,The rate at which the TLB is flushed.,The number of memory accesses that result in an error.,The ratio of CPU speed to memory speed.,B,"The 'hit ratio' is a measure of the TLB's effectiveness, representing the percentage of memory accesses where the required page-to-frame translation is found directly in the TLB (a TLB hit)."
"Calculate the effective memory-access time if a system has a TLB hit ratio of 80%, a TLB access time of 10 ns, and a memory access time of 10 ns (meaning a TLB miss costs 20 ns for page table lookup and data access, in addition to the initial 10 ns TLB lookup).",10 ns,12 ns,15 ns,18 ns,20 ns,B,"Effective memory-access time = (hit ratio * (TLB access time + memory access time)) + (miss ratio * (TLB access time + 2 * memory access time)). As per the text's example, it's (0.80 * 10 ns) + (0.20 * 20 ns) = 8 ns + 4 ns = 12 ns."
"If a TLB has a 99% hit ratio, a TLB access time of 10 ns, and a memory access time of 10 ns, what is the effective memory-access time?",9.9 ns,10.0 ns,10.1 ns,11.0 ns,19.9 ns,C,"Effective memory-access time = (0.99 * 10 ns) + (0.01 * 20 ns) = 9.9 ns + 0.2 ns = 10.1 ns. (The 20ns for miss includes the TLB check plus page table lookup and data access, hence 20 ns for the miss component)."
What is a common feature of TLB organization in modern CPUs like Intel Core i7?,"A single, very large TLB for all memory types.","No TLB at all, relying solely on main memory page tables.","Multiple TLB levels (e.g., L1 instruction TLB, L1 data TLB, L2 TLB).",TLBs that are entirely software-managed.,TLBs that are only used for kernel space addresses.,C,"Modern CPUs often employ multiple levels of TLBs, similar to cache hierarchies (e.g., L1 instruction TLB, L1 data TLB, L2 TLB), to further optimize translation performance."
What happens if a logical address translation results in a miss at the L2 TLB level?,The CPU immediately aborts the process.,The CPU accesses the L1 TLB again.,The CPU walks the page-table entries in main memory or interrupts the OS.,The CPU attempts to write the entry to a wired-down TLB entry.,The CPU reboots the system to clear the cache.,C,"A miss at the highest TLB level (L2 in this example) means the translation is not cached and must be retrieved from the page table in main memory, which involves a potentially costly 'page table walk' (hundreds of cycles) or an interrupt to the OS to handle the miss."
How do hardware features like TLBs influence operating system design related to paging?,OS designers can ignore TLB features as they are purely hardware concerns.,OS paging improvements are independent of hardware changes like TLBs.,OS designers must understand TLB function and features to implement optimal paging for a platform.,TLBs entirely replace the need for OS-managed page tables.,TLBs are a legacy feature and not relevant to modern OS design.,C,"Hardware features such as TLBs significantly impact memory performance, and OS designers must understand their function to implement paging optimally for a given platform, as TLB design changes may necessitate OS paging implementation changes."
How is memory protection typically implemented in a paged environment?,By encrypting sensitive memory regions.,By isolating processes in separate physical memory banks.,Through protection bits associated with each frame in the page table.,By requiring user confirmation for every memory write operation.,By using a firewall between processes.,C,"Memory protection in a paged environment is typically achieved by including protection bits (e.g., read-write, read-only, execute-only) with each frame's entry in the page table. Every memory reference is checked against these bits during translation."
What happens if a process attempts to write to a page that has its protection bits set to 'read-only'?,The write operation is silently ignored.,"The write operation is completed, and the protection bit is automatically changed.","A hardware trap to the OS occurs, indicating a memory-protection violation.",The operating system automatically corrects the data.,The process is paused until user input is received.,C,"If a memory reference attempts an operation (e.g., write) that violates the protection bits (e.g., trying to write to a read-only page), the hardware detects this and generates a trap (interrupt) to the operating system, signaling a memory-protection violation."
"Beyond simple read-write protection, what finer-grained protection types can be associated with pages in a paging system?","Network access, disk access, printer access.","User-level, kernel-level, supervisor-level.","Read-only, read-write, execute-only.","Compressible, decomcompressible, encrypted.","High-priority, medium-priority, low-priority.",C,"Paging systems can implement finer-grained protection by assigning separate bits for read-only, read-write, and execute-only access types, trapping illegal attempts to the OS."
What is the purpose of the 'valid-invalid' bit in a page table entry?,To indicate if the page has been modified since last loaded.,To indicate if the page is currently in physical memory.,To indicate if the page is part of the process's logical address space (legal page).,To specify if the page is cached in the TLB.,To define the page's priority for eviction.,C,The valid-invalid bit in a page table entry indicates whether the corresponding page is part of the process's current logical address space (valid) or not (invalid). Accessing an invalid page generates a trap to the OS.
What happens if an address lookup in the page table points to an entry where the 'valid-invalid' bit is set to 'invalid'?,The page is automatically loaded from disk.,The memory access is silently allowed.,"An illegal address is trapped by the valid-invalid bit, leading to an OS intervention.",The page is marked as 'wired down' in the TLB.,The page size is automatically adjusted.,C,"If a logical address maps to a page table entry marked as 'invalid', it indicates an attempt to access memory outside the process's defined logical address space, and the hardware generates a trap to the OS."
Who is responsible for setting the 'valid-invalid' bit for each page in a process's page table?,The CPU's MMU automatically.,The programmer at compile time.,The operating system.,The hardware manufacturer.,The user during program installation.,C,"The operating system has control over the page tables and sets the valid-invalid bit for each page, allowing or disallowing access to specific logical pages for a given process."
What is the function of the 'page-table length register (PTLR)' in some paging systems?,It specifies the total number of frames in physical memory.,It indicates the size of the logical address space.,It points to the base of the page table in memory.,"It indicates the size of the page table, used to verify addresses are in a valid range.",It stores the size of individual pages.,D,"The PTLR holds the size of the page table. This value is checked against logical addresses to ensure they fall within the allocated portion of the process's logical address space, thus providing an additional layer of protection."
"If a logical address is checked against the Page-Table Length Register (PTLR) and fails the test, what happens?",The address is automatically corrected by the MMU.,The process is swapped out to disk.,An error trap is generated to the operating system.,The page table is dynamically resized.,The TLB entry for that address is flushed.,C,"If a logical address falls outside the range indicated by the PTLR (meaning it attempts to access a part of its logical address space that is beyond its declared size), a hardware error trap is generated to the OS, indicating an illegal memory access."
What is the primary advantage of paging that becomes significant in a multi-process environment?,Reduced CPU power consumption.,Automatic garbage collection.,The possibility of sharing common code.,Direct access to hardware registers.,Simplified debugging for applications.,C,"One of the major advantages of paging in a multi-process environment is the ability to share common code (like standard libraries) among multiple processes by mapping their page tables to the same physical frames, saving significant memory."
What characteristic must code possess to be effectively shared among multiple processes using paging?,It must be compiled with a special shared library flag.,It must be written in a specific programming language like C++.,It must be 'reentrant' (non-self-modifying).,It must be stored on a solid-state drive.,It must be small in size.,C,"For code to be safely shared, it must be reentrant, meaning it does not modify itself during execution. This allows multiple processes to execute the same physical copy of the code without interfering with each other."
What is 'reentrant code'?,Code that can only be executed by a single process at a time.,Code that automatically adapts to different hardware architectures.,"Code that is non-self-modifying, allowing multiple concurrent executions.",Code that must be loaded entirely into contiguous memory.,Code that manages memory allocation for other programs.,C,"Reentrant code is defined as code that does not modify itself during execution, which makes it suitable for simultaneous execution by multiple processes or threads without conflict."
"How does shared reentrant code, like the standard C library (`libc`), lead to significant memory savings when used by multiple processes?",Each process loads a smaller portion of the library into its address space.,The library is stored on disk and only loaded on demand.,"Only one physical copy of the `libc` is kept in memory, mapped by multiple page tables.",It eliminates the need for any page tables for shared libraries.,It compresses the library's code before loading.,C,"Instead of each process loading its own copy, only one physical copy of the reentrant code (e.g., `libc`) resides in physical memory. The page tables of multiple processes are then configured to point to these same physical frames, resulting in significant memory savings."
Which of the following are examples of programs that commonly benefit from shared pages in a multi-process environment?,Custom user applications and private data files.,Device drivers and interrupt handlers.,"Compilers, window systems, and database systems.",Web browsers and email clients.,Antivirus software and firewalls.,C,"Compilers, window systems, and database systems are mentioned as examples of programs that are often shared among multiple processes using paging to save memory because their code is typically reentrant."
How are shared libraries (like DLLs on Windows or SOs on Linux) typically implemented in the context of paging?,By loading a separate copy for each process.,Through direct memory access (DMA) without page tables.,"Using shared pages, mapping to a single physical copy.",By storing them exclusively in the CPU's cache.,"As part of the operating system kernel, not user space.",C,"Shared libraries are typically implemented using shared pages. This means a single physical copy of the library code is loaded into memory, and multiple processes can map to it via their respective page tables."
"When sharing code using paging, what characteristic should the operating system enforce for the shared code?",It should be writable by all processes.,It should be read-only.,It should be executable only by the root user.,It should be non-pageable.,It should be encrypted.,B,"To maintain integrity and enable safe sharing, the OS should enforce the read-only nature of shared code (reentrant code) to prevent one process from inadvertently modifying the code being used by others."
"Which of the following is implemented using shared pages, similar to how shared libraries are handled?",Virtualization of entire operating systems.,Direct Memory Access (DMA) operations.,Interprocess communication (IPC) through shared memory.,Network packet routing.,CPU scheduling algorithms.,C,"Shared memory, a common mechanism for interprocess communication (IPC), is typically implemented by having multiple processes map a shared region of their logical address space to the same physical pages, thus using the shared page mechanism."
What is 'frames' in the context of paging?,Fixed-sized blocks of logical memory.,Fixed-sized blocks of physical memory.,Segments of the CPU cache.,Units of data transferred to the disk.,Portions of a process control block.,B,"Frames are defined as fixed-sized blocks of physical memory, which pages are loaded into."
What is a 'page' in the context of paging?,Fixed-sized blocks of physical memory.,Variable-sized blocks of logical memory.,Fixed-sized blocks of logical memory.,A region of the CPU's internal registers.,A temporary storage area on the hard drive.,C,"A page is defined as a fixed-sized block of logical memory, which corresponds in size to physical memory frames."
"Which term describes a table in paged memory containing base addresses of physical memory frames, indexed by logical page number?",Frame table,Process control block,Translation Look-aside Buffer,Page table,Directory table,D,"The 'page table' is explicitly defined as containing the base address of each frame in physical memory, indexed by the logical page number."
"Which system-wide data structure contains details about physical page frames, such as whether they are free or allocated, and to which process/page?",Page table,Process control block,Frame table,TLB,Resource allocation graph,C,"The 'frame table' is a system-wide structure that tracks the state (free/allocated, owner) of each physical page frame."
What is a 'Translation Look-aside Buffer (TLB)'?,A software component for managing virtual memory.,"A large, slow cache for disk data.","A small, fast-lookup hardware cache for address translation.",A register that points to the page table.,A component responsible for inter-process communication.,C,"The TLB is defined as a special, small, fast-lookup hardware cache used to speed up address translation in paged memory systems."
What does a 'TLB miss' signify?,The TLB has found the requested address translation.,The requested address translation is not found in the TLB.,A fatal memory error has occurred.,The TLB is being flushed.,The process is attempting to access protected memory.,B,A 'TLB miss' occurs when the TLB lookup fails to provide the required address translation because the entry is not present in the TLB.
What does it mean for a TLB entry to be 'wired down'?,The entry is marked as invalid and cannot be used.,The entry is permanently removed from the TLB.,The entry is locked into the TLB and cannot be removed by the usual replacement algorithm.,The entry is transferred to main memory for storage.,"The entry is exclusively for data access, not instruction access.",C,"Wired-down entries are those that are marked as non-removable from the TLB, typically for critical kernel code or data, ensuring they are always available for fast lookup."
What is the 'hit ratio' a measure of in the context of TLBs?,The speed of memory access.,The percentage of times a page number is found in the TLB.,The total number of memory accesses per second.,The rate of page faults.,The average number of entries replaced in the TLB.,B,The 'hit ratio' quantifies the effectiveness of a TLB by indicating the percentage of times a page number (and thus its translation) is successfully found in the TLB.
What is the 'effective memory-access time'?,The theoretical maximum speed of memory access.,The time it takes to access the TLB only.,"The statistical or real measure of CPU time to read/write to memory, considering TLB hits/misses.",The time taken to transfer data between disk and main memory.,The time required for a context switch.,C,"Effective memory-access time is a metric that considers the combined impact of TLB access times, page table access times, and hit/miss ratios to provide an overall measure of how long memory access takes."
What is the primary information contained in a 'valid-invalid' bit of a page table entry?,Whether the page has been modified (dirty bit).,Whether the page is in the process's logical address space (legal).,Whether the page is read-only or read-write.,Whether the page is currently in the TLB.,Whether the page can be swapped out to disk.,B,"The 'valid-invalid' bit primarily indicates if a page is a legitimate part of the process's logical address space. A 'valid' bit means it is, and an 'invalid' bit means it is not, and an attempt to access it will trigger a trap."
